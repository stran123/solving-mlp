{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Machine Learning Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece==0.1.91\n",
      "  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.91\n",
      "    Uninstalling sentencepiece-0.1.91:\n",
      "      Successfully uninstalled sentencepiece-0.1.91\n",
      "Successfully installed sentencepiece-0.1.91\n",
      "Requirement already satisfied: transformers in /home/sunnyt/anaconda3/lib/python3.8/site-packages (4.4.2)\n",
      "Requirement already satisfied: filelock in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: packaging in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: click in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: six in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Collecting dgl\n",
      "  Downloading dgl-0.6.0.post1-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (2.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (2.24.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (1.19.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from networkx>=2.1->dgl) (4.4.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (1.25.11)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-0.6.0.post1\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.9.1-cp38-cp38-manylinux1_x86_64.whl (17.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.4 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install 'sentencepiece==0.1.91' --force-reinstall\n",
    "!pip install transformers\n",
    "!pip install dgl\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:38:46.536166Z",
     "start_time": "2020-10-29T08:38:37.253954Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "## Needs: pytorch, dgl, transformers, Python>=3.7\n",
    "\n",
    "from copy import copy\n",
    "from tqdm import tqdm, trange\n",
    "import itertools\n",
    "import importlib\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "false = False\n",
    "true = True\n",
    "NaN = float(\"NaN\")\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import util\n",
    "importlib.reload(util)\n",
    "from util import setup, check_match, evaluate_prefix_expression, sub_nP, get_quant_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Inputs to Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:30:17.523815Z",
     "start_time": "2020-10-29T08:30:17.503632Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensorize_data(train_data, test_data):\n",
    "    print(f\"Number of items: {len(train_data)+len(test_data)}\")\n",
    "    for d in tqdm(itertools.chain(train_data, test_data)):\n",
    "        d['in_idxs'] = torch.tensor([in_vocab.token2idx.get(x, in_vocab.unk) for x in d['in_tokens']])\n",
    "        d['out_idxs'] = torch.tensor([out_vocab.token2idx.get(x, out_vocab.unk) for x in d['out_tokens']])\n",
    "        d['n_in'] = n_in = len(d['in_idxs'])\n",
    "        d['n_out'] = len(d['out_idxs'])\n",
    "        d['n_nP'] = n_nP = len(d['nP'])\n",
    "        d['nP_in_mask'] = mask = torch.zeros(n_in, dtype=torch.bool)\n",
    "        mask[d['nP_positions']] = True\n",
    "        d['nP_out_mask'] = mask = torch.zeros(n_max_nP, dtype=torch.bool)\n",
    "        mask[:n_nP] = True\n",
    "        d['qcomp_edges'] = get_quantity_comparison_edges(d)\n",
    "        d['qcell_edges'] = get_quantity_cell_edges(d)\n",
    "\n",
    "def get_quantity_comparison_edges(d):\n",
    "    quants = [float(x) for x in d['nP']]\n",
    "    quant_positions = d['nP_positions']\n",
    "#     assert max(quant_positions) < d['n_in']\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=np.bool)\n",
    "    for x, x_pos in zip(quants, quant_positions):\n",
    "        for y, y_pos in zip(quants, quant_positions):\n",
    "            adj_matrix[x_pos, y_pos] |= x > y\n",
    "    \"\"\"\n",
    "    Convert the adjacency matrix of the directed graph into a tuple of (src_edges, dst_edges), which\n",
    "    is the input format of dgl.graph (see https://docs.dgl.ai/generated/dgl.graph.html).\n",
    "    Hint: check out the 'nonzero' function\n",
    "    \"\"\"\n",
    "    return adj_matrix.nonzero(as_tuple=True)\n",
    "\n",
    "def get_quantity_cell_edges(d):\n",
    "    in_idxs = d['in_idxs']\n",
    "    quant_positions = d['nP_positions']\n",
    "    quant_cell_positions = d['quant_cell_positions']\n",
    "    assert max(quant_cell_positions) < d['n_in']\n",
    "    word_cells = set(quant_cell_positions) - set(quant_positions)\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=torch.bool)\n",
    "    for w_pos in word_cells:\n",
    "        for q_pos in quant_positions:\n",
    "            if abs(w_pos - q_pos) < 4:\n",
    "                adj_matrix[w_pos, q_pos] = adj_matrix[q_pos, w_pos] = True\n",
    "    pos_idxs = in_idxs[quant_cell_positions]\n",
    "    for idx1, pos1 in zip(pos_idxs, quant_cell_positions):\n",
    "        for idx2, pos2 in zip(pos_idxs, quant_cell_positions):\n",
    "            if idx1 == idx2:\n",
    "                adj_matrix[pos1, pos2] = adj_matrix[pos2, pos1] = True\n",
    "    \"\"\"\n",
    "    Convert the adjacency matrix of the directed graph into a tuple of (src_edges, dst_edges), which\n",
    "    is the input format of dgl.graph (see https://docs.dgl.ai/generated/dgl.graph.html).\n",
    "    Hint: check out the 'nonzero' function\n",
    "    \"\"\"\n",
    "    return adj_matrix.nonzero(as_tuple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     102
    ]
   },
   "outputs": [],
   "source": [
    "class TransformerAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Used in Transformer Block\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qkv = nn.Linear(n_hid, n_head * (n_k * 2 + n_v))\n",
    "        self.out = nn.Linear(n_head * n_v, n_hid)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        n_batch, n_batch_max_in, n_hid = x.shape\n",
    "        q_k_v = self.qkv(x).view(n_batch, n_batch_max_in, n_head, 2 * n_k + n_v).transpose(1, 2)\n",
    "        q, k, v = q_k_v.split([n_k, n_k, n_v], dim=-1)\n",
    "\n",
    "        q = q.reshape(n_batch * n_head, n_batch_max_in, n_k)\n",
    "        k = k.reshape_as(q).transpose(1, 2)\n",
    "        qk = q.bmm(k) / np.sqrt(n_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            qk = qk.view(n_batch, n_head, n_batch_max_in, n_batch_max_in).transpose(1, 2)\n",
    "            qk[~mask] = -np.inf\n",
    "            qk = qk.transpose(1, 2).view(n_batch * n_head, n_batch_max_in, n_batch_max_in)\n",
    "        qk = qk.softmax(dim=-1)\n",
    "        v = v.reshape(n_batch * n_head, n_batch_max_in, n_v)\n",
    "        qkv = qk.bmm(v).view(n_batch, n_head, n_batch_max_in, n_v).transpose(1, 2).reshape(n_batch, n_batch_max_in, n_head * n_v)\n",
    "        out = self.out(qkv)\n",
    "        return x + out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = TransformerAttention()\n",
    "        n_inner = n_hid * 4\n",
    "        self.inner = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_inner),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_inner, n_hid)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.attn(x, mask=mask)\n",
    "        return x + self.inner(x)\n",
    "    \n",
    "class GCNBranch(nn.Module):\n",
    "    def __init__(self, n_hid_in, n_hid_out, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define a branch of the graph convolution with\n",
    "        1. GraphConv from n_hid_in to n_hid_in\n",
    "        2. ReLU\n",
    "        3. Dropout\n",
    "        4. GraphConv from n_hid_in to n_hid_out\n",
    "        \n",
    "        Note: your should call GraphConv with allow_zero_in_degree=True\n",
    "        \"\"\"\n",
    "        self.gc1 = GraphConv(n_hid_in, n_hid_in, allow_zero_in_degree=True)\n",
    "        self.drelu = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.gc2 = GraphConv(n_hid_in, n_hid_out, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, x, graph):\n",
    "        \"\"\"\n",
    "        Forward pass of your defined branch above\n",
    "        \"\"\"\n",
    "        return self.gc2(graph, self.drelu(self.gc1(graph, x)))\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, n_head=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList(GCNBranch(n_hid, n_hid // n_head, dropout) for _ in range(n_head))\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_hid),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hid, n_hid)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(n_hid)\n",
    "\n",
    "    def forward(self, h, gt_graph, attr_graph):\n",
    "        x = h.reshape(-1, n_hid)\n",
    "        graphs = [gt_graph, gt_graph, attr_graph, attr_graph]\n",
    "        x = torch.cat([branch(x, g) for branch, g in zip(self.branches, graphs)], dim=-1).view_as(h)\n",
    "        x = h + self.layer_norm(x)\n",
    "        return x + self.feed_forward(x)\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(Gate, self).__init__()\n",
    "        self.t = nn.Linear(n_in, n_out)\n",
    "        self.s = nn.Linear(n_in, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.t(x).tanh() * self.s(x).sigmoid()\n",
    "\n",
    "class TreeDecoder(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "        self.constant_embedding = nn.Parameter(torch.randn(1, out_vocab.n_constants, n_hid))\n",
    "\n",
    "        self.qp_gate = nn.Sequential(drop, Gate(n_hid, n_hid))\n",
    "        self.gts_right = nn.Sequential(drop, Gate(2 * n_hid, n_hid))\n",
    "\n",
    "        self.attn_fc = nn.Sequential(drop,\n",
    "            nn.Linear(2 * n_hid, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1)\n",
    "        )\n",
    "        self.quant_fc = nn.Sequential(drop,\n",
    "            nn.Linear(n_hid * 3, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1, bias=False)\n",
    "        )\n",
    "        self.op_fc = nn.Sequential(drop, nn.Linear(n_hid * 2, out_vocab.n_ops))\n",
    "\n",
    "        self.op_embedding = nn.Embedding(out_vocab.n_ops + 1, n_hid, padding_idx=out_vocab.n_ops)\n",
    "        self.gts_left = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "        self.gts_left_qp = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid), self.qp_gate)\n",
    "\n",
    "        self.subtree_gate = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "\n",
    "    def gts_attention(self, q, zbar, in_mask=None):\n",
    "        attn_score = self.attn_fc(\n",
    "            torch.cat([q.unsqueeze(1).expand_as(zbar), zbar], dim=2)\n",
    "        ).squeeze(2)\n",
    "        if in_mask is not None:\n",
    "            attn_score[~in_mask] = -np.inf\n",
    "        attn = attn_score.softmax(dim=1)\n",
    "        return (attn.unsqueeze(1) @ zbar).squeeze(1) # (n_batch, n_hid)\n",
    "\n",
    "    def gts_predict(self, qp_Gc, quant_embed, nP_out_mask=None):\n",
    "        quant_score = self.quant_fc(\n",
    "            torch.cat([qp_Gc.unsqueeze(1).expand(-1, quant_embed.size(1), -1), quant_embed], dim=2)\n",
    "        ).squeeze(2)\n",
    "        op_score = self.op_fc(qp_Gc)\n",
    "        pred_score = torch.cat((op_score, quant_score), dim=1)\n",
    "        if nP_out_mask is not None:\n",
    "            pred_score[:, out_vocab.base_nP:][~nP_out_mask] = -np.inf\n",
    "        return pred_score\n",
    "\n",
    "    def merge_subtree(self, op, tl, yr):\n",
    "        return self.subtree_gate(torch.cat((op, tl, yr), dim=-1))\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "\n",
    "        if use_t5:\n",
    "            \"\"\"\n",
    "            Use t5_model.encoder as the encoder for this model. Note that unlike the custom transformer, you don't\n",
    "            need to use an external positional embedding for the T5 transformer (i.e. don't define self.pos_emb)\n",
    "            \n",
    "            You may specify layer weights to freeze during finetuning by modifying the freeze_layers global variable\n",
    "            \"\"\"\n",
    "            self.t5_encoder = t5_model.encoder\n",
    "            \n",
    "            for i_layer, block in enumerate(self.t5_encoder.block):\n",
    "                if i_layer in freeze_layers:\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "        else:\n",
    "            self.in_embed = nn.Sequential(nn.Embedding(in_vocab.n, n_hid, padding_idx=in_vocab.pad), drop)\n",
    "            self.pos_embed = nn.Embedding(1 + n_max_in, n_hid) # Use the first position as global vector\n",
    "            self.transformer_layers = nn.ModuleList(TransformerBlock() for _ in range(n_layers))\n",
    "\n",
    "        self.gcn = GCN()\n",
    "\n",
    "        self.decoder = TreeDecoder()\n",
    "\n",
    "        if not use_t5:\n",
    "            self.apply(self.init_weight)\n",
    "\n",
    "    def init_weight(self, m):\n",
    "        if type(m) in [nn.Embedding]:\n",
    "            nn.init.normal_(m.weight, 0, 0.1)\n",
    "\n",
    "    def encode(self, in_idxs, n_in, gt_graph, attr_graph, in_mask=None):\n",
    "        in_idxs_pad = F.pad(in_idxs, (1, 0), value=in_vocab.pad)\n",
    "        if use_t5:\n",
    "            \"\"\"\n",
    "            Call your T5 encoder\n",
    "            \"\"\"\n",
    "#             h, = self.t5_encoder(in_idxs_pad)\n",
    "            h = self.t5_encoder(in_idxs_pad).last_hidden_state\n",
    "        else:\n",
    "            x = self.in_embed(in_idxs_pad) # (n_batch, n_batch_max_in, n_hid)\n",
    "            h = x + self.pos_embed(torch.arange(x.size(1), device=x.device))\n",
    "            for layer in self.transformer_layers:\n",
    "                h = layer(h, mask=in_mask)\n",
    "        zg, h = h[:, 0], h[:, 1:]\n",
    "        zbar = self.gcn(h, gt_graph, attr_graph)\n",
    "        return zbar, zg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:31:12.383238Z",
     "start_time": "2020-10-29T08:31:12.342661Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, up):\n",
    "        self.up = up\n",
    "        self.is_root = up is None\n",
    "        self.left = self.right = None\n",
    "        self.ql = self.tl = self.op = None\n",
    "\n",
    "def train(batch, model, opt):\n",
    "    n_batch = len(batch)\n",
    "\n",
    "    n_in = [d['n_in'] for d in batch]\n",
    "    pad = lambda x, value: nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=value)\n",
    "    in_idxs = pad([d['in_idxs'] for d in batch], in_vocab.pad).to(device)\n",
    "    in_mask = pad([torch.ones(n, dtype=torch.bool) for n in n_in], False).to(device)\n",
    "    nP_in_mask = pad([d['nP_in_mask'] for d in batch], False).to(device)\n",
    "    nP_out_mask = torch.stack([d['nP_out_mask'] for d in batch]).to(device)\n",
    "    \n",
    "    qcomp_graph, qcell_graph = [], []\n",
    "    for d in batch:\n",
    "        \"\"\"\n",
    "        Create qcomp_graph and qcell_graph from d['qcomp_edges'] and d['qcell_edges'] by calling dgl.graph\n",
    "        (see https://docs.dgl.ai/generated/dgl.graph.html)\n",
    "\n",
    "        Note that num_nodes needs to be set to the maximum input length in this batch\n",
    "        \"\"\"\n",
    "        qcomp_graph_i = dgl.graph(d['qcomp_edges'], num_nodes=in_idxs.size(1), device=device)\n",
    "        qcell_graph_i = dgl.graph(d['qcell_edges'], num_nodes=in_idxs.size(1), device=device)\n",
    "        \n",
    "        qcomp_graph.append(qcomp_graph_i)\n",
    "        qcell_graph.append(qcell_graph_i)\n",
    "    qcomp_graph = dgl.batch(qcomp_graph)\n",
    "    qcell_graph = dgl.batch(qcell_graph)\n",
    "    \n",
    "    label = pad([d['out_idxs'] for d in batch], out_vocab.pad)\n",
    "    nP_candidates = [d['nP_candidates'] for d in batch]\n",
    "\n",
    "    \n",
    "    zbar, qroot = model.encode(in_idxs, n_in, qcomp_graph, qcell_graph, in_mask=None)\n",
    "    z_nP = zbar.new_zeros((n_batch, n_max_nP, n_hid))\n",
    "    z_nP[nP_out_mask] = zbar[nP_in_mask]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    n_quant = out_vocab.n_constants + n_max_nP\n",
    "    quant_embed = torch.cat([decoder.constant_embedding.expand(n_batch, -1, -1), z_nP], dim=1) # (n_batch, n_quant, n_hid)\n",
    "\n",
    "    nodes = np.array([Node(None) for _ in range(n_batch)])\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "    quant_min, quant_max = out_vocab.base_quant, out_vocab.base_quant + n_quant\n",
    "\n",
    "    # Initialize root node vector according to zg (the global context)\n",
    "    qp = decoder.qp_gate(qroot)\n",
    "    scores = []\n",
    "    for i, label_i in enumerate(label.T): # Iterate over the output positions\n",
    "        Gc = decoder.gts_attention(qp, zbar, in_mask)\n",
    "        qp_Gc = torch.cat([qp, Gc], dim=1) # (n_batch, 2 * n_hid)\n",
    "\n",
    "        score = decoder.gts_predict(qp_Gc, quant_embed, nP_out_mask)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Whether the label is an operator\n",
    "        is_op = (op_min <= label_i) & (label_i < op_max)\n",
    "        # Whether the label is a quantity\n",
    "        is_quant = ((quant_min <= label_i) & (label_i < quant_max)) | (label_i == out_vocab.unk)\n",
    "\n",
    "        op_embed = decoder.op_embedding((label_i[is_op] - out_vocab.base_op).to(device))\n",
    "        qp_Gc_op = torch.cat([qp_Gc[is_op], op_embed], dim=1)\n",
    "\n",
    "        is_left = np.zeros(n_batch, dtype=np.bool)\n",
    "        qleft_qp = decoder.gts_left_qp(qp_Gc_op)\n",
    "        qleft = decoder.gts_left(qp_Gc_op)\n",
    "        for j, ql, op in zip(is_op.nonzero(as_tuple=True)[0], qleft, op_embed):\n",
    "            node = nodes[j]\n",
    "            nodes[j] = node.left = Node(node)\n",
    "            node.op = op\n",
    "            node.ql = ql\n",
    "            is_left[j] = True\n",
    "\n",
    "        is_right = np.zeros(n_batch, dtype=np.bool)\n",
    "        nP_score = score[:, out_vocab.base_nP:].detach().cpu()\n",
    "        ql_tl = []\n",
    "        for j in is_quant.nonzero(as_tuple=True)[0]:\n",
    "            if label_i[j] == out_vocab.unk:\n",
    "                candidates = nP_candidates[j][i]\n",
    "#                 label_i[j] = out_vocab.base_nP + candidates[nP_score[j, candidates].argmax()]\n",
    "                label_i[j] = torch.from_numpy(np.array(out_vocab.base_nP + candidates[nP_score[j, candidates].argmax()])).to(label_i)\n",
    "\n",
    "            node = nodes[j]\n",
    "            pnode = node.up\n",
    "            t = quant_embed[j, label_i[j] - out_vocab.base_quant]\n",
    "            while pnode and pnode.right is node:\n",
    "                t = decoder.merge_subtree(pnode.op, pnode.tl, t) # merge operator, left subtree, and right child\n",
    "                node, pnode = pnode, pnode.up # backtrack to parent node\n",
    "            if pnode is None: # Finished traversing tree of j\n",
    "                continue\n",
    "            # Now pnode.left is node. t is the tl representing the left subtree of pnode\n",
    "            pnode.tl = t\n",
    "            ql_tl.append(torch.cat([pnode.ql, pnode.tl])) # For computing qright\n",
    "            nodes[j] = pnode.right = Node(pnode)\n",
    "            is_right[j] = True\n",
    "\n",
    "        qp = torch.zeros((n_batch, n_hid), device=device)\n",
    "        qp[is_left] = qleft_qp\n",
    "        if ql_tl:\n",
    "            qp[is_right] = decoder.gts_right(torch.stack(ql_tl))\n",
    "\n",
    "    label = label.to(device).view(-1)\n",
    "    scores = torch.stack(scores, dim=1).view(-1, out_vocab.n_ops + n_quant)\n",
    "    loss = F.cross_entropy(scores, label, ignore_index=out_vocab.pad)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamNode(Node):\n",
    "    def __init__(self, up, prev, qp, token=None):\n",
    "        super().__init__(up)\n",
    "        self.prev = prev\n",
    "        self.qp = qp\n",
    "        self.token = token\n",
    "\n",
    "    def trace_tokens(self, *last_token):\n",
    "        if self.prev is None:\n",
    "            return list(last_token)\n",
    "        tokens = self.prev.trace_tokens()\n",
    "        tokens.append(self.token)\n",
    "        tokens.extend(last_token)\n",
    "        return tokens\n",
    "\n",
    "def evaluate(d, model, beam_size=5, n_max_out=45):\n",
    "    in_idxs = d['in_idxs'].unsqueeze(0).to(device=device)\n",
    "    \"\"\"\n",
    "    Create qcomp_graph and qcell_graph from d['qcomp_edges'] and d['qcell_edges'] by calling dgl.graph\n",
    "    (see https://docs.dgl.ai/generated/dgl.graph.html)\n",
    "    \"\"\"\n",
    "#     qcomp_graph = dgl.graph(d['gt_edges'], device=device)\n",
    "#     qcell_graph = dgl.graph(d['attr_edges'], device=device)\n",
    "    qcomp_graph = dgl.graph(d['qcomp_edges'], device=device)\n",
    "    qcell_graph = dgl.graph(d['qcell_edges'], device=device)\n",
    "\n",
    "    zbar, qroot = model.encode(in_idxs, [d['n_in']], qcomp_graph, qcell_graph)\n",
    "    z_nP = zbar[:, d['nP_positions']]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    quant_embed = torch.cat([decoder.constant_embedding, z_nP], dim=1) # (1, n_quant, n_hid)\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "\n",
    "    best_done_beam = (-np.inf, None, None)\n",
    "    beams = [(0, BeamNode(up=None, prev=None, qp=decoder.qp_gate(qroot)))]\n",
    "    for _ in range(n_max_out):\n",
    "        new_beams = []\n",
    "        for logp_prev, node in beams:\n",
    "            Gc = decoder.gts_attention(node.qp, zbar)\n",
    "            qp_Gc = torch.cat([node.qp, Gc], dim=1) # (2 * n_hid,)\n",
    "\n",
    "            log_prob = decoder.gts_predict(qp_Gc, quant_embed).log_softmax(dim=1)\n",
    "            top_logps, top_tokens = log_prob.topk(beam_size, dim=1)\n",
    "            for logp_token_, out_token_ in zip(top_logps.unbind(dim=1), top_tokens.unbind(dim=1)):\n",
    "                out_token = out_token_.item()\n",
    "                logp = logp_prev + logp_token_.item()\n",
    "                if op_min <= out_token < op_max:\n",
    "                    op_embed = decoder.op_embedding(out_token_)\n",
    "                    qp_Gc_op = torch.cat([qp_Gc, op_embed], dim=1)\n",
    "                    prev_node = copy(node)\n",
    "                    next_node = prev_node.left = BeamNode(\n",
    "                        up=prev_node, prev=prev_node,\n",
    "                        qp=decoder.gts_left_qp(qp_Gc_op),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                    prev_node.op = op_embed\n",
    "                    prev_node.ql = decoder.gts_left(qp_Gc_op)\n",
    "                else:\n",
    "                    pnode, prev_node = node.up, node\n",
    "                    t = quant_embed[:, out_token - out_vocab.base_quant]\n",
    "                    while pnode and pnode.tl is not None:\n",
    "                        t = decoder.merge_subtree(pnode.op, pnode.tl, t)\n",
    "                        node, pnode = pnode, pnode.up\n",
    "                    if pnode is None:\n",
    "                        best_done_beam = max(best_done_beam, (logp, prev_node, out_token))\n",
    "                        continue\n",
    "                    pnode = copy(pnode)\n",
    "                    pnode.tl = t\n",
    "                    next_node = pnode.right = BeamNode(\n",
    "                        up=pnode, prev=prev_node,\n",
    "                        qp=decoder.gts_right(torch.cat([pnode.ql, pnode.tl], dim=1)),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                new_beams.append((logp, next_node))\n",
    "        beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "        done_logp, done_node, done_last_token = best_done_beam\n",
    "        if not len(beams) or done_logp >= beams[0][0]:\n",
    "            break\n",
    "    return done_node.trace_tokens(done_last_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/question-to-topic-cleaned.json\", \"r\") as f:\n",
    "    question_to_topic = eval(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_to_topic = {'Whatisthemagnitudeofthevector[]?': 'b', 'Letaninputvectorbe[]Whatisitsmagnitude?': 'b', 'Ifx=[]whatis||x||?': 'b', 'Computethemagnitudeof[]': 'b', 'FindtheEuclidianlengthof[]': 'b', 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 'p', 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 'p', 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 'p', 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 'p', 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 'p', 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 'f', 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 'f', 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 'f', 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 'f', 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 'f', 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 'lg', 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 'lg', 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 'lg', 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 'r', 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 'r', 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 'r', 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 'r', 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 'r', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_i', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_ii', 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 'cnn', 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 'cnn', 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 'cnn', 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 'rnn', 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 'rnn', 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 'rnn', 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 'rnn', 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 'rnn', 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 'sm_mdp', 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 'rl', 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 'rl', 'Letq=AfterQlearningwhatisqifaisandtis?': 'rl', 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 'rl', 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 'rl', 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 'dtnn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_chars = {',', '.', ' ', 'negative', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "def cleaner(q):\n",
    "    for char in delete_chars:\n",
    "        q = q.replace(char, '')\n",
    "    return q\n",
    "    \n",
    "def score_model(model, test_data):\n",
    "    model.eval()\n",
    "    value_match, equation_match = [], []\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(test_data):\n",
    "            val_match = eq_match = False\n",
    "            if not d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "                try:\n",
    "                    pred = evaluate(d, model)\n",
    "                    d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                    val_match, eq_match = check_match(pred, d)\n",
    "                except:\n",
    "                    print(\"pred:\", pred, \"\\nd[processed_question]:\", d['processed_question'])\n",
    "            value_match.append(val_match)\n",
    "            equation_match.append(eq_match)\n",
    "    print(f'Test equation accuracy: {np.mean(equation_match):.3g}')\n",
    "    print(f'Test value accuracy: {np.mean(value_match):.3g}')\n",
    "    \n",
    "def score_model_detailed(model, test_data):\n",
    "    model.eval()\n",
    "    value_match, equation_match = [], []\n",
    "    correct_val_topics = []\n",
    "    correct_eqn_topics = []\n",
    "    correct_questions_val = {} # topic -> (question, answer)\n",
    "    incorrect_questions_val = {} # topic -> (question, answer)\n",
    "    topic_count_in_test = {}\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(test_data):\n",
    "            val_match = eq_match = False\n",
    "            pred_val = None\n",
    "            if not d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "                try:\n",
    "                    pred = evaluate(d, model)\n",
    "                    d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                    val_match, eq_match = check_match(pred, d)\n",
    "                    pred_val = sub_nP(d['pred_tokens'], d['nP'])\n",
    "                except:\n",
    "                    print(\"pred:\", pred, \"\\nd[processed_question]:\", d['processed_question'])\n",
    "            value_match.append(val_match)\n",
    "            equation_match.append(eq_match)\n",
    "            \n",
    "            cleaned_question_topic = question_to_topic[cleaner(d['processed_question'])]\n",
    "            topic_count_in_test[cleaned_question_topic] = topic_count_in_test.get(cleaned_question_topic, 0) + 1\n",
    "            if val_match:\n",
    "                correct_val_topics.append(cleaned_question_topic)\n",
    "                correct_questions_val[cleaned_question_topic] = correct_questions_val.get(cleaned_question_topic, []) + [(d['processed_question'], evaluate_prefix_expression(pred_val))]\n",
    "            else:\n",
    "                incorrect_questions_val[cleaned_question_topic] = incorrect_questions_val.get(cleaned_question_topic, []) + [(d['processed_question'], evaluate_prefix_expression(pred_val))]\n",
    "            if eq_match:\n",
    "                correct_eqn_topics.append(cleaned_question_topic)\n",
    "                \n",
    "    print(f'Test equation accuracy: {np.mean(equation_match):.3g}')\n",
    "    correct_eqn_topics = Counter(correct_eqn_topics)\n",
    "    correct_eqn_percents = {topic: questions_correct/topic_count_in_test[topic] for topic,questions_correct in correct_eqn_topics.items()}\n",
    "    print(f'Test equation accuracy per topic: {correct_eqn_percents}')\n",
    "          \n",
    "    print(f'Test value accuracy: {np.mean(value_match):.3g}')\n",
    "    correct_val_topics = Counter(correct_val_topics)\n",
    "    correct_val_percents = {topic: questions_correct/topic_count_in_test[topic] for topic,questions_correct in correct_val_topics.items()}\n",
    "    print(f'Test value accuracy per topic: {correct_val_percents}')\n",
    "    \n",
    "    return correct_questions_val, incorrect_questions_val\n",
    "    \n",
    "    \n",
    "def score_model_single_input_fr(model, question):\n",
    "    model.eval()\n",
    "    if question[-1] not in {'.', '?'}:\n",
    "        question += \"?\"\n",
    "    d = [{\"expression\": \"\", \"quant_cell_positions\": [i for i in range(len(question.split(\" \")))], \"processed_question\": question, \"raw_question\": question}]\n",
    "    _, input_question_data, _, _, _, _ = setup(use_t5, test_split=1, data=d)\n",
    "    tensorize_data([], input_question_data)\n",
    "    input_question = input_question_data[0]\n",
    "    pred = evaluate(input_question, model)\n",
    "    d[0]['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "    parse_tree = sub_nP(d[0]['pred_tokens'], d[0]['nP'])\n",
    "    return str(evaluate_prefix_expression(parse_tree)), parse_tree\n",
    "\n",
    "def score_model_single_input_mc(model, question, solution_tree, answers_generated=20, num_choices=4):\n",
    "    model.eval()\n",
    "    if question[-1] not in {'.', '?'}:\n",
    "        question += \"?\"\n",
    "    d = [{\"expression\": \"\", \"quant_cell_positions\": [i for i in range(len(question.split(\" \")))], \"processed_question\": question, \"raw_question\": question}]\n",
    "    _, input_question_data, _, _, _, _ = setup(use_t5, test_split=1, data=d)\n",
    "    tensorize_data([], input_question_data)\n",
    "    input_question = input_question_data[0]\n",
    "    \n",
    "    result = []\n",
    "    for _ in range(answers_generated):\n",
    "        try:\n",
    "            pred = evaluate(d, model)\n",
    "            result.append(str(pred))\n",
    "        except:\n",
    "            pass\n",
    "    counts = Counter(result)\n",
    "    counts = sorted(counts.items(), key=lambda x: eval(x[0]))\n",
    "    preds = [elt[0] for elt in sorted(counts, key=lambda x: (x[1], random.random()), reverse=True)][:min(len(counts),num_choices)]\n",
    "\n",
    "    # generate answer choices\n",
    "    correct_tree = sub_nP(solution_tree, d[0]['nP'])\n",
    "    answers, correct_answer = generate_choices(correct_tree, num_choices)\n",
    "    \n",
    "    print(f\"Correct answer: {correct_answer}\")\n",
    "    print(f\"Answers: {answers}\")\n",
    "    \n",
    "    # have model make decision\n",
    "    for try_number in range(num_choices):\n",
    "        chosen_answer = random.choice(answers)\n",
    "        for pred in preds:\n",
    "            if pred in answers:\n",
    "                chosen_answer = pred\n",
    "                break # if not chosen after iterating over all preds, keep the chosen one at random\n",
    "        del answers[answers.index(chosen_answer)]\n",
    "        print(f\"Try #{try_number+1}: {chosen_answer}\")\n",
    "        if chosen_answer == correct_answer:\n",
    "            break\n",
    "            \n",
    "            \n",
    "#     pred = evaluate(input_question, model)\n",
    "#     d[0]['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "#     parse_tree = sub_nP(d[0]['pred_tokens'], d[0]['nP'])\n",
    "#     return str(evaluate_prefix_expression(parse_tree)), parse_tree\n",
    "        \n",
    "    \n",
    "def score_model_ranking_multiple_choice(model, test_data, num_tries=2, answers_generated=20, num_choices=4):\n",
    "    model.eval()\n",
    "    value_match = []\n",
    "    tries = []\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(test_data):\n",
    "            if d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "                val_match = eq_match = False\n",
    "                try_number = num_tries - 1\n",
    "            else:\n",
    "                # generate responses\n",
    "                result = []\n",
    "                for _ in range(answers_generated):\n",
    "                    try:\n",
    "                        pred = evaluate(d, model)\n",
    "                        result.append(str(pred))\n",
    "                    except:\n",
    "                        pass\n",
    "                counts = Counter(result)\n",
    "                counts = sorted(counts.items(), key=lambda x: eval(x[0]))\n",
    "                preds = [elt[0] for elt in sorted(counts, key=lambda x: (x[1], random.random()), reverse=True)][:min(len(counts),num_tries)]\n",
    "                \n",
    "                # generate answer choices\n",
    "                correct_tree = sub_nP(d['out_tokens'], d['nP'])\n",
    "                answers, correct_answer = generate_choices(correct_tree, num_choices)\n",
    "                \n",
    "                # have model make decision\n",
    "                val_match = 0\n",
    "                for try_number in range(len(preds)):\n",
    "                    chosen_answer = random.choice(answers)\n",
    "                    for pred in preds:\n",
    "                        if pred in answers:\n",
    "                            chosen_answer = pred\n",
    "                            break # if not chosen after iterating over all preds, keep the chosen one at random\n",
    "                    del answers[answers.index(chosen_answer)]\n",
    "                    if chosen_answer == correct_answer:\n",
    "                        val_match = 1\n",
    "                        break\n",
    "            tries.append(try_number + 1)\n",
    "            value_match.append(val_match)\n",
    "    print(f'Test value accuracy: {np.mean(value_match):.3g}')\n",
    "    print(f'Avg number of tries: {np.mean(tries):.3g}')\n",
    "    \n",
    "def generate_choices(parse_tree, num_choices, operators=None):\n",
    "    if operators is None:\n",
    "        operators = {'+': np.add, '-': np.subtract, '*': np.multiply, '/': np.divide, 'm': max, 'l':math.log, '^': np.power}\n",
    "    special_values = [0.1, 0.2, 0.25, 0.4, 0.5, 0.6, 0.75, 0.8, 2, 2.5, 3, 4, 5, 6, 7.5, 8, 10]\n",
    "    correct_answer = evaluate_prefix_expression(parse_tree)\n",
    "    parse_tree = [elt if elt in operators else eval(elt) for elt in parse_tree]\n",
    "    \n",
    "    # find all other possible parse tree constructions\n",
    "    good_trees = [parse_tree]\n",
    "    bad_trees = []\n",
    "    valid_answers = []\n",
    "    for _ in range(3):\n",
    "        good_trees_size = len(good_trees)\n",
    "        for tree in good_trees:\n",
    "            for idx in range(len(tree)-4):\n",
    "                if parse_tree[idx] in operators:\n",
    "                    if parse_tree[idx+1] in operators: # zig rotation\n",
    "                        proposed_tree = zig_rotation(parse_tree, idx)\n",
    "                    if parse_tree[idx+2] in operators: # zag rotation\n",
    "                        proposed_tree = zag_rotation(parse_tree, idx)\n",
    "                    if proposed_tree not in good_trees and proposed_tree not in bad_trees:\n",
    "                        try:\n",
    "                            answer = evaluate_prefix_expression(answer_tree)\n",
    "                            good_trees.append(proposed_tree)\n",
    "                            valid_answers.append(answer)\n",
    "                        except:\n",
    "                            bad_trees.append(proposed_tree)\n",
    "        if good_trees_size == len(good_trees) or len(good_trees) > num_choices:\n",
    "            break\n",
    "\n",
    "    while len(valid_answers) < num_choices:\n",
    "        numeric_idxs = [idx for idx in range(len(parse_tree)) if parse_tree[idx] not in operators]\n",
    "        numeric_idx = random.choice(numeric_idxs)\n",
    "        parse_tree_augmented = parse_tree.copy()\n",
    "        option = random.random()\n",
    "        if option < 2/3:\n",
    "            parse_tree_augmented[numeric_idx] *= random.choice(special_values)\n",
    "        elif 1/3 < option:\n",
    "            parse_tree_augmented[numeric_idx] += random.choice(special_values)\n",
    "        else:\n",
    "            parse_tree_augmented[numeric_idx] -= random.choice(special_values)\n",
    "        try:\n",
    "            result = evaluate_prefix_expression(parse_tree_augmented)\n",
    "            if result in valid_answers or result == correct_answer:\n",
    "                continue\n",
    "            else:\n",
    "                valid_answers.append(result)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    random.shuffle(valid_answers)\n",
    "    correct_idx = int(random.random()*num_choices)\n",
    "    valid_answers[correct_idx] = correct_answer\n",
    "    return valid_answers[:num_choices], correct_answer\n",
    "    \n",
    "def zig_rotation(parse_tree, first_rotation_idx):\n",
    "    tree = parse_tree.copy()\n",
    "    tree[first_rotation_idx], tree[first_rotation_idx+1], tree[first_rotation_idx+2] = tree[first_rotation_idx+1], tree[first_rotation_idx+2], tree[first_rotation_idx]\n",
    "    return tree\n",
    "\n",
    "def zag_rotation(parse_tree, first_rotation_idx):\n",
    "    tree = parse_tree.copy()\n",
    "    tree[first_rotation_idx], tree[first_rotation_idx+1], tree[first_rotation_idx+2] = tree[first_rotation_idx+2], tree[first_rotation_idx], tree[first_rotation_idx+1]\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use_t5 = 'small' # Value should be None, 'small', or 'base'\n",
    "use_t5 = None\n",
    "\n",
    "n_max_in = 100\n",
    "n_batch = 32\n",
    "learning_rate = 1e-4\n",
    "if use_t5:\n",
    "    # T5 hyperparameters\n",
    "    n_epochs = 50\n",
    "    freeze_layers = []\n",
    "    weight_decay = 1e-5\n",
    "    n_hid = dict(small=512, base=768)[use_t5] # Do not modify unless you want to try t5-large\n",
    "else:\n",
    "    # Custom transformer hyperparameters\n",
    "    n_epochs = 8\n",
    "    n_layers = 3\n",
    "    n_hid = 512\n",
    "    n_k = n_v = 64\n",
    "    n_head = 8\n",
    "    weight_decay = 0\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 10 examples...\n",
      "\n",
      "{'expression': '(0-5/(46-32))*((5/(46-32))l2)+(0-(46-32-5)/(46-32))*(((46-32-5)/(46-32))l2)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'processed_question': 'If there are 46 points on a 2D plane , 32 of them on the right side split by a line , and 5 points on the left side that are positive , what is the entropy of the left region ?', 'raw_question': 'If there are 46 points on a 2D plane , 32 of them on the right side split by a line , and 5 points on the left side that are positive , what is the entropy of the left region ?', 'is_quadratic': False, 'Id': 28973, 'Expected': 0.9402859586706309}\n",
      "{'expression': '((0*0)+(0*0))+0', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], 'processed_question': 'What is the value of theta times x plus theta_0 if x is ( 0 0 ), theta is ( 0 0 ) , and theta_0 is 0 ?', 'raw_question': 'What is the value of theta times x plus theta_0 if x is ( 0 0 ), theta is ( 0 0 ) , and theta_0 is 0 ?', 'is_quadratic': False, 'Id': 7781, 'Expected': 0}\n",
      "{'expression': '1*((0*1)+(0.5*4))+(4*2)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], 'processed_question': 'A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 0 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 4 , and wOC is 2 ?', 'raw_question': 'A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 0 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 4 , and wOC is 2 ?', 'is_quadratic': False, 'Id': 12730, 'Expected': 10.0}\n",
      "{'expression': '(0-9/(47-26))*((9/(47-26))l2)+(0-(47-26-9)/(47-26))*(((47-26-9)/(47-26))l2)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], 'processed_question': 'There are 47 points on a 2D plane , 26 on the right side of a line and the rest on the left . 9 points on the left of the line are positive . What is the entropy of the left region ?', 'raw_question': 'There are 47 points on a 2D plane , 26 on the right side of a line and the rest on the left . 9 points on the left of the line are positive . What is the entropy of the left region ?', 'is_quadratic': False, 'Id': 29191, 'Expected': 0.9852281360342516}\n",
      "{'expression': '((((((0*1)+0)*1)+2)*1)+0)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], 'processed_question': 'What is the RNN result s_3 if s_0 is 0 , w is 1 , and x is [ 0 2 0 ] if we let s_t = w * s_t-1 + x_t ?', 'raw_question': 'What is the RNN result s_3 if s_0 is 0 , w is 1 , and x is [ 0 2 0 ] if we let s_t = w * s_t-1 + x_t ?', 'is_quadratic': False, 'Id': 20257, 'Expected': 2}\n",
      "{'expression': '4*2+2*(0-4)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], 'processed_question': 'A point p is classified by a classifier whose decision boundary is theta = ( 4 2 ) . How does it classify p , where p is ( 2 negative 4 ) ?', 'raw_question': 'A point p is classified by a classifier whose decision boundary is theta = ( 4 2 ) . How does it classify p , where p is ( 2 negative 4 ) ?', 'is_quadratic': False, 'Id': 4753, 'Expected': 0}\n",
      "{'expression': '((13^2)+(5^2)+(13^2))^0.5', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'processed_question': 'What is the magnitude of the vector [ 13 5 13 ] ?', 'raw_question': 'What is the magnitude of the vector [ 13 5 13 ] ?', 'is_quadratic': False, 'Id': 1765, 'Expected': 19.05255888325765}\n",
      "{'expression': '((1*0)+((0-1)*(0-1)))+0.25', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], 'processed_question': 'Let theta be ( 0 negative 1 ) , theta_0 be 0.25, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .', 'raw_question': 'Let theta be ( 0 negative 1 ) , theta_0 be 0.25, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .', 'is_quadratic': False, 'Id': 8802, 'Expected': 1.25}\n",
      "{'expression': '(3*15.4+8)*(3*15.4+8)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'processed_question': 'f(theta) is the square of the sum of 8 and the product of 3 and theta , where theta is 15.4 . What is f(theta) ?', 'raw_question': 'f(theta) is the square of the sum of 8 and the product of 3 and theta , where theta is 15.4 . What is f(theta) ?', 'is_quadratic': False, 'Id': 11272, 'Expected': 2937.6400000000003}\n",
      "{'expression': '3*0+2*(0-3)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], 'processed_question': 'A point p is classified by a classifier whose decision boundary is theta = ( 3 2 ) . How does it classify p , where p is ( 0 negative 3 ) ?', 'raw_question': 'A point p is classified by a classifier whose decision boundary is theta = ( 3 2 ) . How does it classify p , where p is ( 0 negative 3 ) ?', 'is_quadratic': False, 'Id': 4208, 'Expected': -6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 107.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensorizing...\n",
      "Number of items: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [03:45, 132.99it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing 10 examples...\\n\")\n",
    "train_data, test_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5, path=\"data/train-cleaned.json\")\n",
    "print(\"\\nTensorizing...\")\n",
    "tensorize_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to setup_data_split.pickle\n",
      "Saved to setup_vocab_model_t5_none.pickle\n"
     ]
    }
   ],
   "source": [
    "def save_data_split():\n",
    "    filename = 'setup_data_split.pickle'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump([train_data, test_data, n_max_nP], f)\n",
    "        print(f'Saved to {filename}')\n",
    "        \n",
    "def save_vocab_model():\n",
    "    suffix = str(use_t5) if use_t5 is not None else \"none\"\n",
    "    filename = f'setup_vocab_model_t5_{suffix}.pickle'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump([in_vocab, out_vocab, t5_model], f)\n",
    "        print(f'Saved to {filename}')\n",
    "if not use_t5:\n",
    "    save_data_split() # if using T5, no need to save data split again\n",
    "save_vocab_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening setup_data_split.pickle\n",
      "Opening setup_vocab_model_t5_none.pickle\n"
     ]
    }
   ],
   "source": [
    "def load_data_split():\n",
    "    with open('setup_data_split.pickle', 'rb') as f:\n",
    "        print(\"Opening setup_data_split.pickle\")\n",
    "        return pickle.load(f)\n",
    "        \n",
    "def load_vocab_model():\n",
    "    suffix = str(use_t5) if use_t5 is not None else \"none\"\n",
    "    filename = f'setup_vocab_model_t5_{suffix}.pickle'\n",
    "    with open(filename, 'rb') as f:\n",
    "        print(f\"Opening {filename}\")\n",
    "        return pickle.load(f)\n",
    "train_data, test_data, n_max_nP = load_data_split()\n",
    "in_vocab, out_vocab, t5_model = load_vocab_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [13:55<00:00,  1.11s/it]\n",
      "  0%|          | 1/6000 [00:00<11:10,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.034298973206430675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [11:30<00:00,  8.69it/s]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy: 0.942\n",
      "Test equation accuracy per topic: {'sm_mdp': 0.7683168316831683, 'nn_ii': 0.8455445544554455, 'nn_i': 0.904, 'dtnn': 1.0, 'p': 0.919917864476386, 'r': 1.0, 'f': 1.0, 'b': 1.0, 'rnn': 1.0, 'cnn': 0.9680638722554891, 'rl': 1.0, 'lr': 0.8942115768463074}\n",
      "Test value accuracy: 0.964\n",
      "Test value accuracy per topic: {'sm_mdp': 1.0, 'nn_ii': 0.8633663366336634, 'nn_i': 0.916, 'dtnn': 1.0, 'p': 0.919917864476386, 'r': 1.0, 'f': 1.0, 'b': 1.0, 'rnn': 1.0, 'cnn': 0.9680638722554891, 'rl': 1.0, 'lr': 0.8982035928143712}\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 224/750 [04:08<09:43,  1.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-eb2679ec2dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6b7597cb49f0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batch, model, opt)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant_embed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mout_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_quant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mpnode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_subtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# merge operator, left subtree, and right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup\u001b[0m \u001b[0;31m# backtrack to parent node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Finished traversing tree of j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d7f04308dbde>\u001b[0m in \u001b[0;36mmerge_subtree\u001b[0;34m(self, op, tl, yr)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_subtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtree_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d7f04308dbde>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTreeDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/model-6-t5_none_cleanedx2.pth\"))\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "model.to(device)\n",
    "\n",
    "epoch = 6\n",
    "while epoch < n_epochs:\n",
    "    print('Epoch:', epoch + 1)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for start in trange(0, int(len(train_data)), n_batch):\n",
    "        batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "        loss = train(batch, model, opt)\n",
    "        losses.append(loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    print('Training loss:', np.mean(losses))\n",
    "\n",
    "    epoch += 1\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'models/model-{epoch}-t5_{str(use_t5) if use_t5 is not None else \"none\"}_cleanedx2.pth')\n",
    "        score_model_detailed(model, test_data)\n",
    "#         score_model_ranking_multiple_choice(model, test_data[:int(len(test_data)/1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "# model.load_state_dict(torch.load(\"models/model-5-t5_none_cleaned.pth\"))\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/model-8-t5_none_cleanedx2.pth\"))\n",
    "\n",
    "# model.load_state_dict(torch.load(\"models/model-5-t5_none.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-10-t5_none.pth\"))\n",
    "\n",
    "# model.load_state_dict(torch.load(\"models/model-5-t5_small.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-10-t5_small.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-20-t5_small.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-30-t5_small.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-35-t5_small.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-40-t5_small.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-50-t5_small.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [11:09<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy: 0.981\n",
      "Test value accuracy: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score_model(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [11:19<00:00,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy: 0.97\n",
      "Test equation accuracy per topic: {'sm_mdp': 1.0, 'nn_ii': 0.8831683168316832, 'nn_i': 0.916, 'dtnn': 1.0, 'p': 0.9240246406570842, 'r': 1.0, 'f': 1.0, 'b': 1.0, 'rnn': 1.0, 'rl': 1.0, 'lr': 0.9540918163672655, 'cnn': 0.9600798403193613}\n",
      "Test value accuracy: 0.972\n",
      "Test value accuracy per topic: {'sm_mdp': 1.0, 'nn_ii': 0.900990099009901, 'nn_i': 0.924, 'dtnn': 1.0, 'p': 0.9240246406570842, 'r': 1.0, 'f': 1.0, 'b': 1.0, 'rnn': 1.0, 'rl': 1.0, 'lr': 0.9540918163672655, 'cnn': 0.9600798403193613}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_questions_val, incorrect_questions_val = score_model_detailed(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A left region has 8 points classified as positive. There are 45 points in the plane , and 25 points on the left . Compute the entropy .',\n",
       "  0.904381457724494),\n",
       " ('Calculate the entropy of the left region of a 2D plane, split by a line . There are 9 points on the left side that are positive , 23 points on the right side , and 47 points total .',\n",
       "  0.9544340029249649),\n",
       " ('Consider a 1D classification line on a 2D plane . There is a total of 47 points, 28 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?',\n",
       "  0.6292492238560345),\n",
       " ('Consider a plane of 48 points , 26 of which are on the left side . Of the points on the left , 10 points are positive . Find the entropy of the left side .',\n",
       "  0.961236604722876),\n",
       " ('Given 45 points on a plane , 28 of them are on the right side of a line , and 5 of them that are on the left side are positive . Compute the entropy of the left side .',\n",
       "  0.8739810481273578),\n",
       " ('If a region has 27 points on the left and 44 points total . 4 points that are on the left are positive. Compute the entropy .',\n",
       "  0.6051865766334206),\n",
       " ('If there are 46 points on a 2D plane , 29 of them on the right side split by a line , and 7 points on the left side that are positive , what is the entropy of the left region ?',\n",
       "  0.9774178175281716),\n",
       " ('The left side of a region has 25 points . Of the 25 points , 2 are classified as positive . What is the entropy of the left region if there are 47 points in total ?',\n",
       "  0.4021791902022729),\n",
       " ('There are 45 points on a 2D plane , 24 on the right side of a line and the rest on the left . 9 points on the left of the line are positive . What is the entropy of the left region ?',\n",
       "  0.9852281360342516),\n",
       " ('What is the entropy of the left side of a region containing 27 points where the plane has 47 points in total and 4 points on the left are positive ?',\n",
       "  0.6051865766334206)}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b, p, f, lr, r, nni, nnii, cnn, sm_mdp, rl, rnn, dtnn\n",
    "def get_examples(topic_str):\n",
    "seen = set()\n",
    "show = set()\n",
    "\n",
    "topic = \"dtnn\"\n",
    "datas = correct_questions_val[topic]\n",
    "random.shuffle(datas)\n",
    "for d in datas:\n",
    "    if cleaner(d[0]) not in seen:\n",
    "        show.add(d)\n",
    "        seen.add(cleaner(d[0]))\n",
    "show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cnn': [('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 3 and I has length 6?',\n",
       "   3.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 1 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 1 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 1 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 6?',\n",
       "   4.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 1 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 3 and I has length 6?',\n",
       "   3.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 6?',\n",
       "   4.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 3 and I has length 6?',\n",
       "   3.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 6?',\n",
       "   4.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 2 and I has length 3?',\n",
       "   1.0),\n",
       "  ('What is the length of the result from applying F to I if F has length 3 and I has length 6?',\n",
       "   3.0)],\n",
       " 'nn_i': [('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   7.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   4.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   16.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   14.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   14.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   9.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   10.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   14.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   8.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   16.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   10.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   4.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   14.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   13.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   12.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   3.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   8.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   2.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   6.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   14.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   7.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   14.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   2.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   8.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   5.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   6.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   6.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   4.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   10.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   9.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   8.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   9.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   5.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   20.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   12.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   4.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   5.0),\n",
       "  ('Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 2 .',\n",
       "   12.0)],\n",
       " 'lr': [('Let theta be ( 0 1 ) , theta_0 be 0, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   -2.0),\n",
       "  ('Let theta be ( negative 2 1 ) , theta_0 be negative 1, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   -5.0),\n",
       "  ('If we have x equals ( 1 negative 1 ), theta equals ( 1 negative 1 ), and theta_0 equals negative 3 , then what is the result of theta times x plus theta_0 ?',\n",
       "   1.0),\n",
       "  ('Let theta be ( 2 0 ) , theta_0 be 18, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   6.0),\n",
       "  ('Let theta be ( 0 2 ) , theta_0 be 18, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   4.0),\n",
       "  ('Let theta be ( 1 negative 1 ) , theta_0 be negative 1, and x be ( 0 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   -3.0),\n",
       "  ('Let theta be ( 2 0 ) , theta_0 be negative 1, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   -5.0),\n",
       "  ('Let theta be ( 1 negative 2 ) , theta_0 be negative 1, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   -4.0),\n",
       "  ('Let theta be ( 1 negative 1 ) , theta_0 be 18, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   1.25),\n",
       "  ('Let theta be ( negative 2 1 ) , theta_0 be 0, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   1.0),\n",
       "  ('Let theta be ( 0 1 ) , theta_0 be 18, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   0.25),\n",
       "  ('Let theta be ( 1 negative 1 ) , theta_0 be 18, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   2.25),\n",
       "  ('Let theta be ( 0 0 ) , theta_0 be negative 1, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   -3.0),\n",
       "  ('Let theta be ( 0 negative 1 ) , theta_0 be 18, and x be ( 0 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   0.25),\n",
       "  ('Let theta be ( 2 0 ) , theta_0 be 18, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   8.0),\n",
       "  ('Let theta be ( 1 negative 2 ) , theta_0 be 18, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   2.25),\n",
       "  ('Let theta be ( 0 negative 1 ) , theta_0 be 18, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   1.25),\n",
       "  ('Let theta be ( 1 0 ) , theta_0 be negative 1, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   -2.0),\n",
       "  ('Let theta be ( 1 negative 2 ) , theta_0 be 18, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   3.25),\n",
       "  ('Let theta be ( 0 1 ) , theta_0 be 0, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   -2.0),\n",
       "  ('Let theta be ( negative 2 1 ) , theta_0 be negative 1, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   -1.0),\n",
       "  ('Let theta be ( negative 2 1 ) , theta_0 be 18, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .',\n",
       "   -0.75),\n",
       "  ('Let theta be ( negative 2 1 ) , theta_0 be 18, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .',\n",
       "   2.25)],\n",
       " 'p': [('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 4 1 ) and p is ( 1 negative 3 ) ?',\n",
       "   2.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 4 2 ) , how does it classify point p , where p is equal to ( 1 negative 4 ) ?',\n",
       "   -2.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 3 ) and p is ( 1 negative 2 ) ?',\n",
       "   -1.0),\n",
       "  ('A point p is classified by a classifier whose decision boundary is theta = ( 4 3 ) . How does it classify p , where p is ( 1 negative 2 ) ?',\n",
       "   1.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 3 3 ) , how does it classify point p , where p is equal to ( 1 negative 3 ) ?',\n",
       "   -3.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 3 4 ) and p is ( 2 negative 3 ) ?',\n",
       "   2.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 2 negative 4 ) ?',\n",
       "   -7.0),\n",
       "  ('A classifier has a decision boundary where theta is ( 3 4 ) . What value does it classify p , where p is ( 1 negative 3 ) ?',\n",
       "   -5.0),\n",
       "  ('A point p is classified by a classifier whose decision boundary is theta = ( 4 4 ) . How does it classify p , where p is ( 1 negative 3 ) ?',\n",
       "   -4.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 4 3 ) , how does it classify point p , where p is equal to ( 1 negative 2 ) ?',\n",
       "   1.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 3 1 ) , how does it classify point p , where p is equal to ( 1 negative 4 ) ?',\n",
       "   0.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 3 2 ) and p is ( 1 negative 3 ) ?',\n",
       "   -1.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 3 4 ) and p is ( 1 negative 4 ) ?',\n",
       "   -9.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 1 4 ) and p is ( 1 negative 3 ) ?',\n",
       "   -7.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 2 4 ) , how does it classify point p , where p is equal to ( 3 negative 4 ) ?',\n",
       "   -2.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 4 1 ) and p is ( 1 negative 2 ) ?',\n",
       "   3.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 3 4 ) and p is ( 1 negative 2 ) ?',\n",
       "   -1.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 1 ) and p is ( 1 negative 3 ) ?',\n",
       "   0.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 2 1 ) , how does it classify point p , where p is equal to ( 1 negative 3 ) ?',\n",
       "   0.0),\n",
       "  ('A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 1 negative 4 ) ?',\n",
       "   -8.0),\n",
       "  ('How does a classifier with decision boundary theta classify a point p if theta is ( 1 3 ) and p is ( 2 negative 4 ) ?',\n",
       "   -7.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 2 3 ) , how does it classify point p , where p is equal to ( 2 negative 3 ) ?',\n",
       "   1.0),\n",
       "  ('A classifier has a decision boundary where theta is ( 2 1 ) . What value does it classify p , where p is ( 2 negative 2 ) ?',\n",
       "   3.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 3 3 ) , how does it classify point p , where p is equal to ( 2 negative 4 ) ?',\n",
       "   0.0),\n",
       "  ('How does a classifier with decision boundary theta classify a point p if theta is ( 1 2 ) and p is ( 2 negative 2 ) ?',\n",
       "   0.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 3 negative 3 ) ?',\n",
       "   -3.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 2 ) and p is ( 1 negative 3 ) ?',\n",
       "   -2.0),\n",
       "  ('A classifier has a decision boundary where theta is ( 3 2 ) . What value does it classify p , where p is ( 3 negative 3 ) ?',\n",
       "   7.0),\n",
       "  ('How does a classifier with decision boundary theta classify a point p if theta is ( 1 3 ) and p is ( 3 negative 3 ) ?',\n",
       "   -3.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 4 ) and p is ( 1 negative 4 ) ?',\n",
       "   -10.0),\n",
       "  ('How does a classifier with decision boundary theta classify a point p if theta is ( 1 2 ) and p is ( 2 negative 3 ) ?',\n",
       "   -2.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 2 negative 3 ) ?',\n",
       "   -4.0),\n",
       "  ('A point p is classified by a classifier whose decision boundary is theta = ( 2 4 ) . How does it classify p , where p is ( 1 negative 2 ) ?',\n",
       "   -2.0),\n",
       "  ('A point p is classified by a classifier whose decision boundary is theta = ( 2 4 ) . How does it classify p , where p is ( 1 negative 3 ) ?',\n",
       "   -6.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 4 3 ) and p is ( 1 negative 4 ) ?',\n",
       "   -5.0),\n",
       "  ('If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 3 1 ) and p is ( 1 negative 3 ) ?',\n",
       "   1.0),\n",
       "  ('If the decision bounary of a classifier is theta , where theta is equal to ( 1 2 ) , how does it classify point p , where p is equal to ( 2 negative 2 ) ?',\n",
       "   0.0)],\n",
       " 'nn_ii': [('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 5 . Neuron B has input 1 and offset 1 . Neuron A has input 2 and offset 1 with offset 0.5 .',\n",
       "   13.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   9.0),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 5 . Neuron B has input 2 and offset 1 . Neuron A has input 2 and offset 1 with offset 0.5 .',\n",
       "   15.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   11.0),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 2 . Neuron B has input 0 and offset 1 . Neuron A has input 4 and offset 1 with offset 0.5 .',\n",
       "   12.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   16.5),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 4 . Neuron B has input 0 and offset 1 . Neuron A has input 4 and offset 1 with offset 0.5 .',\n",
       "   14.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   3.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   15.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   14.0),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 4 . Neuron B has input 1 and offset 1 . Neuron A has input 2 and offset 1 with offset 0.5 .',\n",
       "   12.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   3.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   16.0),\n",
       "  ('Neuron A takes in value 4 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .',\n",
       "   33.5),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 3 . Neuron B has input 2 and offset 1 . Neuron A has input 2 and offset 1 with offset 0.5 .',\n",
       "   13.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   15.0),\n",
       "  ('Neuron A takes in value 4 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 1 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 4 and a ReLU on its output . Compute the output of this neural network .',\n",
       "   16.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   8.0),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 1 . Neuron B has input 3 and offset 1 . Neuron A has input 2 and offset 1 with offset 0.5 .',\n",
       "   13.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   7.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 3 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   3.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   12.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   23.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   19.5),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 4 . Neuron B has input 3 and offset 1 . Neuron A has input 4 and offset 1 with offset 0.5 .',\n",
       "   20.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   7.0),\n",
       "  ('Neuron A takes in value 4 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 1 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .',\n",
       "   17.5),\n",
       "  ('Neuron A takes in value 4 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 3 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 4 and a ReLU on its output . Compute the output of this neural network .',\n",
       "   24.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   15.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 3 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   9.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   10.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   8.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   13.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   9.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   11.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   2.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   17.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 0 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   3.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   4.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 3 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   3.0),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 3 . Neuron B has input 3 and offset 1 . Neuron A has input 2 and offset 1 with offset 0.5 .',\n",
       "   15.5),\n",
       "  ('Neuron A takes in value 4 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .',\n",
       "   17.5),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 2 . Neuron B has input 3 and offset 1 . Neuron A has input 2 and offset 1 with offset 0.5 .',\n",
       "   14.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   17.0),\n",
       "  ('Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 2 . Neuron B has input 4 and offset 1 . Neuron A has input 4 and offset 1 with offset 0.5 .',\n",
       "   20.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   16.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   10.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   13.5),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 2 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   8.0),\n",
       "  ('Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 4 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOC being 3 .',\n",
       "   7.0)]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_questions_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Own Input: Free Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 772.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expression': '', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'processed_question': 'What is the magnitude of the vector [ 1 ]?', 'raw_question': 'What is the magnitude of the vector [ 1 ]?'}\n",
      "Number of items: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1.7320508075688772',\n",
       " ['^', '+', '+', '^', '1', '2', '^', '1', '2', '^', '1', '2', '0.5'])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model_single_input_fr(model, \"What is the magnitude of the vector [ 1 ]?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 195.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expression': '', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'processed_question': 'A classifier has a decision boundary where theta is ( 0 1 ) . What value does it classify p , where p is ( 2 negative 4 ) ?', 'raw_question': 'A classifier has a decision boundary where theta is ( 0 1 ) . What value does it classify p , where p is ( 2 negative 4 ) ?'}\n",
      "Number of items: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('-4.0', ['-', '+', '*', '0', '2', '*', '1', '0', '4'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model_single_input_fr(model, \"A classifier has a decision boundary where theta is ( 0 1 ) . What value does it classify p , where p is ( 2 negative 4 ) ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Own Input: Multiple Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 835.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expression': '', 'quant_cell_positions': [0, 1, 2, 3, 4, 5], 'processed_question': 'magnitude [ 1 1 1 ]?', 'raw_question': 'magnitude [ 1 1 1 ]?'}\n",
      "Number of items: 1\n",
      "Correct answer: 1.4142135623730951\n",
      "Answers: [1.0352649238413776, 1.118033988749895, 10.04987562112089, 2.0, 1.5620499351813308, 1.4866068747318506, 1.8027756377319946, 4.0, 1.0307764064044151, 7.566372975210778, 2.0155644370746373, 1.4142135623730951, 1.2806248474865698, 6.082762530298219, 3.1622776601683795, 9.055385138137417, 8.0, 1.189207115002721, 1.3195079107728942, 1.019803902718557, 1.886796226411321, 2.692582403567252, 1.6007810593582121, 2.0591260281974, 1.0905077326652577, 11.313708498984761, 1.148698354997035, 32.0, 2.378414230005442, 1.077032961426901, 2.8284271247461903, 1.16619037896906, 1.0717734625362931, 4.123105625617661, 362.03867196751236, 1.2311444133449163, 5.0990195135927845, 16.0, 1.25, 8.06225774829855]\n",
      "Try #1: 1.077032961426901\n",
      "Try #2: 4.123105625617661\n",
      "Try #3: 2.692582403567252\n",
      "Try #4: 16.0\n",
      "Try #5: 2.0591260281974\n",
      "Try #6: 1.4866068747318506\n",
      "Try #7: 2.8284271247461903\n",
      "Try #8: 1.2311444133449163\n",
      "Try #9: 1.4142135623730951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"magnitude [ 1 1 1 ]?\"\n",
    "solution = ['^', '+', '^', '1', '2', '^', '1', '2', '0.5']\n",
    "solutions_generated = 1\n",
    "num_tries = 40\n",
    "score_model_single_input_mc(model, question, solution, solutions_generated, num_tries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix Code (calculate percent error for each topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_val_2 = []\n",
    "wrong_eqn_2 = []\n",
    "for elt in wrong_val:\n",
    "    elt = elt.replace(\",\",\"\")\n",
    "    elt = elt.replace(\".\", \"\")\n",
    "    elt = elt.replace(\" \",\"\")\n",
    "    elt = elt.replace(\"negative\", \"\")\n",
    "    elt = elt.replace(\"-\", \"\")\n",
    "    for i in range(10):\n",
    "        elt = elt.replace(str(i),\"\")\n",
    "    wrong_val_2.append(elt)\n",
    "for elt in wrong_eqn:\n",
    "    elt = elt.replace(\",\",\"\")\n",
    "    elt = elt.replace(\".\", \"\")\n",
    "    elt = elt.replace(\" \",\"\")\n",
    "    elt = elt.replace(\"negative\", \"\")\n",
    "    elt = elt.replace(\"-\", \"\")\n",
    "    for i in range(10):\n",
    "        elt = elt.replace(str(i),\"\")\n",
    "    wrong_eqn_2.append(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_val_counts = dict()\n",
    "wrong_eqn_counts = dict()\n",
    "for elt in wrong_val_2:\n",
    "    wrong_val_counts[elt] = wrong_val_counts.get(elt, 0) + 1\n",
    "for elt in wrong_eqn_2:\n",
    "    wrong_eqn_counts[elt] = wrong_eqn_counts.get(elt, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ifx=[]whatis||x||?': 102,\n",
       " 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 125,\n",
       " 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 104,\n",
       " 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 99,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 512,\n",
       " 'FindtheEuclidianlengthof[]': 98,\n",
       " 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 90,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 510,\n",
       " 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 94,\n",
       " 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 126,\n",
       " 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 97,\n",
       " 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 93,\n",
       " 'Letq=AfterQlearningwhatisqifaisandtis?': 91,\n",
       " 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 503,\n",
       " 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 496,\n",
       " 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 101,\n",
       " 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 93,\n",
       " 'Computethemagnitudeof[]': 115,\n",
       " 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 82,\n",
       " 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 97,\n",
       " 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 104,\n",
       " 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 94,\n",
       " 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 112,\n",
       " 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 94,\n",
       " 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 96,\n",
       " 'Whatisthemagnitudeofthevector[]?': 108,\n",
       " 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 90,\n",
       " 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 97,\n",
       " 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 94,\n",
       " 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 103,\n",
       " 'Letaninputvectorbe[]Whatisitsmagnitude?': 93,\n",
       " 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 92,\n",
       " 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 95,\n",
       " 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 84,\n",
       " 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 80,\n",
       " 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 83,\n",
       " 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 94,\n",
       " 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 95,\n",
       " 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 83,\n",
       " 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 19,\n",
       " 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 110,\n",
       " 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 82,\n",
       " 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 77,\n",
       " 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 13}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ifx=[]whatis||x||?': 108,\n",
       " 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 125,\n",
       " 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 104,\n",
       " 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 99,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 512,\n",
       " 'FindtheEuclidianlengthof[]': 98,\n",
       " 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 90,\n",
       " 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 96,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 510,\n",
       " 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 94,\n",
       " 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 126,\n",
       " 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 89,\n",
       " 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 97,\n",
       " 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 93,\n",
       " 'Letq=AfterQlearningwhatisqifaisandtis?': 91,\n",
       " 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 113,\n",
       " 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 503,\n",
       " 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 496,\n",
       " 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 101,\n",
       " 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 93,\n",
       " 'Computethemagnitudeof[]': 115,\n",
       " 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 90,\n",
       " 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 97,\n",
       " 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 94,\n",
       " 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 112,\n",
       " 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 94,\n",
       " 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 96,\n",
       " 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 110,\n",
       " 'Whatisthemagnitudeofthevector[]?': 108,\n",
       " 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 90,\n",
       " 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 97,\n",
       " 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 94,\n",
       " 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 103,\n",
       " 'Letaninputvectorbe[]Whatisitsmagnitude?': 93,\n",
       " 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 97,\n",
       " 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 92,\n",
       " 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 95,\n",
       " 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 84,\n",
       " 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 99,\n",
       " 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 102,\n",
       " 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 108,\n",
       " 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 100,\n",
       " 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 110,\n",
       " 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 82}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_eqn_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_to_topic = {'Whatisthemagnitudeofthevector[]?': 'b', 'Letaninputvectorbe[]Whatisitsmagnitude?': 'b', 'Ifx=[]whatis||x||?': 'b', 'Computethemagnitudeof[]': 'b', 'FindtheEuclidianlengthof[]': 'b', 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 'p', 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 'p', 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 'p', 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 'p', 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 'p', 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 'f', 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 'f', 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 'f', 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 'f', 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 'f', 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 'lg', 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 'lg', 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 'lg', 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 'r', 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 'r', 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 'r', 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 'r', 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 'r', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_i', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_ii', 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 'cnn', 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 'cnn', 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 'cnn', 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 'rnn', 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 'rnn', 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 'rnn', 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 'rnn', 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 'rnn', 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 'sm_mdp', 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 'rl', 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 'rl', 'Letq=AfterQlearningwhatisqifaisandtis?': 'rl', 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 'rl', 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 'rl', 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 'dtnn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_to_wrong_val = dict()\n",
    "topic_to_wrong_eqn = dict()\n",
    "for question in wrong_val_counts:\n",
    "    topic = question_to_topic[question]\n",
    "    topic_to_wrong_val[topic] = topic_to_wrong_val.get(topic, 0) + wrong_val_counts[question]\n",
    "for question in wrong_eqn_counts:\n",
    "    topic = question_to_topic[question]\n",
    "    topic_to_wrong_eqn[topic] = topic_to_wrong_eqn.get(topic, 0) + wrong_eqn_counts[question]\n",
    "topic_to_wrong_val_percent_correct = {k:1 - topic_to_wrong_val[k]/len(test_data) for k in topic_to_wrong_val}\n",
    "topic_to_wrong_eqn_percent_correct = {k:1 - topic_to_wrong_eqn[k]/len(test_data) for k in topic_to_wrong_eqn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Rates per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8497435897435898\n",
      "0.9205555555555556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b': 0.914,\n",
       " 'p': 0.9173333333333333,\n",
       " 'f': 0.9183333333333333,\n",
       " 'rl': 0.9443333333333334,\n",
       " 'nn_i': 0.9146666666666666,\n",
       " 'lg': 0.9235,\n",
       " 'nn_ii': 0.915,\n",
       " 'r': 0.916,\n",
       " 'cnn': 0.924,\n",
       " 'dtnn': 0.9161666666666667,\n",
       " 'sm_mdp': 0.9173333333333333,\n",
       " 'rnn': 0.926}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum([topic_to_wrong_val_percent_correct[elt] for elt in topic_to_wrong_val_percent_correct])/(len(topic_to_wrong_val_percent_correct)+1))\n",
    "print(sum([topic_to_wrong_val_percent_correct[elt] for elt in topic_to_wrong_val_percent_correct])/(len(topic_to_wrong_val_percent_correct)))\n",
    "topic_to_wrong_val_percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n",
      "0.9166666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b': 0.913,\n",
       " 'p': 0.9173333333333333,\n",
       " 'f': 0.9183333333333333,\n",
       " 'rl': 0.9151666666666667,\n",
       " 'nn_i': 0.9146666666666666,\n",
       " 'lg': 0.9213333333333333,\n",
       " 'cnn': 0.9196666666666666,\n",
       " 'nn_ii': 0.915,\n",
       " 'r': 0.916,\n",
       " 'rnn': 0.916,\n",
       " 'dtnn': 0.9161666666666667,\n",
       " 'sm_mdp': 0.9173333333333333}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum([topic_to_wrong_eqn_percent_correct[elt] for elt in topic_to_wrong_eqn_percent_correct])/(len(topic_to_wrong_eqn_percent_correct)+1))\n",
    "print(sum([topic_to_wrong_eqn_percent_correct[elt] for elt in topic_to_wrong_eqn_percent_correct])/(len(topic_to_wrong_eqn_percent_correct)))\n",
    "topic_to_wrong_eqn_percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percent Correct')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_keys_val = sorted(tuple(topic_to_wrong_val_percent_correct),reverse=True,key=lambda x: topic_to_wrong_val_percent_correct[x])\n",
    "# sorted_keys_eqn = sorted(tuple(topic_to_wrong_eqn_percent_correct),reverse=True,key=lambda x: topic_to_wrong_eqn_percent_correct[x])\n",
    "plot = pd.DataFrame({\"Value Accuracy\": [topic_to_wrong_val_percent_correct[key] for key in sorted_keys_val],\"Equation Accuracy\": [topic_to_wrong_eqn_percent_correct[key] for key in sorted_keys_val]}, index=sorted_keys_val).plot(kind=\"bar\",title=\"Test Accuracy by Topic\",figsize=(8, 4))\n",
    "plot.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Percent Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-40bfd8a5af52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_to_wrong_val_percent_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Topic to Percentage Correct (Value Accuracy)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_plot' is not defined"
     ]
    }
   ],
   "source": [
    "generate_plot(topic_to_wrong_val_percent_correct,\"Topic to Percentage Correct (Value Accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_plot(topic_to_wrong_eqn_percent_correct,\"Topic to Percentage Correct (Equation Accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
