{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Machine Learning Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece==0.1.91\n",
      "  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.91\n",
      "    Uninstalling sentencepiece-0.1.91:\n",
      "      Successfully uninstalled sentencepiece-0.1.91\n",
      "Successfully installed sentencepiece-0.1.91\n",
      "Requirement already satisfied: transformers in /home/sunnyt/anaconda3/lib/python3.8/site-packages (4.4.2)\n",
      "Requirement already satisfied: filelock in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: packaging in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: click in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: six in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Collecting dgl\n",
      "  Downloading dgl-0.6.0.post1-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (2.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (2.24.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from dgl) (1.19.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from networkx>=2.1->dgl) (4.4.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (1.25.11)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-0.6.0.post1\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.9.1-cp38-cp38-manylinux1_x86_64.whl (17.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.4 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/sunnyt/anaconda3/lib/python3.8/site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install 'sentencepiece==0.1.91' --force-reinstall\n",
    "!pip install transformers\n",
    "!pip install dgl\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer,T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:38:46.536166Z",
     "start_time": "2020-10-29T08:38:37.253954Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "## Needs: pytorch, dgl, transformers, Python>=3.7\n",
    "\n",
    "from copy import copy\n",
    "from tqdm import tqdm, trange\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "false = False\n",
    "true = True\n",
    "NaN = float(\"NaN\")\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from util import setup, check_match, evaluate_prefix_expression, sub_nP # get_quant_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Inputs to Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:30:17.523815Z",
     "start_time": "2020-10-29T08:30:17.503632Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensorize_data(train_data, test_data):\n",
    "    print(f\"Number of items: {len(train_data)+len(test_data)}\")\n",
    "    for d in tqdm(itertools.chain(train_data, test_data)):\n",
    "        d['in_idxs'] = torch.tensor([in_vocab.token2idx.get(x, in_vocab.unk) for x in d['in_tokens']])\n",
    "        d['out_idxs'] = torch.tensor([out_vocab.token2idx.get(x, out_vocab.unk) for x in d['out_tokens']])\n",
    "        d['n_in'] = n_in = len(d['in_idxs'])\n",
    "        d['n_out'] = len(d['out_idxs'])\n",
    "        d['n_nP'] = n_nP = len(d['nP'])\n",
    "        d['nP_in_mask'] = mask = torch.zeros(n_in, dtype=torch.bool)\n",
    "        mask[d['nP_positions']] = True\n",
    "        d['nP_out_mask'] = mask = torch.zeros(n_max_nP, dtype=torch.bool)\n",
    "        mask[:n_nP] = True\n",
    "        d['qcomp_edges'] = get_quantity_comparison_edges(d)\n",
    "        d['qcell_edges'] = get_quantity_cell_edges(d)\n",
    "\n",
    "def get_quantity_comparison_edges(d):\n",
    "    quants = [float(x) for x in d['nP']]\n",
    "    quant_positions = d['nP_positions']\n",
    "#     assert max(quant_positions) < d['n_in']\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=np.bool)\n",
    "    for x, x_pos in zip(quants, quant_positions):\n",
    "        for y, y_pos in zip(quants, quant_positions):\n",
    "            adj_matrix[x_pos, y_pos] |= x > y\n",
    "    \"\"\"\n",
    "    Convert the adjacency matrix of the directed graph into a tuple of (src_edges, dst_edges), which\n",
    "    is the input format of dgl.graph (see https://docs.dgl.ai/generated/dgl.graph.html).\n",
    "    Hint: check out the 'nonzero' function\n",
    "    \"\"\"\n",
    "    return adj_matrix.nonzero(as_tuple=True)\n",
    "\n",
    "def get_quantity_cell_edges(d):\n",
    "    in_idxs = d['in_idxs']\n",
    "    quant_positions = d['nP_positions']\n",
    "    quant_cell_positions = d['quant_cell_positions']\n",
    "    assert max(quant_cell_positions) < d['n_in']\n",
    "    word_cells = set(quant_cell_positions) - set(quant_positions)\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=torch.bool)\n",
    "    for w_pos in word_cells:\n",
    "        for q_pos in quant_positions:\n",
    "            if abs(w_pos - q_pos) < 4:\n",
    "                adj_matrix[w_pos, q_pos] = adj_matrix[q_pos, w_pos] = True\n",
    "    pos_idxs = in_idxs[quant_cell_positions]\n",
    "    for idx1, pos1 in zip(pos_idxs, quant_cell_positions):\n",
    "        for idx2, pos2 in zip(pos_idxs, quant_cell_positions):\n",
    "            if idx1 == idx2:\n",
    "                adj_matrix[pos1, pos2] = adj_matrix[pos2, pos1] = True\n",
    "    \"\"\"\n",
    "    Convert the adjacency matrix of the directed graph into a tuple of (src_edges, dst_edges), which\n",
    "    is the input format of dgl.graph (see https://docs.dgl.ai/generated/dgl.graph.html).\n",
    "    Hint: check out the 'nonzero' function\n",
    "    \"\"\"\n",
    "    return adj_matrix.nonzero(as_tuple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     102
    ]
   },
   "outputs": [],
   "source": [
    "class TransformerAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Used in Transformer Block\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qkv = nn.Linear(n_hid, n_head * (n_k * 2 + n_v))\n",
    "        self.out = nn.Linear(n_head * n_v, n_hid)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        n_batch, n_batch_max_in, n_hid = x.shape\n",
    "        q_k_v = self.qkv(x).view(n_batch, n_batch_max_in, n_head, 2 * n_k + n_v).transpose(1, 2)\n",
    "        q, k, v = q_k_v.split([n_k, n_k, n_v], dim=-1)\n",
    "\n",
    "        q = q.reshape(n_batch * n_head, n_batch_max_in, n_k)\n",
    "        k = k.reshape_as(q).transpose(1, 2)\n",
    "        qk = q.bmm(k) / np.sqrt(n_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            qk = qk.view(n_batch, n_head, n_batch_max_in, n_batch_max_in).transpose(1, 2)\n",
    "            qk[~mask] = -np.inf\n",
    "            qk = qk.transpose(1, 2).view(n_batch * n_head, n_batch_max_in, n_batch_max_in)\n",
    "        qk = qk.softmax(dim=-1)\n",
    "        v = v.reshape(n_batch * n_head, n_batch_max_in, n_v)\n",
    "        qkv = qk.bmm(v).view(n_batch, n_head, n_batch_max_in, n_v).transpose(1, 2).reshape(n_batch, n_batch_max_in, n_head * n_v)\n",
    "        out = self.out(qkv)\n",
    "        return x + out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = TransformerAttention()\n",
    "        n_inner = n_hid * 4\n",
    "        self.inner = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_inner),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_inner, n_hid)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.attn(x, mask=mask)\n",
    "        return x + self.inner(x)\n",
    "    \n",
    "class GCNBranch(nn.Module):\n",
    "    def __init__(self, n_hid_in, n_hid_out, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define a branch of the graph convolution with\n",
    "        1. GraphConv from n_hid_in to n_hid_in\n",
    "        2. ReLU\n",
    "        3. Dropout\n",
    "        4. GraphConv from n_hid_in to n_hid_out\n",
    "        \n",
    "        Note: your should call GraphConv with allow_zero_in_degree=True\n",
    "        \"\"\"\n",
    "        self.gc1 = GraphConv(n_hid_in, n_hid_in, allow_zero_in_degree=True)\n",
    "        self.drelu = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.gc2 = GraphConv(n_hid_in, n_hid_out, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, x, graph):\n",
    "        \"\"\"\n",
    "        Forward pass of your defined branch above\n",
    "        \"\"\"\n",
    "        return self.gc2(graph, self.drelu(self.gc1(graph, x)))\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, n_head=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList(GCNBranch(n_hid, n_hid // n_head, dropout) for _ in range(n_head))\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_hid),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hid, n_hid)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(n_hid)\n",
    "\n",
    "    def forward(self, h, gt_graph, attr_graph):\n",
    "        x = h.reshape(-1, n_hid)\n",
    "        graphs = [gt_graph, gt_graph, attr_graph, attr_graph]\n",
    "        x = torch.cat([branch(x, g) for branch, g in zip(self.branches, graphs)], dim=-1).view_as(h)\n",
    "        x = h + self.layer_norm(x)\n",
    "        return x + self.feed_forward(x)\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(Gate, self).__init__()\n",
    "        self.t = nn.Linear(n_in, n_out)\n",
    "        self.s = nn.Linear(n_in, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.t(x).tanh() * self.s(x).sigmoid()\n",
    "\n",
    "class TreeDecoder(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "        self.constant_embedding = nn.Parameter(torch.randn(1, out_vocab.n_constants, n_hid))\n",
    "\n",
    "        self.qp_gate = nn.Sequential(drop, Gate(n_hid, n_hid))\n",
    "        self.gts_right = nn.Sequential(drop, Gate(2 * n_hid, n_hid))\n",
    "\n",
    "        self.attn_fc = nn.Sequential(drop,\n",
    "            nn.Linear(2 * n_hid, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1)\n",
    "        )\n",
    "        self.quant_fc = nn.Sequential(drop,\n",
    "            nn.Linear(n_hid * 3, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1, bias=False)\n",
    "        )\n",
    "        self.op_fc = nn.Sequential(drop, nn.Linear(n_hid * 2, out_vocab.n_ops))\n",
    "\n",
    "        self.op_embedding = nn.Embedding(out_vocab.n_ops + 1, n_hid, padding_idx=out_vocab.n_ops)\n",
    "        self.gts_left = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "        self.gts_left_qp = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid), self.qp_gate)\n",
    "\n",
    "        self.subtree_gate = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "\n",
    "    def gts_attention(self, q, zbar, in_mask=None):\n",
    "        attn_score = self.attn_fc(\n",
    "            torch.cat([q.unsqueeze(1).expand_as(zbar), zbar], dim=2)\n",
    "        ).squeeze(2)\n",
    "        if in_mask is not None:\n",
    "            attn_score[~in_mask] = -np.inf\n",
    "        attn = attn_score.softmax(dim=1)\n",
    "        return (attn.unsqueeze(1) @ zbar).squeeze(1) # (n_batch, n_hid)\n",
    "\n",
    "    def gts_predict(self, qp_Gc, quant_embed, nP_out_mask=None):\n",
    "        quant_score = self.quant_fc(\n",
    "            torch.cat([qp_Gc.unsqueeze(1).expand(-1, quant_embed.size(1), -1), quant_embed], dim=2)\n",
    "        ).squeeze(2)\n",
    "        op_score = self.op_fc(qp_Gc)\n",
    "        pred_score = torch.cat((op_score, quant_score), dim=1)\n",
    "        if nP_out_mask is not None:\n",
    "            pred_score[:, out_vocab.base_nP:][~nP_out_mask] = -np.inf\n",
    "        return pred_score\n",
    "\n",
    "    def merge_subtree(self, op, tl, yr):\n",
    "        return self.subtree_gate(torch.cat((op, tl, yr), dim=-1))\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "\n",
    "        if use_t5:\n",
    "            \"\"\"\n",
    "            Use t5_model.encoder as the encoder for this model. Note that unlike the custom transformer, you don't\n",
    "            need to use an external positional embedding for the T5 transformer (i.e. don't define self.pos_emb)\n",
    "            \n",
    "            You may specify layer weights to freeze during finetuning by modifying the freeze_layers global variable\n",
    "            \"\"\"\n",
    "            self.t5_encoder = t5_model.encoder\n",
    "            \n",
    "            for i_layer, block in enumerate(self.t5_encoder.block):\n",
    "                if i_layer in freeze_layers:\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "        else:\n",
    "            self.in_embed = nn.Sequential(nn.Embedding(in_vocab.n, n_hid, padding_idx=in_vocab.pad), drop)\n",
    "            self.pos_embed = nn.Embedding(1 + n_max_in, n_hid) # Use the first position as global vector\n",
    "            self.transformer_layers = nn.ModuleList(TransformerBlock() for _ in range(n_layers))\n",
    "\n",
    "        self.gcn = GCN()\n",
    "\n",
    "        self.decoder = TreeDecoder()\n",
    "\n",
    "        if not use_t5:\n",
    "            self.apply(self.init_weight)\n",
    "\n",
    "    def init_weight(self, m):\n",
    "        if type(m) in [nn.Embedding]:\n",
    "            nn.init.normal_(m.weight, 0, 0.1)\n",
    "\n",
    "    def encode(self, in_idxs, n_in, gt_graph, attr_graph, in_mask=None):\n",
    "        in_idxs_pad = F.pad(in_idxs, (1, 0), value=in_vocab.pad)\n",
    "        if use_t5:\n",
    "            \"\"\"\n",
    "            Call your T5 encoder\n",
    "            \"\"\"\n",
    "#             h, = self.t5_encoder(in_idxs_pad)\n",
    "            h = self.t5_encoder(in_idxs_pad).last_hidden_state\n",
    "        else:\n",
    "            x = self.in_embed(in_idxs_pad) # (n_batch, n_batch_max_in, n_hid)\n",
    "            h = x + self.pos_embed(torch.arange(x.size(1), device=x.device))\n",
    "            for layer in self.transformer_layers:\n",
    "                h = layer(h, mask=in_mask)\n",
    "        zg, h = h[:, 0], h[:, 1:]\n",
    "        zbar = self.gcn(h, gt_graph, attr_graph)\n",
    "        return zbar, zg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:31:12.383238Z",
     "start_time": "2020-10-29T08:31:12.342661Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, up):\n",
    "        self.up = up\n",
    "        self.is_root = up is None\n",
    "        self.left = self.right = None\n",
    "        self.ql = self.tl = self.op = None\n",
    "\n",
    "def train(batch, model, opt):\n",
    "    n_batch = len(batch)\n",
    "\n",
    "    n_in = [d['n_in'] for d in batch]\n",
    "    pad = lambda x, value: nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=value)\n",
    "    in_idxs = pad([d['in_idxs'] for d in batch], in_vocab.pad).to(device)\n",
    "    in_mask = pad([torch.ones(n, dtype=torch.bool) for n in n_in], False).to(device)\n",
    "    nP_in_mask = pad([d['nP_in_mask'] for d in batch], False).to(device)\n",
    "    nP_out_mask = torch.stack([d['nP_out_mask'] for d in batch]).to(device)\n",
    "    \n",
    "    qcomp_graph, qcell_graph = [], []\n",
    "    for d in batch:\n",
    "        \"\"\"\n",
    "        Create qcomp_graph and qcell_graph from d['qcomp_edges'] and d['qcell_edges'] by calling dgl.graph\n",
    "        (see https://docs.dgl.ai/generated/dgl.graph.html)\n",
    "\n",
    "        Note that num_nodes needs to be set to the maximum input length in this batch\n",
    "        \"\"\"\n",
    "        qcomp_graph_i = dgl.graph(d['qcomp_edges'], num_nodes=in_idxs.size(1), device=device)\n",
    "        qcell_graph_i = dgl.graph(d['qcell_edges'], num_nodes=in_idxs.size(1), device=device)\n",
    "        \n",
    "        qcomp_graph.append(qcomp_graph_i)\n",
    "        qcell_graph.append(qcell_graph_i)\n",
    "    qcomp_graph = dgl.batch(qcomp_graph)\n",
    "    qcell_graph = dgl.batch(qcell_graph)\n",
    "    \n",
    "    label = pad([d['out_idxs'] for d in batch], out_vocab.pad)\n",
    "    nP_candidates = [d['nP_candidates'] for d in batch]\n",
    "\n",
    "    zbar, qroot = model.encode(in_idxs, n_in, qcomp_graph, qcell_graph, in_mask=None)\n",
    "    z_nP = zbar.new_zeros((n_batch, n_max_nP, n_hid))\n",
    "    z_nP[nP_out_mask] = zbar[nP_in_mask]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    n_quant = out_vocab.n_constants + n_max_nP\n",
    "    quant_embed = torch.cat([decoder.constant_embedding.expand(n_batch, -1, -1), z_nP], dim=1) # (n_batch, n_quant, n_hid)\n",
    "\n",
    "    nodes = np.array([Node(None) for _ in range(n_batch)])\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "    quant_min, quant_max = out_vocab.base_quant, out_vocab.base_quant + n_quant\n",
    "\n",
    "    # Initialize root node vector according to zg (the global context)\n",
    "    qp = decoder.qp_gate(qroot)\n",
    "    scores = []\n",
    "    for i, label_i in enumerate(label.T): # Iterate over the output positions\n",
    "        Gc = decoder.gts_attention(qp, zbar, in_mask)\n",
    "        qp_Gc = torch.cat([qp, Gc], dim=1) # (n_batch, 2 * n_hid)\n",
    "\n",
    "        score = decoder.gts_predict(qp_Gc, quant_embed, nP_out_mask)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Whether the label is an operator\n",
    "        is_op = (op_min <= label_i) & (label_i < op_max)\n",
    "        # Whether the label is a quantity\n",
    "        is_quant = ((quant_min <= label_i) & (label_i < quant_max)) | (label_i == out_vocab.unk)\n",
    "\n",
    "        op_embed = decoder.op_embedding((label_i[is_op] - out_vocab.base_op).to(device))\n",
    "        qp_Gc_op = torch.cat([qp_Gc[is_op], op_embed], dim=1)\n",
    "\n",
    "        is_left = np.zeros(n_batch, dtype=np.bool)\n",
    "        qleft_qp = decoder.gts_left_qp(qp_Gc_op)\n",
    "        qleft = decoder.gts_left(qp_Gc_op)\n",
    "        for j, ql, op in zip(is_op.nonzero(as_tuple=True)[0], qleft, op_embed):\n",
    "            node = nodes[j]\n",
    "            nodes[j] = node.left = Node(node)\n",
    "            node.op = op\n",
    "            node.ql = ql\n",
    "            is_left[j] = True\n",
    "\n",
    "        is_right = np.zeros(n_batch, dtype=np.bool)\n",
    "        nP_score = score[:, out_vocab.base_nP:].detach().cpu()\n",
    "        ql_tl = []\n",
    "        for j in is_quant.nonzero(as_tuple=True)[0]:\n",
    "            if label_i[j] == out_vocab.unk:\n",
    "                candidates = nP_candidates[j][i]\n",
    "#                 label_i[j] = out_vocab.base_nP + candidates[nP_score[j, candidates].argmax()]\n",
    "                label_i[j] = torch.from_numpy(np.array(out_vocab.base_nP + candidates[nP_score[j, candidates].argmax()])).to(label_i)\n",
    "\n",
    "            node = nodes[j]\n",
    "            pnode = node.up\n",
    "            t = quant_embed[j, label_i[j] - out_vocab.base_quant]\n",
    "            while pnode and pnode.right is node:\n",
    "                t = decoder.merge_subtree(pnode.op, pnode.tl, t) # merge operator, left subtree, and right child\n",
    "                node, pnode = pnode, pnode.up # backtrack to parent node\n",
    "            if pnode is None: # Finished traversing tree of j\n",
    "                continue\n",
    "            # Now pnode.left is node. t is the tl representing the left subtree of pnode\n",
    "            pnode.tl = t\n",
    "            ql_tl.append(torch.cat([pnode.ql, pnode.tl])) # For computing qright\n",
    "            nodes[j] = pnode.right = Node(pnode)\n",
    "            is_right[j] = True\n",
    "\n",
    "        qp = torch.zeros((n_batch, n_hid), device=device)\n",
    "        qp[is_left] = qleft_qp\n",
    "        if ql_tl:\n",
    "            qp[is_right] = decoder.gts_right(torch.stack(ql_tl))\n",
    "\n",
    "    label = label.to(device).view(-1)\n",
    "    scores = torch.stack(scores, dim=1).view(-1, out_vocab.n_ops + n_quant)\n",
    "    loss = F.cross_entropy(scores, label, ignore_index=out_vocab.pad)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamNode(Node):\n",
    "    def __init__(self, up, prev, qp, token=None):\n",
    "        super().__init__(up)\n",
    "        self.prev = prev\n",
    "        self.qp = qp\n",
    "        self.token = token\n",
    "\n",
    "    def trace_tokens(self, *last_token):\n",
    "        if self.prev is None:\n",
    "            return list(last_token)\n",
    "        tokens = self.prev.trace_tokens()\n",
    "        tokens.append(self.token)\n",
    "        tokens.extend(last_token)\n",
    "        return tokens\n",
    "\n",
    "def evaluate(d, model, beam_size=5, n_max_out=45):\n",
    "    in_idxs = d['in_idxs'].unsqueeze(0).to(device=device)\n",
    "    \"\"\"\n",
    "    Create qcomp_graph and qcell_graph from d['qcomp_edges'] and d['qcell_edges'] by calling dgl.graph\n",
    "    (see https://docs.dgl.ai/generated/dgl.graph.html)\n",
    "    \"\"\"\n",
    "#     qcomp_graph = dgl.graph(d['gt_edges'], device=device)\n",
    "#     qcell_graph = dgl.graph(d['attr_edges'], device=device)\n",
    "    qcomp_graph = dgl.graph(d['qcomp_edges'], device=device)\n",
    "    qcell_graph = dgl.graph(d['qcell_edges'], device=device)\n",
    "\n",
    "    zbar, qroot = model.encode(in_idxs, [d['n_in']], qcomp_graph, qcell_graph)\n",
    "    z_nP = zbar[:, d['nP_positions']]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    quant_embed = torch.cat([decoder.constant_embedding, z_nP], dim=1) # (1, n_quant, n_hid)\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "\n",
    "    best_done_beam = (-np.inf, None, None)\n",
    "    beams = [(0, BeamNode(up=None, prev=None, qp=decoder.qp_gate(qroot)))]\n",
    "    for _ in range(n_max_out):\n",
    "        new_beams = []\n",
    "        for logp_prev, node in beams:\n",
    "            Gc = decoder.gts_attention(node.qp, zbar)\n",
    "            qp_Gc = torch.cat([node.qp, Gc], dim=1) # (2 * n_hid,)\n",
    "\n",
    "            log_prob = decoder.gts_predict(qp_Gc, quant_embed).log_softmax(dim=1)\n",
    "            top_logps, top_tokens = log_prob.topk(beam_size, dim=1)\n",
    "            for logp_token_, out_token_ in zip(top_logps.unbind(dim=1), top_tokens.unbind(dim=1)):\n",
    "                out_token = out_token_.item()\n",
    "                logp = logp_prev + logp_token_.item()\n",
    "                if op_min <= out_token < op_max:\n",
    "                    op_embed = decoder.op_embedding(out_token_)\n",
    "                    qp_Gc_op = torch.cat([qp_Gc, op_embed], dim=1)\n",
    "                    prev_node = copy(node)\n",
    "                    next_node = prev_node.left = BeamNode(\n",
    "                        up=prev_node, prev=prev_node,\n",
    "                        qp=decoder.gts_left_qp(qp_Gc_op),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                    prev_node.op = op_embed\n",
    "                    prev_node.ql = decoder.gts_left(qp_Gc_op)\n",
    "                else:\n",
    "                    pnode, prev_node = node.up, node\n",
    "                    t = quant_embed[:, out_token - out_vocab.base_quant]\n",
    "                    while pnode and pnode.tl is not None:\n",
    "                        t = decoder.merge_subtree(pnode.op, pnode.tl, t)\n",
    "                        node, pnode = pnode, pnode.up\n",
    "                    if pnode is None:\n",
    "                        best_done_beam = max(best_done_beam, (logp, prev_node, out_token))\n",
    "                        continue\n",
    "                    pnode = copy(pnode)\n",
    "                    pnode.tl = t\n",
    "                    next_node = pnode.right = BeamNode(\n",
    "                        up=pnode, prev=prev_node,\n",
    "                        qp=decoder.gts_right(torch.cat([pnode.ql, pnode.tl], dim=1)),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                new_beams.append((logp, next_node))\n",
    "        beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "        done_logp, done_node, done_last_token = best_done_beam\n",
    "        if not len(beams) or done_logp >= beams[0][0]:\n",
    "            break\n",
    "    return done_node.trace_tokens(done_last_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (multiple choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, test_data):\n",
    "    model.eval()\n",
    "    value_match, equation_match = [], []\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(test_data):\n",
    "            val_match = eq_match = False\n",
    "            if not d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "                try:\n",
    "                    pred = evaluate(d, model)\n",
    "                    d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                    val_match, eq_match = check_match(pred, d)\n",
    "                except:\n",
    "                    print(\"pred:\", pred, \"\\nd[processed_question]:\", d['processed_question'])\n",
    "            value_match.append(val_match)\n",
    "            equation_match.append(eq_match)\n",
    "    print(f'Test equation accuracy {np.mean(equation_match):.3g}')\n",
    "    print(f'Test value accuracy {np.mean(value_match):.3g}')\n",
    "    \n",
    "def score_model_ranking_multiple_choice(model, test_data, num_tries=2, answers_generated=20, num_choices=4):\n",
    "    model.eval()\n",
    "    value_match = []\n",
    "    tries = []\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(test_data):\n",
    "            if d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "                val_match = eq_match = False\n",
    "                try_number = num_tries - 1\n",
    "            else:\n",
    "                # generate responses\n",
    "                result = []\n",
    "                for _ in range(answers_generated):\n",
    "                    try:\n",
    "                        pred = evaluate(d, model)\n",
    "                        result.append(str(pred))\n",
    "                    except:\n",
    "                        pass\n",
    "                counts = Counter(result)\n",
    "                counts = sorted(counts.items(), key=lambda x: eval(x[0]))\n",
    "                preds = [elt[0] for elt in sorted(counts, key=lambda x: (x[1], random.random()), reverse=True)][:min(len(counts),num_tries)]\n",
    "                \n",
    "                # generate answer choices\n",
    "                correct_tree = sub_nP(d['out_tokens'], d['nP'])\n",
    "                answers, correct_answer = generate_choices(correct_tree, num_choices)\n",
    "                \n",
    "                # have model make decision\n",
    "                val_match = 0\n",
    "                for try_number in range(len(preds)):\n",
    "                    chosen_answer = random.choice(answers)\n",
    "                    for pred in preds:\n",
    "                        if pred in answers:\n",
    "                            chosen_answer = pred\n",
    "                            break # if not chosen after iterating over all preds, keep the chosen one at random\n",
    "                    del answers[answers.index(chosen_answer)]\n",
    "                    if chosen_answer == correct_answer:\n",
    "                        val_match = 1\n",
    "                        break\n",
    "            tries.append(try_number + 1)\n",
    "            value_match.append(val_match)\n",
    "    print(f'Test value accuracy {np.mean(value_match):.3g}')\n",
    "    print(f'Avg number of tries {np.mean(tries):.3g}')\n",
    "    \n",
    "def generate_choices(parse_tree, num_choices, operators=None):\n",
    "    if operators is None:\n",
    "        operators = {'+': np.add, '-': np.subtract, '*': np.multiply, '/': np.divide, 'm': max, 'l':math.log, '^': np.power}\n",
    "    special_values = [0.1, 0.2, 0.25, 0.4, 0.5, 0.6, 0.75, 0.8, 2, 2.5, 3, 4, 5, 6, 7.5, 8, 10]\n",
    "    correct_answer = evaluate_prefix_expression(parse_tree)\n",
    "    parse_tree = [elt if elt in operators else eval(elt) for elt in parse_tree]\n",
    "    \n",
    "    # find all other possible parse tree constructions\n",
    "    good_trees = [parse_tree]\n",
    "    bad_trees = []\n",
    "    valid_answers = []\n",
    "    for _ in range(3):\n",
    "        good_trees_size = len(good_trees)\n",
    "        for tree in good_trees:\n",
    "            for idx in range(len(tree)-4):\n",
    "                if parse_tree[idx] in operators:\n",
    "                    if parse_tree[idx+1] in operators: # zig rotation\n",
    "                        proposed_tree = zig_rotation(parse_tree, idx)\n",
    "                    if parse_tree[idx+2] in operators: # zag rotation\n",
    "                        proposed_tree = zag_rotation(parse_tree, idx)\n",
    "                    if proposed_tree not in good_trees and proposed_tree not in bad_trees:\n",
    "                        try:\n",
    "                            answer = evaluate_prefix_expression(answer_tree)\n",
    "                            good_trees.append(proposed_tree)\n",
    "                            valid_answers.append(answer)\n",
    "                        except:\n",
    "                            bad_trees.append(proposed_tree)\n",
    "        if good_trees_size == len(good_trees) or len(good_trees) > num_choices:\n",
    "            break\n",
    "\n",
    "    while len(valid_answers) < num_choices:\n",
    "        numeric_idxs = [idx for idx in range(len(parse_tree)) if parse_tree[idx] not in operators]\n",
    "        numeric_idx = numeric_idxs[int(random.random()*len(numeric_idxs))]\n",
    "        parse_tree_augmented = parse_tree.copy()\n",
    "        option = random.random()\n",
    "        if option < 2/3:\n",
    "            parse_tree_augmented[numeric_idx] *= random.choice(special_values)\n",
    "        elif 1/3 < option:\n",
    "            parse_tree_augmented[numeric_idx] += random.choice(special_values)\n",
    "        else:\n",
    "            parse_tree_augmented[numeric_idx] -= random.choice(special_values)\n",
    "        try:\n",
    "            result = evaluate_prefix_expression(parse_tree_augmented)\n",
    "            if result in valid_answers or result == correct_answer:\n",
    "                continue\n",
    "            else:\n",
    "                valid_answers.append(result)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    random.shuffle(valid_answers)\n",
    "    correct_idx = int(random.random()*num_choices)\n",
    "    valid_answers[correct_idx] = correct_answer\n",
    "    return valid_answers[:num_choices], correct_answer\n",
    "    \n",
    "def zig_rotation(parse_tree, first_rotation_idx):\n",
    "    tree = parse_tree.copy()\n",
    "    tree[first_rotation_idx], tree[first_rotation_idx+1], tree[first_rotation_idx+2] = tree[first_rotation_idx+1], tree[first_rotation_idx+2], tree[first_rotation_idx]\n",
    "    return tree\n",
    "\n",
    "def zag_rotation(parse_tree, first_rotation_idx):\n",
    "    tree = parse_tree.copy()\n",
    "    tree[first_rotation_idx], tree[first_rotation_idx+1], tree[first_rotation_idx+2] = tree[first_rotation_idx+2], tree[first_rotation_idx], tree[first_rotation_idx+1]\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_t5 = 'small' # Value should be None, 'small', or 'base'\n",
    "# use_t5 = None\n",
    "\n",
    "n_max_in = 100\n",
    "n_batch = 32\n",
    "learning_rate = 1e-4\n",
    "if use_t5:\n",
    "    # T5 hyperparameters\n",
    "    n_epochs = 100\n",
    "    freeze_layers = []\n",
    "    weight_decay = 1e-5\n",
    "    n_hid = dict(small=512, base=768)[use_t5] # Do not modify unless you want to try t5-large\n",
    "else:\n",
    "    # Custom transformer hyperparameters\n",
    "    n_epochs = 5\n",
    "    n_layers = 3\n",
    "    n_hid = 512\n",
    "    n_k = n_v = 64\n",
    "    n_head = 8\n",
    "    weight_decay = 0\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create from .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 10 examples...\n",
      "\n",
      "{'expression': '(0-8/(61-23))*((8/(61-23))l2)+(0-(61-23-8)/(61-23))*(((61-23-8)/(61-23))l2)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], 'processed_question': 'Consider a 1D classification line on a 2D plane. There is a total of 61 points, 23 of which are on the right and the rest on the left of the boundary. 8 points on the left are classified positive. What is the entropy of the left region?', 'raw_question': 'Consider a 1D classification line on a 2D plane. There is a total of 61 points, 23 of which are on the right and the rest on the left of the boundary. 8 points on the left are classified positive. What is the entropy of the left region?', 'is_quadratic': False, 'Id': 29207, 'Expected': 0.7424875695421236}\n",
      "{'expression': '9+(0.2*(4-9))', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'processed_question': 'If q is 9, what is its updated value after applying Q learning if a is 0.2 and t is 4?', 'raw_question': 'If q is 9, what is its updated value after applying Q learning if a is 0.2 and t is 4?', 'is_quadratic': False, 'Id': 27281, 'Expected': 8.0}\n",
      "{'expression': '((3^2)+(8^2)+(15^2))^0.5', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'processed_question': 'Let an input vector be [3 8 15]. What is its magnitude?', 'raw_question': 'Let an input vector be [3 8 15]. What is its magnitude?', 'is_quadratic': False, 'Id': 1276, 'Expected': 17.26267650163207}\n",
      "{'expression': '3*(((6m9)m6)m3)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], 'processed_question': 'Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 6, f(s_(t-1), x_t) = (s_(t-1))m(x_t), and g(s_t) = 3*s_t, what is the output y_3 after the inputs [9, 6, 3]?', 'raw_question': 'Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 6, f(s_(t-1), x_t) = (s_(t-1))m(x_t), and g(s_t) = 3*s_t, what is the output y_3 after the inputs [9, 6, 3]?', 'is_quadratic': False, 'Id': 24929, 'Expected': 27}\n",
      "{'expression': '((3^2)+(7^2)+(1^2))^0.5', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6], 'processed_question': 'Compute the magnitude of [3 7 1].', 'raw_question': 'Compute the magnitude of [3 7 1].', 'is_quadratic': False, 'Id': 1108, 'Expected': 7.681145747868608}\n",
      "{'expression': '3+(0.8*(8-3))', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], 'processed_question': 'What is the updated Q value of a tuple (s, a) if q is 3, the a is 0.8, and t is 8?', 'raw_question': 'What is the updated Q value of a tuple (s, a) if q is 3, the a is 0.8, and t is 8?', 'is_quadratic': False, 'Id': 25940, 'Expected': 7.0}\n",
      "{'expression': '((((1*1.5)+0.25)*1.5)+0.5)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], 'processed_question': 'An RNN is defined as s_t = w*s_t-1 + x_t. If s_0 is 1, w is 1.5, and x is [ 0.25 0.5 ] , what is s_2?', 'raw_question': 'An RNN is defined as s_t = w*s_t-1 + x_t. If s_0 is 1, w is 1.5, and x is [ 0.25 0.5 ] , what is s_2?', 'is_quadratic': False, 'Id': 20801, 'Expected': 3.125}\n",
      "{'expression': '1*(3-0-9)*0-1', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], 'processed_question': 'A point 3 has label negative 1. Compute the margin of a classifier on this point. Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 9.', 'raw_question': 'A point 3 has label negative 1. Compute the margin of a classifier on this point. Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 9.', 'is_quadratic': False, 'Id': 5194, 'Expected': -12}\n",
      "{'expression': '0*0+3*0-4', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], 'processed_question': 'How does a classifier with decision boundary theta classify a point p if theta is (0, 3) and p is (0 negative 4)?', 'raw_question': 'How does a classifier with decision boundary theta classify a point p if theta is (0, 3) and p is (0 negative 4)?', 'is_quadratic': False, 'Id': 2800, 'Expected': -12}\n",
      "{'expression': '0-1*(3-9)*0-1', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], 'processed_question': 'What is the margin on a point 3 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 9?', 'raw_question': 'What is the margin on a point 3 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 9?', 'is_quadratic': False, 'Id': 7342, 'Expected': -6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 85.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensorizing...\n",
      "Number of items: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [08:56, 55.89it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing 10 examples...\\n\")\n",
    "train_data, test_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5, path=\"data/ml_data_12_topics/train.json\")\n",
    "print(\"\\nTensorizing...\")\n",
    "tensorize_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to setup_vocab_model_t5_small.pickle\n"
     ]
    }
   ],
   "source": [
    "def save_data_split():\n",
    "    filename = 'setup_data_split.pickle'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump([train_data, test_data, n_max_nP], f)\n",
    "        print(f'Saved to {filename}')\n",
    "        \n",
    "def save_vocab_model():\n",
    "    suffix = str(use_t5) if use_t5 is not None else \"none\"\n",
    "    filename = f'setup_vocab_model_t5_{suffix}.pickle'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump([in_vocab, out_vocab, t5_model], f)\n",
    "        print(f'Saved to {filename}')\n",
    "# if not use_t5:\n",
    "#     save_data_split() # if using T5, no need to save data split again\n",
    "# save_vocab_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening setup_data_split.pickle\n",
      "Opening setup_vocab_model_t5_small.pickle\n"
     ]
    }
   ],
   "source": [
    "def load_data_split():\n",
    "    with open('setup_data_split.pickle', 'rb') as f:\n",
    "        print(\"Opening setup_data_split.pickle\")\n",
    "        return pickle.load(f)\n",
    "        \n",
    "def load_vocab_model():\n",
    "    suffix = str(use_t5) if use_t5 is not None else \"none\"\n",
    "    filename = f'setup_vocab_model_t5_{suffix}.pickle'\n",
    "    with open(filename, 'rb') as f:\n",
    "        print(f\"Opening {filename}\")\n",
    "        return pickle.load(f)\n",
    "train_data, test_data, n_max_nP = load_data_split()\n",
    "in_vocab, out_vocab, t5_model = load_vocab_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:08<00:00,  1.45s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02921789394443234\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:18<00:00,  1.46s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.026203179105495415\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:18<00:00,  1.46s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02567006753385067\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:21<00:00,  1.47s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02377982105128467\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:21<00:00,  1.47s/it]\n",
      "  0%|          | 0/6000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0231595782963559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1709/6000 [03:21<07:53,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 5, 41, 11, 8, 2, 41, 11] \n",
      "d[processed_question]: Compute the magnitude of [1 7 5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1978/6000 [03:51<08:43,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 3, 41, 1, 7, 3, 41, 1, 7, 41, 5, 3, 1, 1, 7, 3, 41, 1, 7, 3, 41, 1, 7, 41, 41, 1, 7, 3, 41, 1, 7, 41, 8, 2, 1, 17, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 10 8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2247/6000 [04:24<06:43,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['+', '+', '*', '0', '0', '0.5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2910/6000 [05:41<07:54,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 7 1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3538/6000 [06:53<06:05,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 5, 41, 11, 8, 2, 41, 11] \n",
      "d[processed_question]: Compute the magnitude of [1 10 5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 5760/6000 [11:09<00:32,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['+', 'm', '8', '*', '0.7', '-', '8', '9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [11:36<00:00,  8.62it/s]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy 0.739\n",
      "Test value accuracy 0.758\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:12<00:00,  1.46s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02354768135926376\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:11<00:00,  1.46s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.021775950835086405\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:17<00:00,  1.46s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.021934600298913816\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:19<00:00,  1.47s/it]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.021401688670739532\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [18:06<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.021868227834192414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:274] . unexpected pos 77213888 vs 77213776",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0f69e3057221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'models/model-{epoch}-t5_{str(use_t5) if use_t5 is not None else \"none\"}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mscore_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         score_model_ranking_multiple_choice(model, test_data[:int(len(test_data)/1000)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:274] . unexpected pos 77213888 vs 77213776"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/model-15-t5_small.pth\"))\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "model.to(device)\n",
    "\n",
    "epoch = 15\n",
    "while epoch < n_epochs:\n",
    "    print('Epoch:', epoch + 1)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for start in trange(0, int(len(train_data)), n_batch):\n",
    "        batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "        loss = train(batch, model, opt)\n",
    "        losses.append(loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    print('Training loss:', np.mean(losses))\n",
    "\n",
    "    epoch += 1\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'models/model-{epoch}-t5_{str(use_t5) if use_t5 is not None else \"none\"}.pth')\n",
    "        score_model(model, test_data[:int(len(test_data))])\n",
    "#         score_model_ranking_multiple_choice(model, test_data[:int(len(test_data)/1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "# model.load_state_dict(torch.load(\"models/model-5-t5_none.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-10-t5_none.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-5-t5_small.pth\"))\n",
    "# model.load_state_dict(torch.load(\"models/model-10-t5_small.pth\"))\n",
    "model.load_state_dict(torch.load(\"models/model-15-t5_small.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'models/model-25-t5_{str(use_t5) if use_t5 is not None else \"none\"}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1029/6000 [02:07<07:51, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['*', '*', '1', '0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2378/6000 [05:00<06:35,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['+', '-', '4', '*', '0.1', '2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4927/6000 [10:23<02:06,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['^', '+', '+', '+', '*', '8', '2', '3', '3', '0.5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 5418/6000 [11:30<01:22,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['^', '+', '+', '+', '*', '3', '2', '3', '3', '0.5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [12:47<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy 0.49\n",
      "Test value accuracy 0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score_model(model, test_data) # t5small, 5 epochs, score on open ended response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/6000 [00:00<09:03, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 2780/6000 [05:52<05:19, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['+', '+', '*', '8', '9', '*', '0.1', '-', '8', '9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 5946/6000 [12:33<00:07,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['+', '-', '8', '*', '5', '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [12:40<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy 0.554\n",
      "Test value accuracy 0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score_model(model, test_data) # t5small, 10 epochs, score on open ended response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 36/6000 [00:04<13:34,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 6 11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 97/6000 [00:12<14:12,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [1, 2, 2, 41, 1, 43, 42, 7, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [1 10 1]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 198/6000 [00:26<13:57,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['+', '*', '*', '8', '8', '*', '8', '8']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 220/6000 [00:28<12:52,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 423/6000 [00:56<12:11,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 526/6000 [01:09<11:39,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 10 11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 591/6000 [01:16<08:23, 10.74it/s]/home/sunnyt/solving-mlp/util.py:207: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return fn(arg1, arg2), end\n",
      " 10%|▉         | 593/6000 [01:16<10:08,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41, 0, 2, 41, 41, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [2 8 11]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 819/6000 [01:46<14:48,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 9 11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 823/6000 [01:46<12:02,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 929/6000 [02:00<12:07,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1086/6000 [02:21<11:29,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1267/6000 [02:46<10:47,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41, 0, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [2 6 9]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1310/6000 [02:53<16:37,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1707/6000 [03:45<12:06,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 11, 8, 2, 1, 41, 41, 11] \n",
      "d[processed_question]: Compute the magnitude of [1 7 5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1735/6000 [03:48<08:43,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1978/6000 [04:17<09:33,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 3, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 10 8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 2053/6000 [04:28<09:54,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 1, 7, 3, 41, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [5 8 12]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 2063/6000 [04:29<09:29,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['*', '*', '9', '9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 2077/6000 [04:31<13:06,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 1, 7, 2, 41, 0, 2, 7, 8, 2, 41, 7, 5, 3, 41, 1, 7, 41, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [1 7 15]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 2122/6000 [04:38<08:42,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 2182/6000 [04:47<13:51,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 43, 1, 41, 42, 5, 3, 43, 1, 41, 42, 8, 2, 1, 7, 3, 1, 1, 41, 42, 43, 1, 41, 42, 5, 3, 1, 1, 41, 42, 43, 1, 41, 42, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [1 9 18]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2387/6000 [05:15<09:57,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41, 0, 2, 41, 41, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [2 7 11]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2441/6000 [05:22<09:13,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 0, 2, 41, 22, 42, 0, 2, 41, 22, 42] \n",
      "d[processed_question]: What is the magnitude of the vector [1 8 18]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2466/6000 [05:24<06:06,  9.64it/s]/home/sunnyt/solving-mlp/util.py:207: RuntimeWarning: invalid value encountered in multiply\n",
      "  return fn(arg1, arg2), end\n",
      " 44%|████▎     | 2610/6000 [05:44<07:36,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2756/6000 [06:03<07:17,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2773/6000 [06:05<07:26,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2806/6000 [06:09<07:49,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 11, 2, 1, 41, 41, 11] \n",
      "d[processed_question]: Find the Euclidian length of [4 7 5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3110/6000 [06:51<05:32,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3131/6000 [06:54<05:55,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 3247/6000 [07:08<05:18,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3373/6000 [07:24<07:37,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 0, 2, 41, 42, 42, 0, 2, 41, 42, 42] \n",
      "d[processed_question]: What is the magnitude of the vector [1 8 1]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3538/6000 [07:46<06:52,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 11, 8, 2, 1, 41, 41, 11] \n",
      "d[processed_question]: Compute the magnitude of [1 10 5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3737/6000 [08:12<08:05,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [4, 7, 0, 2, 11, 0, 2, 10, 8, 2, 13, 15, 2, 15, 11] \n",
      "d[processed_question]: What is the magnitude of the vector [2 10 17]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4046/6000 [08:52<03:41,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 4072/6000 [08:55<04:24,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 4144/6000 [09:05<04:18,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 8, 4, 4, 4, 22, 22, 32, 10] \n",
      "d[processed_question]: What is the magnitude of the vector [2 7 5]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 4154/6000 [09:07<06:33,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 43, 1, 41, 42, 5, 3, 43, 1, 41, 42, 8, 2, 1, 7, 3, 1, 1, 41, 42, 43, 1, 41, 42, 5, 3, 1, 1, 41, 42, 43, 1, 41, 42, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [2 8 5]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 4260/6000 [09:20<06:02,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 41, 0, 2, 11, 8, 2, 11, 41, 2, 11, 11] \n",
      "d[processed_question]: What is the magnitude of the vector [1 6 18]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4384/6000 [09:36<04:08,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4469/6000 [09:47<04:01,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 1, 7, 2, 41, 0, 2, 7, 8, 2, 41, 7, 5, 3, 41, 1, 7, 41, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [5 10 16]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 4550/6000 [09:58<02:31,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['+', '+', '*', '6', '6', '6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 4594/6000 [10:04<04:06,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 11, 0, 2, 8, 8, 2, 41, 1, 8, 17, 2, 8, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [2 6 17]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4704/6000 [10:18<02:26,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 4741/6000 [10:23<03:45,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 0, 8, 41, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [2 7 7]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 4768/6000 [10:26<03:48,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed expression ['*', '*', '10', '10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 4778/6000 [10:28<02:33,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4828/6000 [10:34<02:38,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 1, 7, 3, 41, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [5 10 12]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4868/6000 [10:39<03:43,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4896/6000 [10:43<02:46,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 41, 41] \n",
      "d[processed_question]: Find the Euclidian length of [1 8 4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4951/6000 [10:50<02:05,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4968/6000 [10:52<01:51,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 5080/6000 [11:06<01:54,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 7, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 6 6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 5305/6000 [11:35<01:50,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41, 0, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [2 9 9]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 5395/6000 [11:48<01:58,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 1, 7, 2, 41, 0, 2, 7, 8, 2, 41, 7, 5, 3, 41, 1, 7, 41, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [1 6 15]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 5661/6000 [12:22<00:55,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 1, 7, 2, 41, 0, 2, 7, 8, 2, 41, 7, 5, 3, 41, 1, 7, 41, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [5 7 16]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 5719/6000 [12:29<00:42,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [2, 1, 7, 2, 41, 0, 2, 7, 8, 2, 41, 7, 5, 3, 41, 1, 7, 41, 8] \n",
      "d[processed_question]: What is the magnitude of the vector [5 8 16]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 5937/6000 [12:57<00:09,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 22, 41, 41, 1, 22, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the length of the result from applying F to I if F has length 3 and I has length 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 5978/6000 [13:03<00:02,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 7, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 8 6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [13:05<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy 0.633\n",
      "Test value accuracy 0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score_model(model, test_data) # t5small, 15 epochs, score on open ended response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/6000 [00:00<07:17, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 38/6000 [00:03<09:40, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 6 11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 182/6000 [00:20<09:50,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 6 10]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 367/6000 [00:42<16:03,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 41, 11, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 9 8]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 526/6000 [01:00<09:50,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 10 11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 821/6000 [01:31<10:30,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 7, 41, 5, 3, 41, 1, 7, 41, 8, 2, 1, 41, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 9 11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1272/6000 [02:24<09:23,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 7 10]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1709/6000 [03:15<08:28,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 7 5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1838/6000 [03:29<07:54,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 41, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 6 4]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2143/6000 [04:05<08:15,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 8 10]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2417/6000 [04:36<07:02,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 41, 41, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 9 5]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3130/6000 [05:59<04:08, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 5, 41, 41, 41, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 7 18]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3324/6000 [06:19<05:05,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 41, 41, 5, 3, 41, 1, 41, 38, 8, 2, 1, 38, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 10 16].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3538/6000 [06:43<05:59,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 8, 2, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 10 5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 4137/6000 [07:50<04:38,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 1, 41, 41, 41, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 7 4]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 4279/6000 [08:05<02:55,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 7, 3, 41, 1, 41, 41, 5, 3, 41, 1, 41, 38, 8, 2, 1, 38, 41, 41] \n",
      "d[processed_question]: Compute the magnitude of [1 6 16].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 5668/6000 [10:42<00:31, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0, 2, 1, 41, 41, 5, 3, 1, 1, 41, 41, 41, 41, 11, 2, 41, 41] \n",
      "d[processed_question]: What is the magnitude of the vector [4 7 8]?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [11:19<00:00,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy 0.782\n",
      "Test value accuracy 0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score_model(model, test_data) # t5small, 25 epochs, score on open ended response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [9:57:29<00:00,  5.97s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test value accuracy 0.953\n",
      "Avg number of tries 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIES = 10\n",
    "NUM_GEN_ANS = 25\n",
    "\n",
    "model.eval()\n",
    "value_match, equation_match = [], []\n",
    "wrong_val, wrong_eqn = [], []\n",
    "tries = []\n",
    "with torch.no_grad():\n",
    "    for d in tqdm(test_data):\n",
    "        if d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "            val_match = eq_match = False\n",
    "            try_number = NUM_TRIES - 1\n",
    "        else:\n",
    "            result = []\n",
    "            for _ in range(NUM_GEN_ANS):\n",
    "                pred = evaluate(d, model)\n",
    "                result.append(str(pred))\n",
    "            counts = Counter(result)\n",
    "            counts = sorted(counts.items(), key=lambda x: eval(x[0]))\n",
    "            preds = [elt[0] for elt in sorted(counts, key=lambda x: (x[1], random.random()), reverse=True)][:min(len(counts),NUM_TRIES)]\n",
    "            val_match = 0\n",
    "            for try_number in range(len(preds)):\n",
    "                try:\n",
    "                    d_try = d.copy()\n",
    "                    d_try['pred_tokens'] = [out_vocab.idx2token[idx] for idx in preds[try_number]]\n",
    "                    val_match, eq_match = check_match(eval(preds[try_number]), d_try)\n",
    "                    nP = d['nP']\n",
    "                    pred = sub_nP(d['pred_tokens'], nP)\n",
    "                    print(pred)\n",
    "                    print(evaluate_prefix_expression(pred))\n",
    "                except:\n",
    "#                     print(\"pred:\", eval(preds[try_number], \"\\nd[processed_question]:\", d['processed_question'])\n",
    "                    pass\n",
    "                if val_match == 1:\n",
    "                    break\n",
    "                    \n",
    "#             try:\n",
    "#                 val_match, eq_match = check_match(pred, d)\n",
    "#             except:\n",
    "#                 print(\"pred:\", pred, \"\\nd[processed_question]:\", d['processed_question'])\n",
    "#                 continue\n",
    "        tries.append(try_number + 1)\n",
    "        value_match.append(val_match)\n",
    "        equation_match.append(eq_match)\n",
    "        if val_match != 0:\n",
    "            wrong_val.append(d['raw_question'])\n",
    "        if equation_match != 0:\n",
    "            wrong_eqn.append(d['raw_question'])\n",
    "# print(f'Test equation accuracy {np.mean(equation_match):.3g}')\n",
    "print(f'Test value accuracy {np.mean(value_match):.3g}') # v3\n",
    "print(f'Avg number of tries {np.mean(tries):.3g}') # v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Own Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expression': '', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'processed_question': 'What is the value of theta^T times x plus theta_0 if theta = [1, 1] , theta_0 = negative 0.5, and x = [1, 1]^T ?', 'raw_question': 'What is the value of theta^T times x plus theta_0 if theta = [1, 1] , theta_0 = negative 0.5, and x = [1, 1]^T ?'}\n",
      "['-0.5']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Try inputting a question into the model by changing the `question` variable.\n",
    "\"\"\"\n",
    "\n",
    "question = \"What is the value of theta^T times x plus theta_0 if theta = [1, 1] , theta_0 = negative 0.5, and x = [1, 1]^T ?\"\n",
    "if question[-1] not in {'.', '?'}:\n",
    "    question += \"?\"\n",
    "d = [{\"expression\": \"\", \"quant_cell_positions\": get_quant_cells(question), \"processed_question\": question, \"raw_question\": question}]\n",
    "_, input_question_data, _, _, _, _ = setup(use_t5, test_split=1, data=d)\n",
    "tensorize_data([], input_question_data)\n",
    "input_question = input_question_data[0]\n",
    "result = []\n",
    "for i in range(50):\n",
    "    pred = evaluate(input_question, model)\n",
    "    test['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "    parse_tree = sub_nP(test['pred_tokens'], test['nP'])\n",
    "#     print(\"parse tree:\", parse_tree)\n",
    "    try:\n",
    "        result.append(str(evaluate_prefix_expression(parse_tree)))\n",
    "    except:\n",
    "        i += 1\n",
    "    \n",
    "counts = Counter(result)\n",
    "counts = sorted(counts.items(), key=lambda x: eval(x[0]))\n",
    "answers = [elt[0] for elt in sorted(counts, key=lambda x: (x[1], random.random()), reverse=True)]\n",
    "print(answers)\n",
    "x_ticks = [i[0] for i in counts]\n",
    "freq = [i[1] for i in counts]\n",
    "\n",
    "plt.bar(x_ticks, freq)\n",
    "plt.xticks(rotation=30, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix Code (calculate percent error for each topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_val_2 = []\n",
    "wrong_eqn_2 = []\n",
    "for elt in wrong_val:\n",
    "    elt = elt.replace(\",\",\"\")\n",
    "    elt = elt.replace(\".\", \"\")\n",
    "    elt = elt.replace(\" \",\"\")\n",
    "    elt = elt.replace(\"negative\", \"\")\n",
    "    elt = elt.replace(\"-\", \"\")\n",
    "    for i in range(10):\n",
    "        elt = elt.replace(str(i),\"\")\n",
    "    wrong_val_2.append(elt)\n",
    "for elt in wrong_eqn:\n",
    "    elt = elt.replace(\",\",\"\")\n",
    "    elt = elt.replace(\".\", \"\")\n",
    "    elt = elt.replace(\" \",\"\")\n",
    "    elt = elt.replace(\"negative\", \"\")\n",
    "    elt = elt.replace(\"-\", \"\")\n",
    "    for i in range(10):\n",
    "        elt = elt.replace(str(i),\"\")\n",
    "    wrong_eqn_2.append(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_val_counts = dict()\n",
    "wrong_eqn_counts = dict()\n",
    "for elt in wrong_val_2:\n",
    "    wrong_val_counts[elt] = wrong_val_counts.get(elt, 0) + 1\n",
    "for elt in wrong_eqn_2:\n",
    "    wrong_eqn_counts[elt] = wrong_eqn_counts.get(elt, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ifx=[]whatis||x||?': 102,\n",
       " 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 125,\n",
       " 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 104,\n",
       " 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 99,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 512,\n",
       " 'FindtheEuclidianlengthof[]': 98,\n",
       " 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 90,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 510,\n",
       " 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 94,\n",
       " 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 126,\n",
       " 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 97,\n",
       " 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 93,\n",
       " 'Letq=AfterQlearningwhatisqifaisandtis?': 91,\n",
       " 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 503,\n",
       " 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 496,\n",
       " 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 101,\n",
       " 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 93,\n",
       " 'Computethemagnitudeof[]': 115,\n",
       " 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 82,\n",
       " 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 97,\n",
       " 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 104,\n",
       " 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 94,\n",
       " 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 112,\n",
       " 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 94,\n",
       " 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 96,\n",
       " 'Whatisthemagnitudeofthevector[]?': 108,\n",
       " 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 90,\n",
       " 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 97,\n",
       " 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 94,\n",
       " 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 103,\n",
       " 'Letaninputvectorbe[]Whatisitsmagnitude?': 93,\n",
       " 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 92,\n",
       " 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 95,\n",
       " 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 84,\n",
       " 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 80,\n",
       " 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 83,\n",
       " 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 94,\n",
       " 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 95,\n",
       " 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 83,\n",
       " 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 19,\n",
       " 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 110,\n",
       " 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 82,\n",
       " 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 77,\n",
       " 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 13}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ifx=[]whatis||x||?': 108,\n",
       " 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 125,\n",
       " 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 104,\n",
       " 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 99,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 512,\n",
       " 'FindtheEuclidianlengthof[]': 98,\n",
       " 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 90,\n",
       " 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 96,\n",
       " 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 510,\n",
       " 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 94,\n",
       " 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 126,\n",
       " 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 89,\n",
       " 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 97,\n",
       " 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 93,\n",
       " 'Letq=AfterQlearningwhatisqifaisandtis?': 91,\n",
       " 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 113,\n",
       " 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 503,\n",
       " 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 496,\n",
       " 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 101,\n",
       " 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 93,\n",
       " 'Computethemagnitudeof[]': 115,\n",
       " 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 90,\n",
       " 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 97,\n",
       " 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 94,\n",
       " 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 112,\n",
       " 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 94,\n",
       " 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 96,\n",
       " 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 110,\n",
       " 'Whatisthemagnitudeofthevector[]?': 108,\n",
       " 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 90,\n",
       " 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 97,\n",
       " 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 94,\n",
       " 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 103,\n",
       " 'Letaninputvectorbe[]Whatisitsmagnitude?': 93,\n",
       " 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 97,\n",
       " 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 92,\n",
       " 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 95,\n",
       " 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 84,\n",
       " 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 99,\n",
       " 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 102,\n",
       " 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 108,\n",
       " 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 100,\n",
       " 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 110,\n",
       " 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 82}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_eqn_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_to_topic = {'Whatisthemagnitudeofthevector[]?': 'b', 'Letaninputvectorbe[]Whatisitsmagnitude?': 'b', 'Ifx=[]whatis||x||?': 'b', 'Computethemagnitudeof[]': 'b', 'FindtheEuclidianlengthof[]': 'b', 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 'p', 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 'p', 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 'p', 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 'p', 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 'p', 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 'f', 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 'f', 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 'f', 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 'f', 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 'f', 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 'lg', 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 'lg', 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 'lg', 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 'r', 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 'r', 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 'r', 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 'r', 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 'r', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_i', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_ii', 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 'cnn', 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 'cnn', 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 'cnn', 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 'rnn', 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 'rnn', 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 'rnn', 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 'rnn', 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 'rnn', 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 'sm_mdp', 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 'rl', 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 'rl', 'Letq=AfterQlearningwhatisqifaisandtis?': 'rl', 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 'rl', 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 'rl', 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 'dtnn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_to_wrong_val = dict()\n",
    "topic_to_wrong_eqn = dict()\n",
    "for question in wrong_val_counts:\n",
    "    topic = question_to_topic[question]\n",
    "    topic_to_wrong_val[topic] = topic_to_wrong_val.get(topic, 0) + wrong_val_counts[question]\n",
    "for question in wrong_eqn_counts:\n",
    "    topic = question_to_topic[question]\n",
    "    topic_to_wrong_eqn[topic] = topic_to_wrong_eqn.get(topic, 0) + wrong_eqn_counts[question]\n",
    "topic_to_wrong_val_percent_correct = {k:1 - topic_to_wrong_val[k]/len(test_data) for k in topic_to_wrong_val}\n",
    "topic_to_wrong_eqn_percent_correct = {k:1 - topic_to_wrong_eqn[k]/len(test_data) for k in topic_to_wrong_eqn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Rates per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8497435897435898\n",
      "0.9205555555555556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b': 0.914,\n",
       " 'p': 0.9173333333333333,\n",
       " 'f': 0.9183333333333333,\n",
       " 'rl': 0.9443333333333334,\n",
       " 'nn_i': 0.9146666666666666,\n",
       " 'lg': 0.9235,\n",
       " 'nn_ii': 0.915,\n",
       " 'r': 0.916,\n",
       " 'cnn': 0.924,\n",
       " 'dtnn': 0.9161666666666667,\n",
       " 'sm_mdp': 0.9173333333333333,\n",
       " 'rnn': 0.926}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum([topic_to_wrong_val_percent_correct[elt] for elt in topic_to_wrong_val_percent_correct])/(len(topic_to_wrong_val_percent_correct)+1))\n",
    "print(sum([topic_to_wrong_val_percent_correct[elt] for elt in topic_to_wrong_val_percent_correct])/(len(topic_to_wrong_val_percent_correct)))\n",
    "topic_to_wrong_val_percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n",
      "0.9166666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b': 0.913,\n",
       " 'p': 0.9173333333333333,\n",
       " 'f': 0.9183333333333333,\n",
       " 'rl': 0.9151666666666667,\n",
       " 'nn_i': 0.9146666666666666,\n",
       " 'lg': 0.9213333333333333,\n",
       " 'cnn': 0.9196666666666666,\n",
       " 'nn_ii': 0.915,\n",
       " 'r': 0.916,\n",
       " 'rnn': 0.916,\n",
       " 'dtnn': 0.9161666666666667,\n",
       " 'sm_mdp': 0.9173333333333333}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum([topic_to_wrong_eqn_percent_correct[elt] for elt in topic_to_wrong_eqn_percent_correct])/(len(topic_to_wrong_eqn_percent_correct)+1))\n",
    "print(sum([topic_to_wrong_eqn_percent_correct[elt] for elt in topic_to_wrong_eqn_percent_correct])/(len(topic_to_wrong_eqn_percent_correct)))\n",
    "topic_to_wrong_eqn_percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percent Correct')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_keys_val = sorted(tuple(topic_to_wrong_val_percent_correct),reverse=True,key=lambda x: topic_to_wrong_val_percent_correct[x])\n",
    "# sorted_keys_eqn = sorted(tuple(topic_to_wrong_eqn_percent_correct),reverse=True,key=lambda x: topic_to_wrong_eqn_percent_correct[x])\n",
    "plot = pd.DataFrame({\"Value Accuracy\": [topic_to_wrong_val_percent_correct[key] for key in sorted_keys_val],\"Equation Accuracy\": [topic_to_wrong_eqn_percent_correct[key] for key in sorted_keys_val]}, index=sorted_keys_val).plot(kind=\"bar\",title=\"Test Accuracy by Topic\",figsize=(8, 4))\n",
    "plot.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Percent Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-40bfd8a5af52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_to_wrong_val_percent_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Topic to Percentage Correct (Value Accuracy)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_plot' is not defined"
     ]
    }
   ],
   "source": [
    "generate_plot(topic_to_wrong_val_percent_correct,\"Topic to Percentage Correct (Value Accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_plot(topic_to_wrong_eqn_percent_correct,\"Topic to Percentage Correct (Equation Accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
