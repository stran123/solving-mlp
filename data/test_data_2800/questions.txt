A point p is classified by a classifier whose decision boundary is theta = ( 2 4 ) . How does it classify p , where p is ( 1 negative 1 ) ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 4 ) . How does it classify p , where p is ( 0 0 ) ?
Calculate the entropy of the left region of a 2D plane, split by a line . There are 1 points on the left side that are positive , 23 points on the right side , and 44 points total .
Let s_0 be 0 , w be 1.5 , and x be [ 2 2 0 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
Given an image row [ 1 1 1 ] and filter [ 4 4 0 ] , what is the result from applying the filter to the image row such that they both align ?
If we have x equals ( 1 negative 1 ), theta equals ( 1 negative 1 ), and theta_0 equals negative 3 , then what is the result of theta times x plus theta_0 ?
Consider the point ( negative 1 0 ) , the theta 2 and the theta_0 1 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
If the decision boundary of a classifier is theta , where theta is equal to ( 2 4 ) , how does it classify point p , where p is equal to ( 3 negative 3 ) ?
Consider the classifier [ 1 2 0 ] and [ 4 2 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
f(theta) is the square of the sum of 8 and the product of 7 and theta , where theta is 1 . What is f(theta) ?
Consider the point ( negative 2 2 ) , the theta 2 and the theta_0 3 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
If you let theta be 0 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 2 * theta + 3 ) ^ 3 ?
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 negative 1 ) , ( 1 negative 1 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 4 with weight wOC being 2 . What is the output of neuron C ?
What is the length of the output when we use an image of length 50 and a filter of length 7 if we use a stride length of 1 ?
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 23 points on the right side , and 45 points total .
Neurons A and B take inputs 1 and 1 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 1 . What is the output ?
What is the loss for the data point ( negative 2 negative 1 ) if we use NLL . Let theta be 2 and theta_0 be 0 . Also use natural log where the base is 2.71828 .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 1 .
Compute the mean squared error with the data points  [ ( 2 1 )  and ( 1 3 ) ] , theta = 1 , and lda = 0.5 .
The left side of a region has 27 points . Of the 27 points , 4 are classified as positive . What is the entropy of the left region if there are 45 points in total ?
If x = [ 4 1 1 ], what is || x || ?
If filter F has length 41 and an image I has length 50 , what is the length of the result from applying F to I ?
Given the values for theta as 2 and theta_0 as 3 , compute the NLL loss on the data point ( 2 1 ) . Use log base e of 2.71828 for the log .
Given a function ( 2 * theta + negative 2 ) ^ 2 , calculate the value of the function after one gradient descent update if theta is 2 and eta is 0.01 .
Calculate the value of the function ( 2 * theta + 2 ) ^ 3 after updating the theta value in one step of gradient descent . Have theta be 1 and eta be 0.01 .
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 2 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
Consider the input x_t = [ 11 10 16 6 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_4 if our initial conditions are s_0 is 16 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t .
What is the margin of a classifier with theta being 1 and theta_0 being negative 2 on a point 3 with label 1 ?
Given the largest magnitude of a point as 17 and the margin of the dataset be 5 from the separator , compute the most number of mistakes made by the perceptron algotithm .
f(theta) is the square of the sum of 6 and the product of 6 and theta , where theta is 1 . What is f(theta) ?
What is the updated Q value of a tuple ( s a ) if q is 9 , the a is 0.1 , and t is 2 ?
After applying Q learning to q = 7 , what is its value ? Let the t be 8 and a be 0.2 .
Given the input negative 34 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
What is the NLL loss for the single data point ( 0 negative 1 ) where theta is 2 and theta_0 is 3 ? Let the log be natural log ( base is 2.71828 ) .
What is the size of the margin of a point 4 by a classifier with theta negative 1 and theta_0 2 if the point has label negative 1 ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 3 , and wOC is 2 ?
Given a function ( 2 * theta + negative 1 ) ^ 3 , calculate the value of the function after one gradient descent update if theta is 0 and eta is 0.05 .
What does the sigmoid function return when  you pass into it negative 23 ? Hint: have e be 2.71828 .
Calculate the value of the function ( 2 * theta + negative 1 ) ^ 2 after updating the theta value in one step of gradient descent . Have theta be 2 and eta be 0.05 .
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 1 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
Consider a filter [ 0 4 0 ] applied on an image [ 3 3 0 ] . What is the output if the filter has a ReLU activation ?
What is the most number of mistakes made by the perceptron algorithm if 15 is the maximum magnitude of a point in the dataset and the dataset has a margin of 4 to the separator .
If there are 48 points on a 2D plane , 26 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 3 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
Given the classifiers [ 1 2 1 ] and [ 4 1 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 5 and the maximum magnitude of a point is 2 .
What is the loss for the data point ( 0 negative 1 ) if we use NLL . Let theta be 2 and theta_0 be 0 . Also use natural log where the base is 2.71828 .
If we have a neural network layer with 30 inputs and 60 outputs , how many weights ( including biases ) are needed to describe each connection ?
If you are given two classifiers [ 1 0 1 ] and [ 3 3 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Compute the output of the sigmoid function when we pass in negative 1 . Let e be equal to 2.71828 .
If we have an image of size 90 by 90 and a filter of size 27 by 27 , how far out on each side should we pad to maintain the same output dimensions ?
If we let theta be 3 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 2 5 ) ] ?
Given theta be 0 and eta be 0.01 , calculate the value of the function ( 2 * theta + negative 1 ) ^ 3 after one step of gradient descent .
Given an image of length 50 and a filter of length 15 , compute the output from applying the filter if we have a stride length of 2 ?
Consider an image I of length 51 and filter F of length 5 . What is the length of the output if we have a stride length of 1 ?
If we let theta be 0 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 negative 2 )  and ( 1 4 ) ] ?
Using a stride length of 2 , what is the output from applying a filter of length 15 to an image of length 50 ?
Assume e is equal to 2.71828 . What do you get from passing the value negative 47 into the sigmoid function ?
Let 2 be the margin of the dataset with respect to the separator . Also let 15 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
What is the total number of outputs for a zero-padded max pooling layer that has 20 inputs , a stride of 1 , and a pooling filter size of 5 ?
Using a row of an image [ 1 3 0 ] and filter [ 3 0 1 ] , calculate the value from applying the filter which has a ReLU on its output .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 2 , and wOC is 2 ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 4 , and wOC is 2 ?
What is the value of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is negative 3 ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 1 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 3 and applies an ReLU on its output . Compute the output .
Compute the output of the sigmoid function when we pass in 25 . Let e be equal to 2.71828 .
Using the row of an image  [ 1 0 0 ] and a filter [ 1 2 1 ] , calculate the value of applying the filter on top of the image .
How much padding is needed on each side of a 80 by 80 input using a 15 by 15 filter to get an output the same size as the input ?
Given an image row [ 3 3 1 ] and filter [ 1 0 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 1 negative 3 ) ?
Given a function ( 2 * theta + negative 1 ) ^ 2 , calculate the value of the function after one gradient descent update if theta is 3 and eta is 0.01 .
Do the two classifiers [ 4 1 0 ] and [ 2 4 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_4 if we have s_0 being 16 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 2 * s_t , and we input [ 16 16 4 0 ] ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 5 . Neuron B has input 3 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
If a point 2 with label 1 was classified by a classifier with theta negative 1 and theta_0 1 , what is the margin of this point ?
A max pooling layer has 14 inputs, a pooling filter length of 3 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
Given a 50 by 50 image and 9 by 9 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
What is the value from applying a filter [ 2 3 1 ] directly on top of an image  [ 1 3 0 ] ?
What is the most number of mistakes made by the perceptron algorithm if 2 is the maximum magnitude of a point in the dataset and the dataset has a margin of 1 to the separator .
Given the dataset [ ( 0 1 ) , ( 1 2 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 1 ?
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 1 ) , ( 1 negative 2 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 3 ?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 1.5 , w is 1 , and x is [ 0 3 1 ] ?
An image I has length 50 and filter F has length 7 , what is the length of the result of applying F to I ?
Using the row of an image  [ 1 0 1 ] and a filter [ 0 4 0 ] , calculate the value of applying the filter on top of the image .
If we are given the classifiers [ 1 3 1 ] and [ 3 0 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Using a filter [ 1 3 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 0 3 0 ] .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 3 and a ReLU on its output . Compute the output of this neural network .
Consider a filter [ 4 4 1 ] applied on an image [ 2 3 1 ] . What is the output if the filter has a ReLU activation ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 0 , w = 0.5 , and x = [ 1 0 2 ] , what is s_3 ?
Given theta be 1 and eta be 0.01 , calculate the value of the function ( 2 * theta + 0 ) ^ 2 after one step of gradient descent .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 negative 2 ) , ( 1 negative 2 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
What is the result from applying a filter [ 0 2 1 ] to a row of an image [ 4 3 1 ] , where the filter has a ReLU activation on its output ?
Compute the magnitude of [ 1 5 ] .
Consider the classifier [ 1 3 0 ] and [ 2 1 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Given the largest magnitude of a point as 19 and the margin of the dataset be 3 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 1 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 2 . What is the output ?
Given 45 points on a plane , 27 of them are on the right side of a line , and 1 of them that are on the left side are positive . Compute the entropy of the left side .
Neurons A and B take inputs 1 and 3 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 2 . What is the output ?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 2 , w is 0 , and x is [ 1 0 2 ] ?
What is f(theta) if f(theta) is theta times 10 plus 8 squared and theta is 2 ?
Given the largest magnitude of a point as 15 and the margin of the dataset be 2 from the separator , compute the most number of mistakes made by the perceptron algotithm .
What is the margin on a point 4 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 negative 1 ?
What is the total number of outputs for a zero-padded max pooling layer that has 26 inputs , a stride of 1 , and a pooling filter size of 5 ?
Using the row of an image  [ 1 1 1 ] and a filter [ 3 4 1 ] , calculate the value of applying the filter on top of the image .
A point p is classified by a classifier whose decision boundary is theta = ( 1 4 ) . How does it classify p , where p is ( 1 negative 2 ) ?
Let s_0 be 0 , w be 0.1 , and x be [ 1 0 2 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
If we have x equals ( 0 0 ), theta equals ( 1 negative 1 ), and theta_0 equals 6 , then what is the result of theta times x plus theta_0 ?
If we have x equals ( 0 0 ), theta equals ( negative 2 1 ), and theta_0 equals 0.25 , then what is the result of theta times x plus theta_0 ?
What is the margin on a point 4 with a label 1 if it is classified by a classifier with theta 1 and theta_0 1 ?
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 4 with weight wOC being 2 . What is the output of neuron C ?
If we know the stride 2 of a max pooling layer , along with the filter length of 5 and input length of 12 , what is the number of outputs of this layer ?
Neurons A and B take inputs negative 1 and 0 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 2 , respectively , and with offset 5 . Neuron C also applies a ReLU on its output . What is the output ?
An image I has length 60 and filter F has length 19 , what is the length of the result of applying F to I ?
What is the most number of mistakes made by the perceptron algorithm if 7 is the maximum magnitude of a point in the dataset and the dataset has a margin of 1 to the separator .
We define an RNN as s_t = w * s_t-1 + x_t . What is s_2 if s_0 is 1.5 , w is 0.1 , and x is [ 0.25 0.5 ] ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 12 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , compute y_6 if the input is x_t = [ 18 12 18 5 17 15 ] .
Let an input vector be [ 8 0 ] . What is its magnitude ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 1 .
Assume e is equal to 2.71828 . What do you get from passing the value 25 into the sigmoid function ?
Given the dataset [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 1 ?
If f(theta) is 2 times theta plus 8 squared , what is f(theta) when theta is 2 ?
What is the NLL loss for the single data point ( negative 1 1 ) where theta is 2 and theta_0 is 1 ? Let the log be natural log ( base is 2.71828 ) .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 10 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , compute y_6 if the input is x_t = [ 11 8 12 16 4 0 ] .
If f(theta) is 7 times theta plus 6 squared , what is f(theta) when theta is 2 ?
What is the value from applying a filter [ 1 3 1 ] directly on top of an image  [ 1 1 1 ] ?
Given two classifiers [ 3 1 1 ] and [ 0 0 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Given the largest magnitude of a point as 6 and the margin of the dataset be 4 from the separator , compute the most number of mistakes made by the perceptron algotithm .
After applying Q learning to q = 8 , what is its value ? Let the t be 6 and a be 0.1 .
x is ( negative 1 0 ) , theta is ( negative 2 1 ) and theta_0 is negative 3 . What is the value of theta times x plus theta_0?
Given 46 points on a plane , 27 of them are on the right side of a line , and 3 of them that are on the left side are positive . Compute the entropy of the left side .
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 2 .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 20 inputs and 90 outputs .
What is the most number of mistakes made by the perceptron algorithm if 18 is the maximum magnitude of a point in the dataset and the dataset has a margin of 3 to the separator .
Given the dataset [ ( 0 negative 2 ) , ( 1 0 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 1 is minimal . What does y need to be if lambda is 1 ?
If there are 47 points on a 2D plane , 25 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
Calculate the value of y in the dataset [ ( 0 2 ) , ( 1 negative 1 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 2 ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 20 inputs and 140 outputs ?
What is the value from applying a filter [ 0 2 1 ] directly on top of an image  [ 1 2 1 ] ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 60 outputs and 30 inputs .
Given the values for theta as 2 and theta_0 as 3 , compute the NLL loss on the data point ( 0 1 ) . Use log base e of 2.71828 for the log .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 40 inputs and 180 outputs ?
Neuron A takes in value 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 1 . Compute the output of this neural network .
Given a 80 by 80 image and 9 by 9 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
What is the size of the margin of a point 1 by a classifier with theta 1 and theta_0 2 if the point has label negative 1 ?
Using a row of an image [ 0 3 0 ] and filter [ 0 2 0 ] , calculate the value from applying the filter which has a ReLU on its output .
The left side of a region has 25 points . Of the 25 points , 2 are classified as positive . What is the entropy of the left region if there are 47 points in total ?
If a region has 27 points on the left and 44 points total . 4 points that are on the left are positive. Compute the entropy .
If x = [ 4 1 ] , what is || x || ?
Using a stride length of 1 , what is the output from applying a filter of length 15 to an image of length 51 ?
Consider the input x_t = [ 17 9 1 1 17 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_5 if our initial conditions are s_0 is 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t .
Given the classifiers [ 1 4 0 ] and [ 3 0 1 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Using a filter [ 2 3 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 4 3 1 ] .
Calculate the value of the function ( 2 * theta + negative 2 ) ^ 2 after updating the theta value in one step of gradient descent . Have theta be 1 and eta be 0.01 .
Given a loss function , ( 0 * theta + 3 ) ^ 2 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 1 and eta be 0.05 .
Let q = 2 . After Q learning, what is q if a is 0.1 and t is 10 ?
Neurons A and B take inputs 1 and 1 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 3 . What is the output ?
If filter F has length 33 and an image I has length 70 , what is the length of the result from applying F to I ?
If we are given the classifiers [ 1 4 0 ] and [ 0 1 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What does the sigmoid function return when  you pass into it 19 ? Hint: have e be 2.71828 .
What is the loss for the data point ( 1 negative 2 ) if we use NLL . Let theta be 2 and theta_0 be 0 . Also use natural log where the base is 2.71828 .
What is the most number of mistakes made by the perceptron algorithm if 3 is the maximum magnitude of a point in the dataset and the dataset has a margin of 4 to the separator .
Given the classifiers [ 1 4 0 ] and [ 3 2 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Consider the classifier [ 0 1 1 ] and [ 4 1 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
What is the most number of mistakes made by the perceptron algorithm if 12 is the maximum magnitude of a point in the dataset and the dataset has a margin of 2 to the separator .
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 1 ) , ( 1 negative 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 1 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 3 with weight wOC being 2 . What is the output of neuron C ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 2 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 1 points on the left side that are positive , 27 points on the right side , and 46 points total .
What is the result of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 3 ?
Given the classifiers [ 1 3 1 ] and [ 4 4 1 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Given a 60 by 60 image and 19 by 19 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , compute y_3 if the input is x_t = [ 14 16 15 ] .
What is the length of the result from applying F to I if F has length 15 and I has length 80?
Neurons A and B take inputs negative 1 and 4 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 2 , respectively , and with offset 4 . Neuron C also applies a ReLU on its output . What is the output ?
Given an image row [ 1 1 1 ] and filter [ 3 4 1 ] , what is the result from applying the filter to the image row such that they both align ?
How much padding is needed on each side of a 80 by 80 input using a 39 by 39 filter to get an output the same size as the input ?
What is the margin on a point 2 with a label 1 if it is classified by a classifier with theta 1 and theta_0 negative 2 ?
If you are given two classifiers [ 1 3 1 ] and [ 1 3 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
What is the total number of outputs for a zero-padded max pooling layer that has 24 inputs , a stride of 1 , and a pooling filter size of 1 ?
If you let theta be 1 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( 1 * theta + 3 ) ^ 3 ?
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 negative 1 ) , ( 1 negative 2 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Compute the output length given the stride 1 , image length 54 , and filter length 7 .
What is the margin on a point 4 with a label 1 if it is classified by a classifier with theta 1 and theta_0 negative 2 ?
What is the length of the output when we use an image of length 51 and a filter of length 5 if we use a stride length of 2 ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 10 inputs and 110 outputs ?
What is the margin of a classifier with theta being 1 and theta_0 being 0 on a point 1 with label negative 1 ?
Calculate the updated theta after one gradient descent step if theta is 0 , eta is 0.05 , and the loss function is ( negative 2 * theta + 3 ) ^ 2 .
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 2 . Neuron B has input 3 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
Let theta be ( negative 2 1 ) , theta_0 be 0.25, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .
Determine if the following two classifiers represent the same hyperplane , [ 0 1 0 ] and [ 3 1 0 ] . If so , return 1 , and return anything else otherwise .
What is the entropy of the left side of a region containing 27 points where the plane has 48 points in total and 2 points on the left are positive ?
x is ( 0 0 ) , theta is ( negative 2 1 ) and theta_0 is 2 . What is the value of theta times x plus theta_0?
Neurons A and B take inputs 1 and 0 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 1 . What is the output ?
Let a function f(theta) = ( 2 * theta + 0 ) ^ 4 . For theta = 4 and eta = 0.05 , calculate f(theta) after one gradient descent update .
If the classifiers [ 2 1 0 ] and [ 4 4 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Consider the classifier [ 1 4 0 ] and [ 0 2 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 4 and a ReLU on its output . Compute the output of this neural network .
Using a stride length of 2 , what is the output from applying a filter of length 17 to an image of length 53 ?
If you are given two classifiers [ 1 0 0 ] and [ 4 3 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
What is the output y_3 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , and input x_t = [ 15 2 12 ] ?
Given a 1D image I that is length 60 and a filter F that is length 3 , what is the length of the result from applying F to I ?
If we are given the classifiers [ 1 0 1 ] and [ 2 0 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is negative 3 ?
What is the total number of outputs for a zero-padded max pooling layer that has 22 inputs , a stride of 1 , and a pooling filter size of 1 ?
Given theta = 3 and lda = 1 , compute the mean squared error with the data points [ ( 2 0 )  and ( 2 5 ) ] .
A left region has 4 points classified as positive. There are 47 points in the plane , and 26 points on the left . Compute the entropy .
A max pooling layer has 12 inputs, a pooling filter length of 1 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
Let s_0 be 1 , w be 0.5 , and x be [ 0 3 1 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
If f(theta) is 5 times theta plus 3 squared and theta is 2 what is f(theta) ?
What is the value from applying a filter [ 0 1 0 ] directly on top of an image  [ 1 0 1 ] ?
Compute the magnitude of [ 2 6 1 ] .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 26 points on the right side , and 44 points total .
If x = [ 1 6 1 ], what is || x || ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 negative 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
Using the row of an image  [ 1 4 0 ] and a filter [ 1 2 1 ] , calculate the value of applying the filter on top of the image .
If we have a neural network layer with 20 inputs and 10 outputs , how many weights ( including biases ) are needed to describe each connection ?
Given a function ( 2 * theta + 1 ) ^ 4 , calculate the value of the function after one gradient descent update if theta is 1 and eta is 0.05 .
Given an image row [ 1 3 1 ] and filter [ 3 3 0 ] , what is the result from applying the filter to the image row such that they both align ?
If a is 0.1 and t is 6 , what is the Q learning value after applying one tuple ( s a ) if q is 0 ?
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 4 .
With lambda = 0.5 , the optimal theta is 2 . If the datapoints are [ ( 0 0 ) , ( 1 0 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Given a 1D image I that is length 60 and a filter F that is length 29 , what is the length of the result from applying F to I ?
Given the largest magnitude of a point as 4 and the margin of the dataset be 4 from the separator , compute the most number of mistakes made by the perceptron algotithm .
What is the result of applying the value 16 to the sigmoid function ? Let e be equal to 2.71828 .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , compute y_3 if the input is x_t = [ 10 10 1 ] .
What is the total number of outputs for a zero-padded max pooling layer that has 18 inputs , a stride of 1 , and a pooling filter size of 3 ?
If filter F has length 33 and an image I has length 90 , what is the length of the result from applying F to I ?
f(theta) is the square of the sum of 8 and the product of 3 and theta , where theta is 2 . What is f(theta) ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 0 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 2 and applies an ReLU on its output . Compute the output .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 negative 2 ) , ( 1 negative 1 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
If we have a neural network layer with 20 inputs and 150 outputs , how many weights ( including biases ) are needed to describe each connection ?
If we have a neural network layer with 10 inputs and 190 outputs , how many weights ( including biases ) are needed to describe each connection ?
If you let theta be 0 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( 2 * theta + 3 ) ^ 4 ?
What is the result of theta times x plus theta_0 if x is ( 1 0 ), theta is ( negative 2 1 ) , and theta_0 is 18 ?
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 2 ) , ( 1 negative 2 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
If there are 48 points on a 2D plane , 23 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
What is the minimum number of padding needed to maintain the same output size if the input image is 90 by 90 and the filter is 21 by 21 ?
Using a row of an image [ 2 3 0 ] and filter [ 0 3 1 ] , calculate the value from applying the filter which has a ReLU on its output .
What is f(theta) if f(theta) is theta times 8 plus 5 squared and theta is 1 ?
If q is 4 , what is its updated value after applying Q learning if a is 0.1 and t is 10 ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 0.5 , and x is [ 0 3 1 ] , what is s_3 ?
If x = [ 0 4 ] , what is || x || ?
If we are given the classifiers [ 1 0 0 ] and [ 3 0 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
x is ( 1 0 ) , theta is ( 1 negative 1 ) and theta_0 is 0 . What is the value of theta times x plus theta_0?
A point 2 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be 1 .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 20 inputs and 40 outputs ?
If an image has length 80 and filter has length 15 , compute the length of the output from applying the filter to the image ?
Using a row of an image [ 0 3 1 ] and filter [ 2 2 0 ] , calculate the value from applying the filter which has a ReLU on its output .
Given a function ( 0 * theta + 3 ) ^ 2 , compute theta after one gradient descent step if theta is 3 and eta is 0.01 .
Using a row of an image [ 2 3 1 ] and filter [ 2 2 1 ] , calculate the value from applying the filter which has a ReLU on its output .
Given a 1D image I that is length 50 and a filter F that is length 17 , what is the length of the result from applying F to I ?
Consider a 1D classification line on a 2D plane . There is a total of 44 points, 24 of which are on the right and the rest on the left of the boundary . 1 points on the left are classified positive . What is the entropy of the left region ?
Given the classifiers [ 1 1 1 ] and [ 0 2 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
What is the most number of mistakes made by the perceptron algorithm if 20 is the maximum magnitude of a point in the dataset and the dataset has a margin of 5 to the separator .
Given theta = 1 and lda = 1 , compute the mean squared error with the data points [ ( 2 2 )  and ( 2 4 ) ] .
Given the classifiers [ 1 0 1 ] and [ 3 1 1 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
A neural network has inputs x1 = 1 with weight 2 and x2 = 2 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 4 . Compute the output .
Calculate the value of the function ( 2 * theta + 2 ) ^ 4 after updating the theta value in one step of gradient descent . Have theta be 2 and eta be 0.01 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 4 , and wOC is 3 ?
An image I has length 60 and filter F has length 5 , what is the length of the result of applying F to I ?
Consider the input x_t = [ 7 9 12 10 19 19 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_6 if our initial conditions are s_0 is 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t .
Compute the loss from the datapoint ( 0 negative 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
What is the total number of outputs for a zero-padded max pooling layer that has 12 inputs , a stride of 2 , and a pooling filter size of 5 ?
What is the result of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 0 ?
If a is 0.1 and t is 4 , what is the Q learning value after applying one tuple ( s a ) if q is 3 ?
What is the NLL loss for the single data point ( 0 2 ) where theta is 2 and theta_0 is 0 ? Let the log be natural log ( base is 2.71828 ) .
If a point 2 with label negative 1 was classified by a classifier with theta 1 and theta_0 negative 2 , what is the margin of this point ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 2 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 5 and applies an ReLU on its output . Compute the output .
What is the most number of mistakes made by the perceptron algorithm if 18 is the maximum magnitude of a point in the dataset and the dataset has a margin of 2 to the separator .
Compute the output length given the stride 2 , image length 51 , and filter length 11 .
f(theta) is defined as 6 times theta plus 8 squared and theta is 2 . What is f(theta) ?
Now consider a zero-padded max pooling layer with 18 inputs , a pooling filter size of 1 and stride of 2 . How many total output units are there for this layer?
The row of an image  [ 1 3 1 ] has a filter [ 3 0 0 ] applied to it . What is the resulting value if they both align ?
What is the result of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 0.25 ?
Using theta = 3 and lda = 1 , calculate the mean squared error of the points  [ ( 2 0 )  and ( 2 5 ) ] .
Let a function f(theta) = ( 2 * theta + negative 1 ) ^ 3 . For theta = 0 and eta = 0.05 , calculate f(theta) after one gradient descent update .
Consider the classifier [ 3 1 0 ] and [ 1 2 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Given theta = 1 and lda = 1 , compute the mean squared error with the data points [ ( 2 negative 2 )  and ( 2 1 ) ] .
What does the sigmoid function return when  you pass into it negative 49 ? Hint: have e be 2.71828 .
What does the sigmoid function return when  you pass into it negative 1 ? Hint: have e be 2.71828 .
What does the sigmoid function return when  you pass into it 37 ? Hint: have e be 2.71828 .
f(theta) is the square of the sum of 8 and the product of 9 and theta , where theta is 1 . What is f(theta) ?
Compute the magnitude of [ 1 0 3 ] .
What is the most number of mistakes made by the perceptron algorithm if 9 is the maximum magnitude of a point in the dataset and the dataset has a margin of 3 to the separator .
What is the output y_3 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , and input x_t = [ 12 3 8 ] ?
If q is 8 , what is its updated value after applying Q learning if a is 0.1 and t is 6 ?
A max pooling layer has 20 inputs, a pooling filter length of 4 , a stride length of 2 , and is zero-padded . Compute the number of output units for this layer .
Using the row of an image  [ 1 4 1 ] and a filter [ 4 4 1 ] , calculate the value of applying the filter on top of the image .
Given the classifiers [ 1 4 1 ] and [ 0 4 1 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Given theta be 3 and eta be 0.01 , calculate the value of the function ( 2 * theta + 1 ) ^ 2 after one step of gradient descent .
The row of an image  [ 1 0 0 ] has a filter [ 0 0 0 ] applied to it . What is the resulting value if they both align ?
Given theta be 0 and eta be 0.05 , calculate the value of the function ( 2 * theta + negative 1 ) ^ 3 after one step of gradient descent .
Let theta be ( 1 negative 1 ) , theta_0 be 0.5, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .
Find the Euclidian length of [ 0 3 ] .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 3 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , compute y_6 if the input is x_t = [ 11 9 14 4 5 0 ] .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 1 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 4 , and wOC is 2 ?
Neurons A and B take inputs negative 1 and 2 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 2 . Neuron C also applies a ReLU on its output . What is the output ?
If the decision boundary of a classifier is theta , where theta is equal to ( 2 0 ) , how does it classify point p , where p is equal to ( 2 negative 3 ) ?
What is the result of applying the value 32 to the sigmoid function ? Let e be equal to 2.71828 .
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 2 ) , ( 1 0 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
What is the minimum number of padding needed to maintain the same output size if the input image is 50 by 50 and the filter is 37 by 37 ?
Using a row of an image [ 3 3 1 ] and filter [ 1 0 1 ] , calculate the value from applying the filter which has a ReLU on its output .
Do the classifiers [ 1 4 1 ] and [ 3 1 1 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 1 ) , ( 1 negative 2 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Let a function f(theta) = ( 2 * theta + 3 ) ^ 4 . For theta = 3 and eta = 0.05 , calculate theta after one gradient descent step .
Given an image row [ 1 3 1 ] and filter [ 2 1 1 ] , what is the result from applying the filter to the image row such that they both align ?
x is ( 1 0 ) , theta is ( 1 negative 1 ) and theta_0 is negative 1 . What is the value of theta times x plus theta_0?
If you are given two classifiers [ 1 0 0 ] and [ 0 4 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Given the classifiers [ 1 1 1 ] and [ 4 0 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Consider a 1D classification line on a 2D plane . There is a total of 45 points, 25 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?
A classifier has a decision boundary where theta is ( 1 3 ) . What value does it classify p , where p is ( 0 negative 2 ) ?
Calculate the value of y in the dataset [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 0.5 .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 5 with weight wOC being 3 . What is the output ?
Compute the value returned from aligning the filter  [ 1 0 0 ] to the image  [ 1 0 0 ] on top of one another .
Consider a 1D classification line on a 2D plane . There is a total of 45 points, 23 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?
Now consider a zero-padded max pooling layer with 24 inputs , a pooling filter size of 1 and stride of 2 . How many total output units are there for this layer?
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 2 ) , ( 1 0 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
Let q = 7 . After Q learning, what is q if a is 0.2 and t is 8 ?
How much padding is needed on each side of a 80 by 80 input using a 19 by 19 filter to get an output the same size as the input ?
If an image has length 60 and filter has length 11 , compute the length of the output from applying the filter to the image ?
After applying Q learning to q = 4 , what is its value ? Let the t be 6 and a be 0.1 .
If q is 0 , what is its updated value after applying Q learning if a is 0.1 and t is 2 ?
Using a filter [ 3 4 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 0 3 1 ] .
Using a stride length of 1 , what is the output from applying a filter of length 3 to an image of length 53 ?
What is the RNN result s_2 if s_0 is 3 , w is 1.5 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
What is the RNN result s_2 if s_0 is 3 , w is 0 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
If an image has length 60 and filter has length 35 , compute the length of the output from applying the filter to the image ?
What is the margin of a classifier with theta being negative 1 and theta_0 being 2 on a point 4 with label negative 1 ?
If f(theta) is 6 times theta plus 19 squared and theta is 2 what is f(theta) ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 4 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 1 with an offset of 1 .
What is the RNN result s_3 if s_0 is 0 , w is 0 , and x is [ 1 0 2 ] if we let s_t = w * s_t-1 + x_t ?
If we are given the classifiers [ 1 1 0 ] and [ 1 2 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What does the sigmoid function return when  you pass into it 1 ? Hint: have e be 2.71828 .
If you are given two classifiers [ 1 4 1 ] and [ 3 0 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
If you are given two classifiers [ 1 0 1 ] and [ 4 4 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Compute the output length given the stride 2 , image length 54 , and filter length 3 .
An image I has length 50 and filter F has length 21 , what is the length of the result of applying F to I ?
If an image has length 90 and filter has length 27 , compute the length of the output from applying the filter to the image ?
Compute the magnitude of [ 3 3 1 ] .
Compute the output length given the stride 2 , image length 54 , and filter length 15 .
If we have a neural network layer with 10 inputs and 120 outputs , how many weights ( including biases ) are needed to describe each connection ?
Consider the point ( 2 negative 1 ) , the theta 2 and the theta_0 0 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
What does the sigmoid function return when  you pass into it 45 ? Hint: have e be 2.71828 .
If we have a neural network layer with 50 inputs and 20 outputs , how many weights ( including biases ) are needed to describe each connection ?
Now consider a zero-padded max pooling layer with 12 inputs , a pooling filter size of 1 and stride of 2 . How many total output units are there for this layer?
Consider a plane of 48 points , 26 of which are on the left side . Of the points on the left , 2 points are positive . Find the entropy of the left side .
What is f(theta) if f(theta) is theta times 1 plus 6 squared and theta is 1 ?
x is ( 1 0 ) , theta is ( 1 negative 1 ) and theta_0 is 3 . What is the value of theta times x plus theta_0?
A point 0 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 2 .
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 1 3 ) and p is ( 3 negative 1 ) ?
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 2 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 4 and a ReLU on its output . Compute the output of this neural network .
What is f(theta) if f(theta) is theta times 8 plus 6 squared and theta is 1 ?
What is the entropy of the left side of a region containing 24 points where the plane has 46 points in total and 4 points on the left are positive ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 1 , and wOC is 2 ?
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 1 with weight wOC being 2 . What is the output of neuron C ?
Determine if the following two classifiers represent the same hyperplane , [ 2 1 0 ] and [ 4 4 1 ] . If so , return 1 , and return anything else otherwise .
A fully-connected neural network has 50 outputs and 40 inputs . How many total weights are there including the biases ?
How much padding is needed on each side of a 60 by 60 input using a 7 by 7 filter to get an output the same size as the input ?
What is the result from applying a filter [ 0 3 0 ] to a row of an image [ 4 3 0 ] , where the filter has a ReLU activation on its output ?
Consider a filter [ 3 1 0 ] applied on an image [ 4 3 0 ] . What is the output if the filter has a ReLU activation ?
If we are given the classifiers [ 1 0 1 ] and [ 3 1 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Let an input vector be [ 6 2 1 ] . What is its magnitude ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , what is the output y_6 after the inputs [ 14 18 10 11 19 3 ] ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 0.5 , and x is [ 0.25 0.5 ] , what is s_2 ?
If q is 2 , what is its updated value after applying Q learning if a is 0.1 and t is 4 ?
Given an image of length 50 and a filter of length 3 , compute the output from applying the filter if we have a stride length of 2 ?
If the classifiers [ 0 1 1 ] and [ 2 1 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
What is the RNN result s_3 if s_0 is 2 , w is 1.5 , and x is [ 1 0 2 ] if we let s_t = w * s_t-1 + x_t ?
Using the row of an image  [ 1 0 0 ] and a filter [ 4 4 0 ] , calculate the value of applying the filter on top of the image .
Given a loss function , ( negative 1 * theta + 3 ) ^ 2 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 4 and eta be 0.01 .
What is the length of the result from applying F to I if F has length 11 and I has length 90?
What is the margin on a point 1 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 2 ?
Given the classifiers [ 1 4 1 ] and [ 3 0 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Consider the classifier [ 4 1 1 ] and [ 0 2 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
A left region has 4 points classified as positive. There are 44 points in the plane , and 25 points on the left . Compute the entropy .
Let a function f(theta) = ( 2 * theta + 3 ) ^ 4 . For theta = 0 and eta = 0.01 , calculate theta after one gradient descent step .
Calculate the value of y in the dataset [ ( 0 1 ) , ( 1 negative 1 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
How much padding is needed on each side of a 70 by 70 input using a 41 by 41 filter to get an output the same size as the input ?
If you are given two classifiers [ 1 4 1 ] and [ 1 1 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 5 and the maximum magnitude of a point is 6 .
Let an input vector be [ 7 2 ] . What is its magnitude ?
Consider the point ( 0 negative 2 ) , the theta 2 and the theta_0 1 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
What is the result of theta times x plus theta_0 if x is ( 1 0 ), theta is ( negative 2 1 ) , and theta_0 is 2 ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 2 ) , ( 1 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
Given an image of length 54 and a filter of length 19 , compute the output from applying the filter if we have a stride length of 1 ?
Given the dataset [ ( 0 negative 1 ) , ( 1 2 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 0.5 ?
Consider the classifier [ 3 1 1 ] and [ 4 2 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Compute the mean squared error with the data points  [ ( 2 negative 2 )  and ( 2 3 ) ] , theta = 4 , and lda = 1 .
Given theta = 4 and lda = 0.5 , compute the mean squared error with the data points [ ( 2 negative 1 )  and ( 2 3 ) ] .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 4 ) and p is ( 3 0 ) ?
If x = [ 4 0 1 ], what is || x || ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 1 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 1 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
The left side of a region has 23 points . Of the 23 points , 4 are classified as positive . What is the entropy of the left region if there are 47 points in total ?
With lambda = 0.5 , the optimal theta is 2 . If the datapoints are [ ( 0 2 ) , ( 1 negative 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
What is the total number of outputs for a zero-padded max pooling layer that has 24 inputs , a stride of 1 , and a pooling filter size of 2 ?
Using a stride length of 2 , what is the output from applying a filter of length 15 to an image of length 53 ?
Given a 90 by 90 image and 29 by 29 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Calculate the entropy of the left region of a 2D plane, split by a line . There are 1 points on the left side that are positive , 23 points on the right side , and 47 points total .
If we have x equals ( 1 negative 1 ), theta equals ( 1 negative 1 ), and theta_0 equals 0 , then what is the result of theta times x plus theta_0 ?
What is the most number of mistakes made by the perceptron algorithm if 2 is the maximum magnitude of a point in the dataset and the dataset has a margin of 5 to the separator .
Compute the loss from the datapoint ( negative 1 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 1 .
Compute the output length given the stride 2 , image length 52 , and filter length 19 .
Let q = 8 . After Q learning, what is q if a is 0.2 and t is 4 ?
Determine if the following two classifiers represent the same hyperplane , [ 3 1 1 ] and [ 0 0 1 ] . If so , return 1 , and return anything else otherwise .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 1 negative 1 ) ?
Using a stride length of 1 , what is the output from applying a filter of length 11 to an image of length 52 ?
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 1 with weight wOC being 2 . What is the output of neuron C ?
Given a loss function , ( 2 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 3 and eta be 0.01 .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 4 .
Determine if the following two classifiers represent the same hyperplane , [ 3 1 1 ] and [ 0 1 0 ] . If so , return 1 , and return anything else otherwise .
Given two classifiers [ 0 1 0 ] and [ 2 4 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
If an image has length 80 and filter has length 35 , compute the length of the output from applying the filter to the image ?
If a point 0 with label 1 was classified by a classifier with theta negative 1 and theta_0 1 , what is the margin of this point ?
Given a function ( 1 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 3 and eta is 0.05 .
Do the two classifiers [ 2 1 0 ] and [ 4 0 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Using a row of an image [ 1 3 1 ] and filter [ 3 4 0 ] , calculate the value from applying the filter which has a ReLU on its output .
The row of an image  [ 1 2 1 ] has a filter [ 2 4 1 ] applied to it . What is the resulting value if they both align ?
Given theta be 2 and eta be 0.01 , calculate the value of the function ( 2 * theta + 2 ) ^ 4 after one step of gradient descent .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 2 , and wOC is 2 ?
Given the classifiers [ 1 0 1 ] and [ 4 4 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Compute the output length given the stride 1 , image length 51 , and filter length 15 .
After applying Q learning to q = 8 , what is its value ? Let the t be 10 and a be 0.1 .
Compute the loss from the datapoint ( 1 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Compute the magnitude of [ 3 3 ] .
A max pooling layer has 16 inputs, a pooling filter length of 4 , a stride length of 2 , and is zero-padded . Compute the number of output units for this layer .
What is the margin on a point 1 with a label 1 if it is classified by a classifier with theta negative 1 and theta_0 0 ?
Given the points  [ ( 2 0 )  and ( 1 4 ) ] , what is the mean squared error if theta is 3 and lda is 0.5 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 1 and the maximum magnitude of a point is 8 .
The function ( 2 * theta + 1 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 2 and eta be 0.01 .
Find the Euclidean length of [ 4 3 3 ] .
Using theta = 0 and lda = 0.5 , calculate the mean squared error of the points  [ ( 2 negative 1 )  and ( 2 1 ) ] .
Given the classifiers [ 1 4 0 ] and [ 3 1 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 0 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 3 and applies an ReLU on its output . Compute the output .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 4 ) and p is ( 0 0 ) ?
If we are given the classifiers [ 1 2 1 ] and [ 2 3 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
How does a classifier with decision boundary theta classify a point p if theta is ( 1 4 ) and p is ( 3 negative 4 ) ?
What is the value from applying a filter [ 4 1 1 ] directly on top of an image  [ 1 0 0 ] ?
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 3 negative 1 ) ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 0 .
The row of an image  [ 1 4 0 ] has a filter [ 1 2 0 ] applied to it . What is the resulting value if they both align ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 2 with an offset of 1 .
How much padding is needed on each side of a 50 by 50 input using a 23 by 23 filter to get an output the same size as the input ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 3 , and wOC is 3 ?
Let q = 0 . After Q learning, what is q if a is 0.2 and t is 6 ?
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 5 . Neuron B has input 4 and offset 1 . Neuron A has input 1 and offset 2 with offset 0.5 .
If q is 2 , what is its updated value after applying Q learning if a is 0.2 and t is 8 ?
If f(theta) is 6 times theta plus 6 squared , what is f(theta) when theta is 1 ?
If f(theta) is 4 times theta plus 19 squared and theta is 2 what is f(theta) ?
x is ( 0 0 ) , theta is ( 1 negative 1 ) and theta_0 is 0.25 . What is the value of theta times x plus theta_0?
Compute the value returned from aligning the filter  [ 1 2 0 ] to the image  [ 1 2 0 ] on top of one another .
What is the size of the margin of a point 4 by a classifier with theta 1 and theta_0 1 if the point has label negative 1 ?
A neural network has inputs x1 = 1 with weight 1 and x2 = 0 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 . Compute the output .
What is the result of applying the value 2 to the sigmoid function ? Let e be equal to 2.71828 .
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 1 ) , ( 1 negative 1 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 3 . What is the output ?
Given two classifiers [ 3 1 0 ] and [ 4 0 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Determine how many pixels of padding we need on the input of size 70 by 70 to ensure our filter 35 by 35 gives an output of the same size .
Given the largest magnitude of a point as 7 and the margin of the dataset be 1 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 20 outputs and 50 inputs .
If the decision boundary of a classifier is theta , where theta is equal to ( 2 0 ) , how does it classify point p , where p is equal to ( 0 negative 1 ) ?
Consider the input x_t = [ 3 6 8 11 19 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_5 if our initial conditions are s_0 is 5 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t .
Let theta be ( 1 negative 1 ) , theta_0 be 6, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 negative 1 ) , ( 1 negative 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Compute the magnitude of [ 2 3 ] .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 3 negative 2 ) ?
What is the output y_3 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , and input x_t = [ 1 1 15 ] ?
If you are given two classifiers [ 1 0 1 ] and [ 3 4 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 4 . Neuron A takes in value x1 = 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 2 with an offset of 1 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 1 , and wOC is 2 ?
If we have x equals ( 1 negative 1 ), theta equals ( negative 2 1 ), and theta_0 equals 6 , then what is the result of theta times x plus theta_0 ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 3 , and wOC is 2 ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 1 .
What is the RNN result s_3 if s_0 is 1 , w is 0.5 , and x is [ 1 0 2 ] if we let s_t = w * s_t-1 + x_t ?
The row of an image  [ 1 2 1 ] has a filter [ 1 0 1 ] applied to it . What is the resulting value if they both align ?
Given theta be 1 and eta be 0.05 , calculate the value of the function ( 2 * theta + negative 2 ) ^ 3 after one step of gradient descent .
Compute the output length given the stride 2 , image length 50 , and filter length 7 .
Compute the loss from the datapoint ( negative 2 0 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 1 .
If the margin of the dataset with respect to a separator is 1 and the maximum magnitude of a point is 4 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Calculate the value of y in the dataset [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 0.5 .
If an image has length 80 and filter has length 7 , compute the length of the output from applying the filter to the image ?
A point 2 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 2 .
If there are 48 points on a 2D plane , 24 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 2 negative 2 ) ?
If the classifiers [ 2 1 1 ] and [ 4 0 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
What is the result of applying the value 49 to the sigmoid function ? Let e be equal to 2.71828 .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 10 inputs and 30 outputs .
Given that there are 28 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 2 ?
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 5 with weight wOC being 2 . What is the output of neuron C ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 3 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 5 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
Given a function ( negative 1 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 3 and eta is 0.01 .
If the classifiers [ 1 1 1 ] and [ 0 0 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Given an image row [ 4 3 1 ] and filter [ 4 2 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
What is the length of the output when we use an image of length 53 and a filter of length 17 if we use a stride length of 2 ?
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 10 inputs and 40 outputs .
If the decision boundary of a classifier is theta , where theta is equal to ( 2 4 ) , how does it classify point p , where p is equal to ( 0 negative 1 ) ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 0 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 5 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
If the decision boundary of a classifier is theta , where theta is equal to ( 2 4 ) , how does it classify point p , where p is equal to ( 0 negative 2 ) ?
Consider the input x_t = [ 2 18 18 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_3 if our initial conditions are s_0 is 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t .
Given an image row [ 0 3 0 ] and filter [ 4 1 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 16 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , what is the output y_6 after the inputs [ 11 12 9 3 12 5 ] ?
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is negative 1 ?
If the classifiers [ 3 1 0 ] and [ 4 2 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Consider an image I of length 51 and filter F of length 21 . What is the length of the output if we have a stride length of 2 ?
What is the output y_4 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 10 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , and input x_t = [ 16 19 0 16 ] ?
If the classifiers [ 0 1 1 ] and [ 3 3 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Given theta be 1 and eta be 0.05 , calculate the value of the function ( 2 * theta + 2 ) ^ 4 after one step of gradient descent .
What is the updated Q value of a tuple ( s a ) if q is 0 , the a is 0.2 , and t is 10 ?
What is the most number of mistakes made by the perceptron algorithm if 17 is the maximum magnitude of a point in the dataset and the dataset has a margin of 1 to the separator .
Given two classifiers [ 4 1 1 ] and [ 4 0 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Given the largest magnitude of a point as 9 and the margin of the dataset be 1 from the separator , compute the most number of mistakes made by the perceptron algotithm .
What is the value of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 0.5 ?
Given a function ( 2 * theta + negative 1 ) ^ 3 , calculate the value of the function after one gradient descent update if theta is 1 and eta is 0.05 .
f(theta) is defined as 8 times theta plus 19 squared and theta is 1 . What is f(theta) ?
Consider the classifier [ 1 1 0 ] and [ 3 3 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
The row of an image  [ 1 4 1 ] has a filter [ 2 3 0 ] applied to it . What is the resulting value if they both align ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 5 and the maximum magnitude of a point is 13 .
What is the value of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 6 ?
Let s_0 be 1.5 , w be 0.1 , and x be [ 2 2 0 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
Given a 60 by 60 image and 41 by 41 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
If the classifiers [ 3 1 0 ] and [ 2 4 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Consider the classifier [ 3 1 0 ] and [ 1 4 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 4 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
If a is 0.2 and t is 2 , what is the Q learning value after applying one tuple ( s a ) if q is 6 ?
Using a row of an image [ 1 3 1 ] and filter [ 1 2 0 ] , calculate the value from applying the filter which has a ReLU on its output .
Compute the output of the sigmoid function when we pass in negative 32 . Let e be equal to 2.71828 .
Given that there are 22 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 2 ?
If a is 0.1 and t is 8 , what is the Q learning value after applying one tuple ( s a ) if q is 8 ?
What is the result from applying a filter [ 4 3 1 ] to a row of an image [ 4 3 0 ] , where the filter has a ReLU activation on its output ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 1 4 ) and p is ( 0 negative 4 ) ?
If x = [ 3 4 1 ], what is || x || ?
What is the result from applying a filter [ 1 1 1 ] to a row of an image [ 0 3 0 ] , where the filter has a ReLU activation on its output ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 90 outputs and 20 inputs .
If we let theta be 0 and lda be 1 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 2 1 ) ] ?
What is the length of the output when we use an image of length 51 and a filter of length 7 if we use a stride length of 2 ?
Using theta = 0 and lda = 1 , calculate the mean squared error of the points  [ ( 2 1 )  and ( 2 1 ) ] .
Given a function ( 2 * theta + 1 ) ^ 4 , calculate the value of the function after one gradient descent update if theta is 4 and eta is 0.01 .
If f(theta) is 7 times theta plus 19 squared and theta is 1 what is f(theta) ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_5 if we have s_0 being 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 0 * s_t , and we input [ 17 2 12 2 14 ] ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 40 inputs and 40 outputs ?
If an image has length 80 and filter has length 3 , compute the length of the output from applying the filter to the image ?
What is the minimum number of padding needed to maintain the same output size if the input image is 50 by 50 and the filter is 23 by 23 ?
What is f(theta) if f(theta) is theta times 5 plus 19 squared and theta is 1 ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 2 , and wOC is 2 ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 1 3 ) and p is ( 1 negative 4 ) ?
Compute the loss from the datapoint ( 2 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 2 .
Given an image row [ 1 4 0 ] and filter [ 0 3 0 ] , what is the result from applying the filter to the image row such that they both align ?
Neurons A and B take inputs negative 1 and 0 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 3 . Neuron C also applies a ReLU on its output . What is the output ?
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 2 and a ReLU on its output . Compute the output of this neural network .
What is the output y_6 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 13 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , and input x_t = [ 18 6 18 19 15 5 ] ?
Compute the output of the sigmoid function when we pass in negative 26 . Let e be equal to 2.71828 .
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 3 , w is 0.1 , and x is [ 0 3 1 ] ?
If we have an image of size 90 by 90 and a filter of size 33 by 33 , how far out on each side should we pad to maintain the same output dimensions ?
Now consider a zero-padded max pooling layer with 26 inputs , a pooling filter size of 5 and stride of 2 . How many total output units are there for this layer?
Do the classifiers [ 1 1 0 ] and [ 0 4 0 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
Using the row of an image  [ 1 3 0 ] and a filter [ 2 4 0 ] , calculate the value of applying the filter on top of the image .
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 0 , w is 0 , and x is [ 0.25 0.5 ] , what is s_2 ?
What is the length of the output when we use an image of length 53 and a filter of length 13 if we use a stride length of 1 ?
What is the length of the output when we use an image of length 50 and a filter of length 7 if we use a stride length of 2 ?
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 2 ) , ( 1 0 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 3 negative 3 ) ?
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 4 and a ReLU on its output . Compute the output of this neural network .
If we are given the classifiers [ 1 2 1 ] and [ 3 3 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
A neural network has inputs x1 = 1 with weight 1 and x2 = 1 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 1 . Compute the output .
Given a 90 by 90 image and 35 by 35 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
If we are given the classifiers [ 1 3 1 ] and [ 4 0 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Consider the input x_t = [ 4 12 5 3 16 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_5 if our initial conditions are s_0 is 11 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t .
Given a 1D image I that is length 80 and a filter F that is length 21 , what is the length of the result from applying F to I ?
Compute the output of the sigmoid function when we pass in 48 . Let e be equal to 2.71828 .
Consider a filter [ 3 1 0 ] applied on an image [ 1 3 1 ] . What is the output if the filter has a ReLU activation ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 5 , and wOC is 2 ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
The function ( 2 * theta + negative 1 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 4 and eta be 0.01 .
If f(theta) is 5 times theta plus 3 squared , what is f(theta) when theta is 2 ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_4 if we have s_0 being 0 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 4 * s_t , and we input [ 10 0 11 6 ] ?
Let 5 be the margin of the dataset with respect to the separator . Also let 7 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
Let theta be ( 1 negative 1 ) , theta_0 be negative 3, and x be ( 0 , 0 ) . Compute theta times x plus theta_0 .
Calculate the updated theta after one gradient descent step if theta is 0 , eta is 0.05 , and the loss function is ( 0 * theta + 3 ) ^ 3 .
Find the Euclidean length of [ 6 2 1 ] .
Given a function ( 2 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 4 and eta is 0.01 .
Consider the classifier [ 4 1 1 ] and [ 4 4 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 10 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , what is the output y_3 after the inputs [ 14 13 15 ] ?
Calculate the updated theta after one gradient descent step if theta is 1 , eta is 0.05 , and the loss function is ( 2 * theta + 3 ) ^ 2 .
Given an image of length 51 and a filter of length 9 , compute the output from applying the filter if we have a stride length of 1 ?
Calculate the updated theta after one gradient descent step if theta is 2 , eta is 0.05 , and the loss function is ( 1 * theta + 3 ) ^ 4 .
If an image has length 70 and filter has length 19 , compute the length of the output from applying the filter to the image ?
Using the row of an image  [ 1 3 1 ] and a filter [ 1 0 1 ] , calculate the value of applying the filter on top of the image .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 50 inputs and 100 outputs ?
Given the values for theta as 2 and theta_0 as 1 , compute the NLL loss on the data point ( negative 2 1 ) . Use log base e of 2.71828 for the log .
What is the length of the output when we use an image of length 51 and a filter of length 3 if we use a stride length of 1 ?
Given the points  [ ( 2 0 )  and ( 1 5 ) ] , what is the mean squared error if theta is 4 and lda is 1 ?
After applying Q learning to q = 9 , what is its value ? Let the t be 8 and a be 0.1 .
Given an image row [ 1 0 0 ] and filter [ 1 1 0 ] , what is the result from applying the filter to the image row such that they both align ?
If filter F has length 15 and an image I has length 50 , what is the length of the result from applying F to I ?
Let a function f(theta) = ( 2 * theta + negative 2 ) ^ 2 . For theta = 3 and eta = 0.01 , calculate f(theta) after one gradient descent update .
Compute the value returned from aligning the filter  [ 1 4 0 ] to the image  [ 1 4 0 ] on top of one another .
What is the RNN result s_3 if s_0 is 0 , w is 0.5 , and x is [ 1 0 2 ] if we let s_t = w * s_t-1 + x_t ?
What is the magnitude of the vector [ 5 1 ] ?
Given the values for theta as 2 and theta_0 as 1 , compute the NLL loss on the data point ( negative 2 negative 1 ) . Use log base e of 2.71828 for the log .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 0 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 2 . What is the output of neuron C ?
Given a loss function , ( 0 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 3 and eta be 0.05 .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 4 with weight wOC being 2 . What is the output of neuron C ?
What is the minimum number of padding needed to maintain the same output size if the input image is 60 by 60 and the filter is 39 by 39 ?
What is the margin on a point 2 with a label negative 1 if it is classified by a classifier with theta 1 and theta_0 2 ?
If we let theta be 1 and lda be 1 , what is the mean squared error of the given points  [ ( 2 negative 1 )  and ( 2 4 ) ] ?
What is the loss for the data point ( 0 0 ) if we use NLL . Let theta be 2 and theta_0 be 2 . Also use natural log where the base is 2.71828 .
How much padding is needed on each side of a 70 by 70 input using a 29 by 29 filter to get an output the same size as the input ?
Do the classifiers [ 1 1 1 ] and [ 1 0 1 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
If x = [ 5 0 3 ], what is || x || ?
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 50 inputs and 190 outputs .
What is the margin of a classifier with theta being negative 1 and theta_0 being negative 1 on a point 2 with label negative 1 ?
What is the size of the margin of a point 2 by a classifier with theta negative 1 and theta_0 negative 2 if the point has label 1 ?
If the margin of the dataset with respect to a separator is 4 and the maximum magnitude of a point is 15 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 4 with weight wOC being 3 . What is the output ?
How much padding is needed on each side of a 70 by 70 input using a 35 by 35 filter to get an output the same size as the input ?
f(theta) is defined as 9 times theta plus 19 squared and theta is 2 . What is f(theta) ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 2 ) , ( 1 0 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
Given theta = 3 and lda = 1 , compute the mean squared error with the data points [ ( 2 negative 2 )  and ( 1 5 ) ] .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 3 . Neuron B has input 4 and offset 1 . Neuron A has input 1 and offset 2 with offset 0.5 .
Given the largest magnitude of a point as 3 and the margin of the dataset be 4 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Neurons A and B take inputs 1 and 4 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 4 . What is the output ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 2 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , compute y_3 if the input is x_t = [ 3 13 3 ] .
Consider the classifier [ 1 2 1 ] and [ 3 3 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
What is the margin on a point 2 with a label negative 1 if it is classified by a classifier with theta 1 and theta_0 negative 2 ?
Let a function f(theta) = ( 2 * theta + 3 ) ^ 2 . For theta = 2 and eta = 0.05 , calculate theta after one gradient descent step .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 2 . What is the output of neuron C ?
What is the NLL loss for the single data point ( 0 negative 2 ) where theta is 2 and theta_0 is 2 ? Let the log be natural log ( base is 2.71828 ) .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 0 negative 3 ) ?
Given the largest magnitude of a point as 8 and the margin of the dataset be 4 from the separator , compute the most number of mistakes made by the perceptron algotithm .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 0 ) and p is ( 1 negative 3 ) ?
Compute the magnitude of [ 0 1 1 ] .
A neural network has inputs x1 = 1 with weight 1 and x2 = 1 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 3 . Compute the output .
If q is 4 , what is its updated value after applying Q learning if a is 0.2 and t is 10 ?
If the decision boundary of a classifier is theta , where theta is equal to ( 2 3 ) , how does it classify point p , where p is equal to ( 1 negative 4 ) ?
If there are 45 points on a 2D plane , 24 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
The row of an image  [ 1 2 0 ] has a filter [ 0 0 1 ] applied to it . What is the resulting value if they both align ?
What is the RNN result s_3 if s_0 is 2 , w is 0.5 , and x is [ 1 0 2 ] if we let s_t = w * s_t-1 + x_t ?
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 1 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 2 and applies an ReLU on its output . Compute the output .
Consider the classifier [ 1 2 1 ] and [ 0 4 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
x is ( 0 0 ) , theta is ( 1 negative 1 ) and theta_0 is 6 . What is the value of theta times x plus theta_0?
If an image has length 90 and filter has length 13 , compute the length of the output from applying the filter to the image ?
Neuron A takes in value 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 3 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 4 . Compute the output of this neural network .
Given a 50 by 50 image and 21 by 21 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
The row of an image  [ 1 0 0 ] has a filter [ 1 3 1 ] applied to it . What is the resulting value if they both align ?
If you are given two classifiers [ 1 3 1 ] and [ 1 4 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Let q = 7 . After Q learning, what is q if a is 0.1 and t is 6 ?
Given the input negative 37 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
If f(theta) is 9 times theta plus 3 squared and theta is 1 what is f(theta) ?
Compute the value returned from aligning the filter  [ 1 4 1 ] to the image  [ 1 4 1 ] on top of one another .
Determine how many pixels of padding we need on the input of size 50 by 50 to ensure our filter 41 by 41 gives an output of the same size .
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 2 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 1 and a ReLU on its output . Compute the output of this neural network .
What is the size of the margin of a point 0 by a classifier with theta 1 and theta_0 negative 1 if the point has label 1 ?
Compute the magnitude of [ 6 2 1 ] .
Consider a filter [ 2 4 1 ] applied on an image [ 1 3 0 ] . What is the output if the filter has a ReLU activation ?
Consider the point ( 0 0 ) , the theta 2 and the theta_0 3 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
Compute the loss from the datapoint ( 0 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Given the classifiers [ 1 2 0 ] and [ 4 2 1 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
If filter F has length 9 and an image I has length 70 , what is the length of the result from applying F to I ?
If a point 1 with label 1 was classified by a classifier with theta 1 and theta_0 negative 1 , what is the margin of this point ?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 1.5 , w is 1.5 , and x is [ 1 0 2 ] ?
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 2 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 2 and a ReLU on its output . Compute the output of this neural network .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 1 ) , ( 1 2 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
What is f(theta) if f(theta) is theta times 3 plus 6 squared and theta is 2 ?
What is the result from applying a filter [ 1 2 1 ] to a row of an image [ 1 3 1 ] , where the filter has a ReLU activation on its output ?
What is the magnitude of the vector [ 2 0 3 ] ?
If we have x equals ( negative 1 0 ), theta equals ( negative 2 1 ), and theta_0 equals 0 , then what is the result of theta times x plus theta_0 ?
Given the input 31 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 0 , w = 0 , and x = [ 2 2 0 ] , what is s_3 ?
A neural network has inputs x1 = 1 with weight 1 and x2 = 4 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 . Compute the output .
What is the updated Q value of a tuple ( s a ) if q is 9 , the a is 0.2 , and t is 4 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 3 and the maximum magnitude of a point is 9 .
Now consider a zero-padded max pooling layer with 24 inputs , a pooling filter size of 2 and stride of 1 . How many total output units are there for this layer?
If we let theta be 1 and lda be 1 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 1 3 ) ] ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 4 , and wOC is 2 ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 2 . Neuron B has input 2 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
If the margin of the dataset with respect to a separator is 1 and the maximum magnitude of a point is 19 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , compute y_3 if the input is x_t = [ 11 6 19 ] .
If we have x equals ( 1 0 ), theta equals ( negative 2 1 ), and theta_0 equals 0 , then what is the result of theta times x plus theta_0 ?
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 0 .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1.5 , w = 0.1 , and x = [ 0 3 1 ] , what is s_3 ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 3 , w is 1.5 , and x is [ 1 0 2 ] , what is s_3 ?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 2 , w is 0.5 , and x is [ 0 3 1 ] ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_4 if we have s_0 being 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 2 * s_t , and we input [ 0 4 13 13 ] ?
If we have a neural network layer with 30 inputs and 90 outputs , how many weights ( including biases ) are needed to describe each connection ?
Let an input vector be [ 0 0 ] . What is its magnitude ?
If x = [ 6 2 ] , what is || x || ?
A classifier has a decision boundary where theta is ( 2 3 ) . What value does it classify p , where p is ( 3 negative 3 ) ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 40 outputs and 50 inputs .
If x = [ 8 0 1 ], what is || x || ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 5 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_5 after the inputs [ 3 12 12 14 10 ] ?
Let s_0 be 1.5 , w be 0 , and x be [ 0 3 1 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
Do the classifiers [ 1 3 0 ] and [ 0 4 1 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
After applying Q learning to q = 0 , what is its value ? Let the t be 10 and a be 0.1 .
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 3 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .
Let an input vector be [ 7 0 ] . What is its magnitude ?
x is ( 0 negative 1 ) , theta is ( 1 negative 1 ) and theta_0 is 0 . What is the value of theta times x plus theta_0?
Determine how many pixels of padding we need on the input of size 80 by 80 to ensure our filter 3 by 3 gives an output of the same size .
Given an image of length 50 and a filter of length 17 , compute the output from applying the filter if we have a stride length of 2 ?
What is the result from applying a filter [ 1 4 1 ] to a row of an image [ 4 3 0 ] , where the filter has a ReLU activation on its output ?
A neural network has inputs x1 = 1 with weight 1 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 . Compute the output .
What is the value from applying a filter [ 3 0 0 ] directly on top of an image  [ 1 4 0 ] ?
If f(theta) is 10 times theta plus 6 squared and theta is 2 what is f(theta) ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 1.5 , and x is [ 0 3 1 ] , what is s_3 ?
What is the updated Q value of a tuple ( s a ) if q is 0 , the a is 0.2 , and t is 8 ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_4 if we have s_0 being 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 3 * s_t , and we input [ 7 1 15 14 ] ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 150 outputs and 30 inputs .
What is the most number of mistakes made by the perceptron algorithm if 12 is the maximum magnitude of a point in the dataset and the dataset has a margin of 1 to the separator .
What is the length of the output when we use an image of length 51 and a filter of length 19 if we use a stride length of 2 ?
If we know the stride 2 of a max pooling layer , along with the filter length of 1 and input length of 20 , what is the number of outputs of this layer ?
Given theta = 0 and lda = 1 , compute the mean squared error with the data points [ ( 2 0 )  and ( 2 2 ) ] .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 50 inputs and 200 outputs .
Given the points  [ ( 2 0 )  and ( 2 2 ) ] , what is the mean squared error if theta is 0 and lda is 0.5 ?
With lambda = 0.5 , the optimal theta is 2 . If the datapoints are [ ( 0 negative 1 ) , ( 1 negative 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Compute the value returned from aligning the filter  [ 1 4 1 ] to the image  [ 1 4 1 ] on top of one another .
An image I has length 80 and filter F has length 7 , what is the length of the result of applying F to I ?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 1.5 , w is 0 , and x is [ 0 3 1 ] ?
Neurons A and B take inputs negative 1 and 4 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 2 . Neuron C also applies a ReLU on its output . What is the output ?
If you let theta be 3 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( 2 * theta + 3 ) ^ 3 ?
What is f(theta) if f(theta) is theta times 6 plus 8 squared and theta is 1 ?
If an image has length 50 and filter has length 31 , compute the length of the output from applying the filter to the image ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 1 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 3 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 1 .
Consider a 1D classification line on a 2D plane . There is a total of 44 points, 23 of which are on the right and the rest on the left of the boundary . 1 points on the left are classified positive . What is the entropy of the left region ?
Consider an image I of length 52 and filter F of length 13 . What is the length of the output if we have a stride length of 1 ?
What is the NLL loss for the single data point ( 1 2 ) where theta is 2 and theta_0 is 1 ? Let the log be natural log ( base is 2.71828 ) .
Let 3 be the margin of the dataset with respect to the separator . Also let 20 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
Given that there are 26 inputs to a zero-padded max pooling layer and a stride length of 1 , compute the number of output units if we also know the pooling filter size of 2 ?
Find the Euclidean length of [ 7 0 1 ] .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_3 if we have s_0 being 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 1 * s_t , and we input [ 11 6 19 ] ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 0 , and x is [ 0 3 1 ] , what is s_3 ?
What is the RNN result s_2 if s_0 is 1.5 , w is 1.5 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_6 after the inputs [ 16 15 3 13 18 11 ] ?
What is the magnitude of the vector [ 0 6 ] ?
What is the margin of a classifier with theta being negative 1 and theta_0 being negative 2 on a point 3 with label 1 ?
Given a 1D image I that is length 70 and a filter F that is length 11 , what is the length of the result from applying F to I ?
If we have an image of size 90 by 90 and a filter of size 37 by 37 , how far out on each side should we pad to maintain the same output dimensions ?
Given an image of length 54 and a filter of length 3 , compute the output from applying the filter if we have a stride length of 2 ?
Neuron A takes in value 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 1 . Compute the output of this neural network .
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 2 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 1 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
Compute the magnitude of [ 2 5 ] .
Compute the output length given the stride 2 , image length 51 , and filter length 3 .
Given theta be 3 and eta be 0.01 , calculate the value of the function ( 2 * theta + negative 2 ) ^ 2 after one step of gradient descent .
The left side of a region has 24 points . Of the 24 points , 4 are classified as positive . What is the entropy of the left region if there are 48 points in total ?
Given 47 points on a plane , 27 of them are on the right side of a line , and 1 of them that are on the left side are positive . Compute the entropy of the left side .
What does the sigmoid function return when  you pass into it negative 3 ? Hint: have e be 2.71828 .
Consider a plane of 46 points , 23 of which are on the left side . Of the points on the left , 2 points are positive . Find the entropy of the left side .
Using the row of an image  [ 1 0 1 ] and a filter [ 0 1 0 ] , calculate the value of applying the filter on top of the image .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 3 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
A left region has 4 points classified as positive. There are 45 points in the plane , and 27 points on the left . Compute the entropy .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 0 , w = 1 , and x = [ 0 3 1 ] , what is s_3 ?
A fully-connected neural network has 20 outputs and 20 inputs . How many total weights are there including the biases ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , what is the output y_6 after the inputs [ 7 9 12 10 19 19 ] ?
Given a loss function , ( 2 * theta + 3 ) ^ 2 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 4 and eta be 0.01 .
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 2 and a ReLU on its output . Compute the output of this neural network .
What is the margin of a classifier with theta being 1 and theta_0 being 1 on a point 0 with label negative 1 ?
What is the loss for the data point ( 2 negative 1 ) if we use NLL . Let theta be 2 and theta_0 be 0 . Also use natural log where the base is 2.71828 .
If the margin of the dataset with respect to a separator is 3 and the maximum magnitude of a point is 11 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
f(theta) is the square of the sum of 8 and the product of 5 and theta , where theta is 1 . What is f(theta) ?
If q is 8 , what is its updated value after applying Q learning if a is 0.2 and t is 2 ?
What is the value from applying a filter [ 1 2 0 ] directly on top of an image  [ 1 3 1 ] ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 170 outputs and 20 inputs .
What is the output y_6 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 11 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , and input x_t = [ 1 1 7 18 15 13 ] ?
What is the most number of mistakes made by the perceptron algorithm if 5 is the maximum magnitude of a point in the dataset and the dataset has a margin of 2 to the separator .
Given a function ( 2 * theta + negative 1 ) ^ 3 , calculate the value of the function after one gradient descent update if theta is 0 and eta is 0.05 .
Calculate the value of y in the dataset [ ( 0 0 ) , ( 1 negative 2 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 0.5 .
Determine if the following two classifiers represent the same hyperplane , [ 2 1 0 ] and [ 4 0 1 ] . If so , return 1 , and return anything else otherwise .
If we let theta be 1 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 0 )  and ( 1 1 ) ] ?
Let a function f(theta) = ( 1 * theta + 3 ) ^ 2 . For theta = 3 and eta = 0.01 , calculate theta after one gradient descent step .
If f(theta) is 10 times theta plus 6 squared and theta is 1 what is f(theta) ?
What is the updated Q value of a tuple ( s a ) if q is 8 , the a is 0.1 , and t is 4 ?
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 1 with weight wOC being 3 . What is the output ?
The row of an image  [ 1 2 1 ] has a filter [ 2 3 1 ] applied to it . What is the resulting value if they both align ?
A fully-connected neural network has 90 outputs and 40 inputs . How many total weights are there including the biases ?
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 2 . Neuron A takes in value x1 = 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 2 with an offset of 1 .
What is the minimum number of padding needed to maintain the same output size if the input image is 60 by 60 and the filter is 13 by 13 ?
What is the updated Q value of a tuple ( s a ) if q is 4 , the a is 0.2 , and t is 2 ?
Compute the loss from the datapoint ( negative 1 0 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Let theta be ( 1 negative 1 ) , theta_0 be 2, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .
Consider an image I of length 54 and filter F of length 15 . What is the length of the output if we have a stride length of 1 ?
What is the loss for the data point ( negative 2 0 ) if we use NLL . Let theta be 2 and theta_0 be 0 . Also use natural log where the base is 2.71828 .
If we let theta be 0 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 negative 1 )  and ( 2 1 ) ] ?
If the margin of the dataset with respect to a separator is 3 and the maximum magnitude of a point is 10 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Compute the loss from the datapoint ( 2 negative 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Let theta be ( 1 negative 1 ) , theta_0 be 18, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .
Given an image row [ 4 3 1 ] and filter [ 0 2 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Given two classifiers [ 4 1 1 ] and [ 3 3 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 16 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , compute y_6 if the input is x_t = [ 11 12 9 3 12 5 ] .
What is the total number of outputs for a zero-padded max pooling layer that has 14 inputs , a stride of 2 , and a pooling filter size of 1 ?
Calculate the value of the function ( 2 * theta + 2 ) ^ 2 after updating the theta value in one step of gradient descent . Have theta be 3 and eta be 0.05 .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_5 if we have s_0 being 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 2 * s_t , and we input [ 17 9 1 1 17 ] ?
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 negative 1 ) , ( 1 2 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Given the values for theta as 2 and theta_0 as 3 , compute the NLL loss on the data point ( 2 2 ) . Use log base e of 2.71828 for the log .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , compute y_5 if the input is x_t = [ 15 12 15 5 5 ] .
If we have an image of size 50 by 50 and a filter of size 33 by 33 , how far out on each side should we pad to maintain the same output dimensions ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 2 , and wOC is 2 ?
Compute the value returned from aligning the filter  [ 1 4 1 ] to the image  [ 1 4 1 ] on top of one another .
The row of an image  [ 1 2 1 ] has a filter [ 0 0 0 ] applied to it . What is the resulting value if they both align ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 3 ) and p is ( 3 negative 1 ) ?
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 0 negative 4 ) ?
If you let theta be 1 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( 0 * theta + 3 ) ^ 2 ?
If an image has length 90 and filter has length 11 , compute the length of the output from applying the filter to the image ?
What is the value of theta times x plus theta_0 if x is ( 1 0 ), theta is ( 1 negative 1 ) , and theta_0 is 2 ?
If x = [ 1 2 1 ], what is || x || ?
How much padding is needed on each side of a 90 by 90 input using a 11 by 11 filter to get an output the same size as the input ?
Given a function ( 2 * theta + 0 ) ^ 3 , calculate the value of the function after one gradient descent update if theta is 3 and eta is 0.05 .
If we let theta be 2 and lda be 1 , what is the mean squared error of the given points  [ ( 2 2 )  and ( 2 1 ) ] ?
With lambda = 1 , the optimal theta is 2 . If the datapoints are [ ( 0 negative 2 ) , ( 1 negative 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Determine if the following two classifiers represent the same hyperplane , [ 4 1 1 ] and [ 3 3 0 ] . If so , return 1 , and return anything else otherwise .
An image I has length 90 and filter F has length 41 , what is the length of the result of applying F to I ?
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 1 . Neuron A takes in value x1 = 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
Consider a 1D classification line on a 2D plane . There is a total of 45 points, 26 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?
Compute the output of the sigmoid function when we pass in 19 . Let e be equal to 2.71828 .
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 negative 1 ) , ( 1 negative 1 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
The function ( 2 * theta + negative 2 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 3 and eta be 0.01 .
Let 3 be the margin of the dataset with respect to the separator . Also let 10 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
Consider an image I of length 51 and filter F of length 15 . What is the length of the output if we have a stride length of 1 ?
Let a function f(theta) = ( 2 * theta + 1 ) ^ 4 . For theta = 4 and eta = 0.01 , calculate f(theta) after one gradient descent update .
Consider a filter [ 2 1 1 ] applied on an image [ 1 3 0 ] . What is the output if the filter has a ReLU activation ?
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 1 with an offset of 1 .
Given the values for theta as 2 and theta_0 as 0 , compute the NLL loss on the data point ( 2 1 ) . Use log base e of 2.71828 for the log .
What does the sigmoid function return when  you pass into it negative 50 ? Hint: have e be 2.71828 .
Let 5 be the margin of the dataset with respect to the separator . Also let 17 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
If an image has length 90 and filter has length 29 , compute the length of the output from applying the filter to the image ?
What is the value of theta times x plus theta_0 if x is ( 1 0 ), theta is ( 1 negative 1 ) , and theta_0 is 0.25 ?
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 2 and a ReLU on its output . Compute the output of this neural network .
Compute the output of the sigmoid function when we pass in 10 . Let e be equal to 2.71828 .
There are 47 points on a 2D plane , 25 on the right side of a line and the rest on the left . 3 points on the left of the line are positive . What is the entropy of the left region ?
Do the two classifiers [ 3 1 1 ] and [ 0 0 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 3 , and wOC is 2 ?
Consider the point ( negative 1 2 ) , the theta 2 and the theta_0 2 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
Given a 1D image I that is length 80 and a filter F that is length 27 , what is the length of the result from applying F to I ?
Let an input vector be [ 0 6 3 ] . What is its magnitude ?
What is the updated Q value of a tuple ( s a ) if q is 4 , the a is 0.2 , and t is 8 ?
How much padding is needed on each side of a 80 by 80 input using a 41 by 41 filter to get an output the same size as the input ?
Calculate the value of the function ( 2 * theta + 1 ) ^ 2 after updating the theta value in one step of gradient descent . Have theta be 3 and eta be 0.05 .
Using the row of an image  [ 1 2 0 ] and a filter [ 0 0 1 ] , calculate the value of applying the filter on top of the image .
What is the margin on a point 0 with a label negative 1 if it is classified by a classifier with theta 1 and theta_0 2 ?
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 3 negative 2 ) ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 3 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 3 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
Given theta be 1 and eta be 0.05 , calculate the value of the function ( 2 * theta + negative 1 ) ^ 2 after one step of gradient descent .
A fully-connected neural network has 40 outputs and 20 inputs . How many total weights are there including the biases ?
Consider a filter [ 2 4 1 ] applied on an image [ 3 3 1 ] . What is the output if the filter has a ReLU activation ?
If you are given two classifiers [ 1 1 0 ] and [ 4 3 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
What is the result of applying the value negative 18 to the sigmoid function ? Let e be equal to 2.71828 .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 0 ) , ( 1 1 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Let q = 0 . After Q learning, what is q if a is 0.2 and t is 10 ?
Compute the output length given the stride 2 , image length 52 , and filter length 5 .
If a is 0.1 and t is 2 , what is the Q learning value after applying one tuple ( s a ) if q is 7 ?
Given an image row [ 1 3 0 ] and filter [ 3 4 1 ] , what is the result from applying the filter to the image row such that they both align ?
Compute the value returned from aligning the filter  [ 1 2 1 ] to the image  [ 1 2 1 ] on top of one another .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 2 , w = 0.5 , and x = [ 0 3 1 ] , what is s_3 ?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_2 if s_0 is 2 , w is 0.1 , and x is [ 0.25 0.5 ] ?
Given a function ( 2 * theta + negative 2 ) ^ 2 , calculate the value of the function after one gradient descent update if theta is 1 and eta is 0.01 .
Let a function f(theta) = ( 1 * theta + 3 ) ^ 3 . For theta = 1 and eta = 0.01 , calculate theta after one gradient descent step .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 1 , and wOC is 3 ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 0 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , what is the output y_4 after the inputs [ 15 19 2 17 ] ?
If we have x equals ( 1 negative 1 ), theta equals ( negative 2 1 ), and theta_0 equals 3 , then what is the result of theta times x plus theta_0 ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 2 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 4 with an offset of 1 .
Let q = 0 . After Q learning, what is q if a is 0.2 and t is 2 ?
If a point 3 with label negative 1 was classified by a classifier with theta negative 1 and theta_0 negative 1 , what is the margin of this point ?
Determine if the following two classifiers represent the same hyperplane , [ 3 1 1 ] and [ 3 3 0 ] . If so , return 1 , and return anything else otherwise .
Consider an image I of length 53 and filter F of length 17 . What is the length of the output if we have a stride length of 2 ?
If you let theta be 2 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 2 * theta + 3 ) ^ 4 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 4 and the maximum magnitude of a point is 1 .
If a is 0.2 and t is 10 , what is the Q learning value after applying one tuple ( s a ) if q is 6 ?
Compute the loss from the datapoint ( 0 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 2 .
What is the size of the margin of a point 2 by a classifier with theta 1 and theta_0 negative 2 if the point has label negative 1 ?
Compute the mean squared error with the data points  [ ( 2 2 )  and ( 1 4 ) ] , theta = 2 , and lda = 0.5 .
What is the result of applying the value 14 to the sigmoid function ? Let e be equal to 2.71828 .
Using a filter [ 1 4 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 2 3 0 ] .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 14 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , what is the output y_5 after the inputs [ 0 8 17 7 18 ] ?
If f(theta) is 9 times theta plus 5 squared , what is f(theta) when theta is 2 ?
Consider a filter [ 3 0 0 ] applied on an image [ 2 3 1 ] . What is the output if the filter has a ReLU activation ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 2 , and wOC is 2 ?
Given the dataset [ ( 0 negative 1 ) , ( 1 0 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 0.5 ?
Let theta be ( 1 negative 1 ) , theta_0 be negative 1, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .
Given a 80 by 80 image and 5 by 5 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 0 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 and applies an ReLU on its output . Compute the output .
A fully-connected neural network has 110 outputs and 40 inputs . How many total weights are there including the biases ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 50 outputs and 10 inputs .
If a point 4 with label 1 was classified by a classifier with theta 1 and theta_0 0 , what is the margin of this point ?
What is the RNN result s_3 if s_0 is 1.5 , w is 1 , and x is [ 2 2 0 ] if we let s_t = w * s_t-1 + x_t ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , what is the output y_4 after the inputs [ 2 17 18 6 ] ?
Given the largest magnitude of a point as 4 and the margin of the dataset be 3 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Given a loss function , ( negative 1 * theta + 3 ) ^ 4 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 1 and eta be 0.05 .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 1 with an offset of 1 .
Compute the value returned from aligning the filter  [ 1 3 1 ] to the image  [ 1 3 1 ] on top of one another .
Given that there are 14 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 5 ?
Using a row of an image [ 3 3 1 ] and filter [ 3 1 0 ] , calculate the value from applying the filter which has a ReLU on its output .
Compute the output of the sigmoid function when we pass in negative 44 . Let e be equal to 2.71828 .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 2 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 4 with an offset of 1 .
Compute the mean squared error with the data points  [ ( 2 negative 2 )  and ( 1 5 ) ] , theta = 3 , and lda = 1 .
Given theta be 4 and eta be 0.05 , calculate the value of the function ( 2 * theta + 1 ) ^ 3 after one step of gradient descent .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 70 outputs and 30 inputs .
Compute the mean squared error with the data points  [ ( 2 negative 1 )  and ( 1 1 ) ] , theta = 1 , and lda = 1 .
If we are given the classifiers [ 1 0 0 ] and [ 3 3 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
The function ( 2 * theta + negative 2 ) ^ 2 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.01 .
Given the largest magnitude of a point as 5 and the margin of the dataset be 2 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Consider the point ( negative 1 negative 2 ) , the theta 2 and the theta_0 3 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 5 , and wOC is 2 ?
What is f(theta) if f(theta) is theta times 4 plus 6 squared and theta is 2 ?
Given 45 points on a plane , 25 of them are on the right side of a line , and 1 of them that are on the left side are positive . Compute the entropy of the left side .
What is the result from applying a filter [ 4 1 1 ] to a row of an image [ 3 3 0 ] , where the filter has a ReLU activation on its output ?
With lambda = 1 , the optimal theta is 1 . If the datapoints are [ ( 0 negative 2 ) , ( 1 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Compute the mean squared error with the data points  [ ( 2 negative 2 )  and ( 1 4 ) ] , theta = 0 , and lda = 0.5 .
The function ( 2 * theta + negative 2 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 2 and eta be 0.05 .
What is the RNN result s_3 if s_0 is 2 , w is 1 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
Consider the point ( 0 1 ) , the theta 2 and the theta_0 3 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
How does a classifier with decision boundary theta classify a point p if theta is ( 1 3 ) and p is ( 0 negative 4 ) ?
What is the result of applying the value 34 to the sigmoid function ? Let e be equal to 2.71828 .
What is the magnitude of the vector [ 5 1 1 ] ?
If we have a neural network layer with 20 inputs and 40 outputs , how many weights ( including biases ) are needed to describe each connection ?
Using theta = 3 and lda = 0.5 , calculate the mean squared error of the points  [ ( 2 negative 1 )  and ( 1 4 ) ] .
What is the NLL loss for the single data point ( negative 2 negative 2 ) where theta is 2 and theta_0 is 0 ? Let the log be natural log ( base is 2.71828 ) .
Find the Euclidian length of [ 1 5 ] .
Given an image of length 50 and a filter of length 19 , compute the output from applying the filter if we have a stride length of 1 ?
Do the two classifiers [ 0 1 0 ] and [ 1 3 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Let a function f(theta) = ( 2 * theta + negative 2 ) ^ 4 . For theta = 0 and eta = 0.05 , calculate f(theta) after one gradient descent update .
Using a stride length of 1 , what is the output from applying a filter of length 17 to an image of length 51 ?
Given that there are 18 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 2 ?
Given a 90 by 90 image and 39 by 39 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Using a stride length of 1 , what is the output from applying a filter of length 7 to an image of length 51 ?
What does the sigmoid function return when  you pass into it 30 ? Hint: have e be 2.71828 .
What is the margin of a classifier with theta being negative 1 and theta_0 being negative 2 on a point 2 with label 1 ?
Using a stride length of 2 , what is the output from applying a filter of length 7 to an image of length 53 ?
Given an image row [ 1 0 0 ] and filter [ 4 1 1 ] , what is the result from applying the filter to the image row such that they both align ?
Given the points  [ ( 2 negative 1 )  and ( 1 3 ) ] , what is the mean squared error if theta is 4 and lda is 0.5 ?
Neurons A and B take inputs negative 1 and 2 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 5 . Neuron C also applies a ReLU on its output . What is the output ?
If we are given the classifiers [ 1 4 1 ] and [ 3 0 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Given the values for theta as 2 and theta_0 as 1 , compute the NLL loss on the data point ( 0 2 ) . Use log base e of 2.71828 for the log .
A point 2 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 1 .
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 2 .
What is the result of applying the value negative 22 to the sigmoid function ? Let e be equal to 2.71828 .
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 1 . Neuron B has input 2 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
Consider a filter [ 2 0 1 ] applied on an image [ 4 3 0 ] . What is the output if the filter has a ReLU activation ?
A classifier has a decision boundary where theta is ( 2 4 ) . What value does it classify p , where p is ( 1 0 ) ?
What is the result of theta times x plus theta_0 if x is ( 0 0 ), theta is ( 1 negative 1 ) , and theta_0 is 0.5 ?
If you are given two classifiers [ 1 2 0 ] and [ 0 1 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Calculate the updated theta after one gradient descent step if theta is 4 , eta is 0.05 , and the loss function is ( 1 * theta + 3 ) ^ 3 .
What is the length of the result from applying F to I if F has length 33 and I has length 70?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 0 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
A classifier has a decision boundary where theta is ( 1 4 ) . What value does it classify p , where p is ( 1 negative 4 ) ?
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 1 negative 2 ) ?
What is the updated Q value of a tuple ( s a ) if q is 4 , the a is 0.1 , and t is 2 ?
If we are given the classifiers [ 1 0 1 ] and [ 0 2 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Given two classifiers [ 1 1 1 ] and [ 4 3 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Using the row of an image  [ 1 1 0 ] and a filter [ 1 0 1 ] , calculate the value of applying the filter on top of the image .
Neurons A and B take inputs negative 1 and 3 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 3 . Neuron C also applies a ReLU on its output . What is the output ?
Given the values for theta as 2 and theta_0 as 0 , compute the NLL loss on the data point ( 2 negative 1 ) . Use log base e of 2.71828 for the log .
What is the value of theta times x plus theta_0 if x is ( 0 0 ), theta is ( negative 2 1 ) , and theta_0 is 6 ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 1 , and wOC is 3 ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 5 , and wOC is 2 ?
Using a stride length of 2 , what is the output from applying a filter of length 15 to an image of length 54 ?
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 25 points on the right side , and 47 points total .
Assume e is equal to 2.71828 . What do you get from passing the value 31 into the sigmoid function ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 1 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
Given two classifiers [ 3 1 1 ] and [ 0 0 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Do the classifiers [ 1 0 1 ] and [ 3 1 0 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 3 with weight wOC being 2 . What is the output ?
If a point 2 with label 1 was classified by a classifier with theta negative 1 and theta_0 2 , what is the margin of this point ?
Consider the input x_t = [ 0 16 11 19 7 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_5 if our initial conditions are s_0 is 12 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t .
Given an image row [ 1 3 0 ] and filter [ 3 0 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
If we have x equals ( 0 negative 1 ), theta equals ( negative 2 1 ), and theta_0 equals 6 , then what is the result of theta times x plus theta_0 ?
Let theta be ( negative 2 1 ) , theta_0 be negative 1, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .
If we have x equals ( negative 1 0 ), theta equals ( 1 negative 1 ), and theta_0 equals 0.25 , then what is the result of theta times x plus theta_0 ?
If f(theta) is 5 times theta plus 5 squared and theta is 1 what is f(theta) ?
Consider a filter [ 4 1 0 ] applied on an image [ 0 3 0 ] . What is the output if the filter has a ReLU activation ?
Calculate the value of the function ( 2 * theta + 0 ) ^ 4 after updating the theta value in one step of gradient descent . Have theta be 4 and eta be 0.05 .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 5 and the maximum magnitude of a point is 15 .
Consider an image I of length 53 and filter F of length 3 . What is the length of the output if we have a stride length of 1 ?
A fully-connected neural network has 70 outputs and 50 inputs . How many total weights are there including the biases ?
Using a filter [ 0 0 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 0 3 0 ] .
A point 3 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 2 .
What is the updated Q value of a tuple ( s a ) if q is 6 , the a is 0.1 , and t is 8 ?
If we have an image of size 50 by 50 and a filter of size 15 by 15 , how far out on each side should we pad to maintain the same output dimensions ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 4 .
Compute the loss from the datapoint ( negative 2 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Calculate the value of y in the dataset [ ( 0 0 ) , ( 1 2 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 2 .
Using a stride length of 1 , what is the output from applying a filter of length 9 to an image of length 52 ?
A neural network has inputs x1 = 1 with weight 2 and x2 = 0 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 3 . Compute the output .
Given an image of length 51 and a filter of length 5 , compute the output from applying the filter if we have a stride length of 1 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 3 and the maximum magnitude of a point is 14 .
x is ( negative 1 0 ) , theta is ( 1 negative 1 ) and theta_0 is 3 . What is the value of theta times x plus theta_0?
What does the sigmoid function return when  you pass into it 8 ? Hint: have e be 2.71828 .
What is the result from applying a filter [ 2 0 0 ] to a row of an image [ 4 3 0 ] , where the filter has a ReLU activation on its output ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 4 with an offset of 1 .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 2 and the maximum magnitude of a point is 9 .
What is the value of theta times x plus theta_0 if x is ( 1 0 ), theta is ( 1 negative 1 ) , and theta_0 is negative 1 ?
How much padding is needed on each side of a 70 by 70 input using a 37 by 37 filter to get an output the same size as the input ?
If there are 45 points on a 2D plane , 26 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
If there are 46 points on a 2D plane , 25 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
Calculate the value of y in the dataset [ ( 0 2 ) , ( 1 negative 2 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
What is the length of the output when we use an image of length 51 and a filter of length 17 if we use a stride length of 2 ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 3 ) and p is ( 0 0 ) ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 20 inputs and 90 outputs ?
Using theta = 0 and lda = 0.5 , calculate the mean squared error of the points  [ ( 2 0 )  and ( 1 3 ) ] .
If q is 6 , what is its updated value after applying Q learning if a is 0.2 and t is 4 ?
If a point 0 with label 1 was classified by a classifier with theta negative 1 and theta_0 negative 1 , what is the margin of this point ?
If a point 1 with label negative 1 was classified by a classifier with theta negative 1 and theta_0 0 , what is the margin of this point ?
Neuron A takes in value 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 4 . Compute the output of this neural network .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 4 , and wOC is 2 ?
Assume e is equal to 2.71828 . What do you get from passing the value 37 into the sigmoid function ?
If we are given the classifiers [ 1 1 0 ] and [ 0 4 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
If you let theta be 1 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( 2 * theta + 3 ) ^ 2 ?
Given an image row [ 1 0 1 ] and filter [ 1 4 1 ] , what is the result from applying the filter to the image row such that they both align ?
What is f(theta) if f(theta) is theta times 10 plus 19 squared and theta is 1 ?
A point p is classified by a classifier whose decision boundary is theta = ( 2 4 ) . How does it classify p , where p is ( 1 negative 4 ) ?
Assume e is equal to 2.71828 . What do you get from passing the value 14 into the sigmoid function ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 4 ) and p is ( 0 negative 4 ) ?
Now consider a zero-padded max pooling layer with 24 inputs , a pooling filter size of 5 and stride of 1 . How many total output units are there for this layer?
Given an image of length 53 and a filter of length 19 , compute the output from applying the filter if we have a stride length of 2 ?
If a point 2 with label 1 was classified by a classifier with theta 1 and theta_0 2 , what is the margin of this point ?
Now consider a zero-padded max pooling layer with 28 inputs , a pooling filter size of 1 and stride of 2 . How many total output units are there for this layer?
What is the most number of mistakes made by the perceptron algorithm if 18 is the maximum magnitude of a point in the dataset and the dataset has a margin of 5 to the separator .
If you are given two classifiers [ 1 3 1 ] and [ 1 1 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
What is the length of the output when we use an image of length 52 and a filter of length 15 if we use a stride length of 2 ?
Using a row of an image [ 4 3 1 ] and filter [ 0 1 0 ] , calculate the value from applying the filter which has a ReLU on its output .
Neuron A takes in value 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 2 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 4 . Compute the output of this neural network .
Given an image row [ 1 0 1 ] and filter [ 0 3 1 ] , what is the result from applying the filter to the image row such that they both align ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_6 if we have s_0 being 10 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 1 * s_t , and we input [ 11 8 12 16 4 0 ] ?
What is the value of theta times x plus theta_0 if x is ( 1 0 ), theta is ( 1 negative 1 ) , and theta_0 is 18 ?
A fully-connected neural network has 170 outputs and 10 inputs . How many total weights are there including the biases ?
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is negative 3 ?
Calculate the updated theta after one gradient descent step if theta is 1 , eta is 0.01 , and the loss function is ( 1 * theta + 3 ) ^ 4 .
Given a 50 by 50 image and 15 by 15 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Given two classifiers [ 3 1 0 ] and [ 1 2 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Compute the magnitude of [ 8 1 ] .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_3 after the inputs [ 2 18 18 ] ?
Given a 80 by 80 image and 3 by 3 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
A point 2 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 1 .
Given a function ( 2 * theta + 0 ) ^ 2 , calculate the value of the function after one gradient descent update if theta is 1 and eta is 0.05 .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 2 . What is the output of neuron C ?
Calculate the value of y in the dataset [ ( 0 1 ) , ( 1 negative 2 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 0.5 .
Given a function ( 2 * theta + 1 ) ^ 4 , calculate the value of the function after one gradient descent update if theta is 0 and eta is 0.01 .
Given the classifiers [ 1 0 0 ] and [ 0 4 1 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
An image I has length 90 and filter F has length 15 , what is the length of the result of applying F to I ?
Consider the classifier [ 1 1 0 ] and [ 0 0 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_3 if we have s_0 being 14 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 4 * s_t , and we input [ 5 14 13 ] ?
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 0 ) , ( 1 negative 1 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
Given the points  [ ( 2 negative 2 )  and ( 1 4 ) ] , what is the mean squared error if theta is 0 and lda is 0.5 ?
A left region has 4 points classified as positive. There are 44 points in the plane , and 24 points on the left . Compute the entropy .
After applying Q learning to q = 4 , what is its value ? Let the t be 2 and a be 0.1 .
What is the total number of outputs for a zero-padded max pooling layer that has 18 inputs , a stride of 1 , and a pooling filter size of 1 ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 3 with an offset of 1 .
If a is 0.2 and t is 8 , what is the Q learning value after applying one tuple ( s a ) if q is 5 ?
Let s_0 be 2 , w be 1 , and x be [ 2 2 0 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
A max pooling layer has 16 inputs, a pooling filter length of 2 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
A classifier has a decision boundary where theta is ( 1 3 ) . What value does it classify p , where p is ( 3 negative 3 ) ?
f(theta) is defined as 5 times theta plus 8 squared and theta is 1 . What is f(theta) ?
If f(theta) is 2 times theta plus 6 squared , what is f(theta) when theta is 2 ?
Let theta be ( 1 negative 1 ) , theta_0 be negative 3, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 50 inputs and 200 outputs ?
The function ( 2 * theta + 0 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.05 .
What is the margin on a point 3 with a label 1 if it is classified by a classifier with theta 1 and theta_0 negative 1 ?
Given the input negative 47 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 0 ) and p is ( 1 negative 3 ) ?
Consider the classifier [ 1 4 1 ] and [ 3 0 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
The left side of a region has 23 points . Of the 23 points , 4 are classified as positive . What is the entropy of the left region if there are 46 points in total ?
If we are given the classifiers [ 1 4 0 ] and [ 2 4 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
If x = [ 0 3 ] , what is || x || ?
Consider the point ( negative 1 1 ) , the theta 2 and the theta_0 2 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 1 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 5 , and wOC is 3 ?
What is the length of the result from applying F to I if F has length 41 and I has length 70?
Calculate the updated theta after one gradient descent step if theta is 2 , eta is 0.01 , and the loss function is ( 1 * theta + 3 ) ^ 4 .
What is the total number of outputs for a zero-padded max pooling layer that has 26 inputs , a stride of 1 , and a pooling filter size of 1 ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 3 0 ) ?
What is the NLL loss for the single data point ( 2 1 ) where theta is 2 and theta_0 is 0 ? Let the log be natural log ( base is 2.71828 ) .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , what is the output y_6 after the inputs [ 5 12 1 16 6 19 ] ?
Consider the input x_t = [ 18 6 18 19 15 5 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_6 if our initial conditions are s_0 is 13 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t .
Given a 70 by 70 image and 39 by 39 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
What is the value of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 2 ?
If we have a neural network layer with 40 inputs and 120 outputs , how many weights ( including biases ) are needed to describe each connection ?
Consider a 1D classification line on a 2D plane . There is a total of 47 points, 24 of which are on the right and the rest on the left of the boundary . 1 points on the left are classified positive . What is the entropy of the left region ?
What is the margin on a point 4 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 negative 2 ?
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 18 ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 2 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 4 with an offset of 1 .
What is the length of the output when we use an image of length 51 and a filter of length 21 if we use a stride length of 1 ?
Given an image row [ 1 3 0 ] and filter [ 2 4 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
What is f(theta) if f(theta) is theta times 2 plus 3 squared and theta is 1 ?
If an image has length 60 and filter has length 27 , compute the length of the output from applying the filter to the image ?
If q is 9 , what is its updated value after applying Q learning if a is 0.1 and t is 4 ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1 , w = 1 , and x = [ 0 3 1 ] , what is s_3 ?
What is the total number of outputs for a zero-padded max pooling layer that has 26 inputs , a stride of 1 , and a pooling filter size of 4 ?
Compute the loss from the datapoint ( 0 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 3 .
If we have an image of size 50 by 50 and a filter of size 11 by 11 , how far out on each side should we pad to maintain the same output dimensions ?
A point 0 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 1 .
If you are given two classifiers [ 1 1 1 ] and [ 0 4 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Given an image row [ 4 3 1 ] and filter [ 0 1 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Consider the classifier [ 1 4 0 ] and [ 3 2 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_3 if we have s_0 being 2 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 1 * s_t , and we input [ 17 10 14 ] ?
What is the total number of outputs for a zero-padded max pooling layer that has 22 inputs , a stride of 1 , and a pooling filter size of 3 ?
What is the length of the result from applying F to I if F has length 9 and I has length 60?
Consider the input x_t = [ 15 2 12 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_3 if our initial conditions are s_0 is 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t .
Consider a plane of 47 points , 25 of which are on the left side . Of the points on the left , 2 points are positive . Find the entropy of the left side .
Consider an image I of length 53 and filter F of length 21 . What is the length of the output if we have a stride length of 1 ?
Let 3 be the margin of the dataset with respect to the separator . Also let 13 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
A point p is classified by a classifier whose decision boundary is theta = ( 2 0 ) . How does it classify p , where p is ( 2 negative 1 ) ?
What is the output y_4 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , and input x_t = [ 2 17 18 6 ] ?
An image I has length 60 and filter F has length 35 , what is the length of the result of applying F to I ?
If a is 0.1 and t is 6 , what is the Q learning value after applying one tuple ( s a ) if q is 6 ?
After applying Q learning to q = 5 , what is its value ? Let the t be 10 and a be 0.2 .
A fully-connected neural network has 140 outputs and 50 inputs . How many total weights are there including the biases ?
A neural network has inputs x1 = 1 with weight 1 and x2 = 2 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 4 . Compute the output .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 2 . What is the output of neuron C ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 1 , and wOC is 3 ?
Compute the output length given the stride 1 , image length 50 , and filter length 3 .
Consider a filter [ 0 3 1 ] applied on an image [ 2 3 0 ] . What is the output if the filter has a ReLU activation ?
Consider the classifier [ 2 1 0 ] and [ 4 2 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
If the classifiers [ 2 1 0 ] and [ 2 2 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
If q is 0 , what is its updated value after applying Q learning if a is 0.1 and t is 8 ?
What is the updated Q value of a tuple ( s a ) if q is 1 , the a is 0.2 , and t is 8 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 1 and the maximum magnitude of a point is 10 .
Let a function f(theta) = ( 1 * theta + 3 ) ^ 3 . For theta = 3 and eta = 0.05 , calculate theta after one gradient descent step .
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 4 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 3 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
Using a row of an image [ 0 3 1 ] and filter [ 4 4 1 ] , calculate the value from applying the filter which has a ReLU on its output .
Let 1 be the margin of the dataset with respect to the separator . Also let 5 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 1 . Neuron B has input 0 and offset 1 . Neuron A has input 1 and offset 1 with offset 0.5 .
Determine how many pixels of padding we need on the input of size 60 by 60 to ensure our filter 7 by 7 gives an output of the same size .
Given a function ( 2 * theta + 2 ) ^ 4 , calculate the value of the function after one gradient descent update if theta is 0 and eta is 0.01 .
What is the updated Q value of a tuple ( s a ) if q is 0 , the a is 0.1 , and t is 10 ?
Given a 60 by 60 image and 25 by 25 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
What is the size of the margin of a point 3 by a classifier with theta negative 1 and theta_0 2 if the point has label 1 ?
Find the Euclidian length of [ 0 4 ] .
Assume e is equal to 2.71828 . What do you get from passing the value 45 into the sigmoid function ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_4 after the inputs [ 3 10 2 3 ] ?
If we have a neural network layer with 10 inputs and 60 outputs , how many weights ( including biases ) are needed to describe each connection ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 2 , and wOC is 2 ?
If filter F has length 35 and an image I has length 60 , what is the length of the result from applying F to I ?
Given a function ( 1 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 2 and eta is 0.01 .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1 , w = 1 , and x = [ 2 2 0 ] , what is s_3 ?
Let q = 2 . After Q learning, what is q if a is 0.2 and t is 4 ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 3 ) and p is ( 1 negative 2 ) ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 3 . Neuron B has input 3 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
x is ( negative 1 0 ) , theta is ( 1 negative 1 ) and theta_0 is 0.25 . What is the value of theta times x plus theta_0?
What is the result from applying a filter [ 1 4 1 ] to a row of an image [ 2 3 0 ] , where the filter has a ReLU activation on its output ?
Let 3 be the margin of the dataset with respect to the separator . Also let 3 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
A neural network has inputs x1 = 1 with weight 2 and x2 = 2 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 3 . Compute the output .
Compute the output of the sigmoid function when we pass in negative 17 . Let e be equal to 2.71828 .
How much padding is needed on each side of a 90 by 90 input using a 41 by 41 filter to get an output the same size as the input ?
What is the magnitude of the vector [ 5 4 ] ?
If the margin of the dataset with respect to a separator is 4 and the maximum magnitude of a point is 13 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Compute the output length given the stride 2 , image length 53 , and filter length 5 .
What is the value from applying a filter [ 1 4 1 ] directly on top of an image  [ 1 0 1 ] ?
How does a classifier with decision boundary theta classify a point p if theta is ( 1 4 ) and p is ( 0 negative 1 ) ?
Given a loss function , ( negative 1 * theta + 3 ) ^ 4 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 2 and eta be 0.05 .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 1 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 2 . What is the output of neuron C ?
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 3 . Neuron A takes in value x1 = 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 2 with an offset of 1 .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 0 , w = 0 , and x = [ 1 0 2 ] , what is s_3 ?
With lambda = 1 , the optimal theta is 1 . If the datapoints are [ ( 0 0 ) , ( 1 negative 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Given 46 points on a plane , 25 of them are on the right side of a line , and 3 of them that are on the left side are positive . Compute the entropy of the left side .
The function ( 2 * theta + negative 1 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 3 and eta be 0.05 .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 30 inputs and 200 outputs .
If f(theta) is 4 times theta plus 8 squared and theta is 1 what is f(theta) ?
The function ( 2 * theta + negative 1 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 2 and eta be 0.01 .
Neuron A takes in value 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 1 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 1 . Compute the output of this neural network .
If we are given the classifiers [ 1 3 0 ] and [ 1 0 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What is the updated Q value of a tuple ( s a ) if q is 5 , the a is 0.1 , and t is 2 ?
Consider an image I of length 52 and filter F of length 5 . What is the length of the output if we have a stride length of 2 ?
What is the output y_5 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , and input x_t = [ 15 12 15 5 5 ] ?
Compute the output of the sigmoid function when we pass in 29 . Let e be equal to 2.71828 .
Given two classifiers [ 4 1 1 ] and [ 4 0 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Given a function ( negative 1 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 4 and eta is 0.01 .
Given the dataset [ ( 0 0 ) , ( 1 2 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 0.5 ?
Let a function f(theta) = ( 2 * theta + 1 ) ^ 4 . For theta = 4 and eta = 0.05 , calculate f(theta) after one gradient descent update .
Given an image of length 52 and a filter of length 15 , compute the output from applying the filter if we have a stride length of 1 ?
A neural network has an input neuron A and output neuron C . Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 4 , and an input x1 being 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 2 . Find the output of the neural network .
If we have x equals ( 0 0 ), theta equals ( 1 negative 1 ), and theta_0 equals negative 3 , then what is the result of theta times x plus theta_0 ?
Let q = 6 . After Q learning, what is q if a is 0.1 and t is 4 ?
Calculate the updated theta after one gradient descent step if theta is 1 , eta is 0.05 , and the loss function is ( negative 2 * theta + 3 ) ^ 4 .
Compute the mean squared error with the data points  [ ( 2 2 )  and ( 1 4 ) ] , theta = 2 , and lda = 1 .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 4 ) and p is ( 0 negative 4 ) ?
How does a classifier with decision boundary theta classify a point p if theta is ( 1 4 ) and p is ( 0 negative 2 ) ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 5 , and wOC is 3 ?
Given an image of length 50 and a filter of length 19 , compute the output from applying the filter if we have a stride length of 2 ?
If f(theta) is 6 times theta plus 8 squared , what is f(theta) when theta is 2 ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 6 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , what is the output y_5 after the inputs [ 14 13 7 18 17 ] ?
The function ( 2 * theta + 0 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 4 and eta be 0.01 .
If we have a neural network layer with 20 inputs and 60 outputs , how many weights ( including biases ) are needed to describe each connection ?
Given a 50 by 50 image and 35 by 35 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Calculate the updated theta after one gradient descent step if theta is 2 , eta is 0.05 , and the loss function is ( 0 * theta + 3 ) ^ 2 .
What is the margin of a classifier with theta being 1 and theta_0 being negative 1 on a point 1 with label 1 ?
If we have a neural network layer with 20 inputs and 110 outputs , how many weights ( including biases ) are needed to describe each connection ?
Calculate the value of y in the dataset [ ( 0 2 ) , ( 1 2 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 0.5 .
If we know the stride 2 of a max pooling layer , along with the filter length of 1 and input length of 28 , what is the number of outputs of this layer ?
Consider a filter [ 2 2 1 ] applied on an image [ 2 3 1 ] . What is the output if the filter has a ReLU activation ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 60 outputs and 10 inputs .
Calculate the value of y in the dataset [ ( 0 negative 2 ) , ( 1 negative 2 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 1 .
Given the input negative 35 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 negative 2 ) , ( 1 1 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 4 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
Let a function f(theta) = ( negative 1 * theta + 3 ) ^ 4 . For theta = 0 and eta = 0.01 , calculate theta after one gradient descent step .
What is f(theta) if f(theta) is theta times 5 plus 19 squared and theta is 2 ?
Determine if the following two classifiers represent the same hyperplane , [ 1 1 1 ] and [ 4 3 0 ] . If so , return 1 , and return anything else otherwise .
Calculate the value of y in the dataset [ ( 0 negative 1 ) , ( 1 1 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 4 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 1 and applies an ReLU on its output . Compute the output .
Consider a 1D classification line on a 2D plane . There is a total of 48 points, 27 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?
What is the margin of a classifier with theta being negative 1 and theta_0 being negative 2 on a point 4 with label 1 ?
Given the dataset [ ( 0 1 ) , ( 1 0 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 1 ?
Let a function f(theta) = ( 2 * theta + 2 ) ^ 3 . For theta = 0 and eta = 0.01 , calculate f(theta) after one gradient descent update .
Do the two classifiers [ 2 1 0 ] and [ 4 2 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
What is the margin on a point 2 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 2 ?
Given a function ( 0 * theta + 3 ) ^ 2 , compute theta after one gradient descent step if theta is 3 and eta is 0.01 .
Calculate the updated theta after one gradient descent step if theta is 3 , eta is 0.01 , and the loss function is ( negative 1 * theta + 3 ) ^ 3 .
The left side of a region has 27 points . Of the 27 points , 2 are classified as positive . What is the entropy of the left region if there are 47 points in total ?
Compute the output length given the stride 2 , image length 52 , and filter length 11 .
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 3 . Neuron B has input 1 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
A point 3 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 2 .
Let a function f(theta) = ( 2 * theta + 3 ) ^ 2 . For theta = 1 and eta = 0.05 , calculate theta after one gradient descent step .
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 2 ) , ( 1 negative 2 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
What is the RNN result s_3 if s_0 is 3 , w is 1 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
What is the total number of outputs for a zero-padded max pooling layer that has 12 inputs , a stride of 2 , and a pooling filter size of 4 ?
What is the result from applying a filter [ 2 4 0 ] to a row of an image [ 0 3 0 ] , where the filter has a ReLU activation on its output ?
Consider an image I of length 54 and filter F of length 21 . What is the length of the output if we have a stride length of 2 ?
Consider the input x_t = [ 11 5 13 9 14 8 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_6 if our initial conditions are s_0 is 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t .
If we let theta be 0 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 1 1 ) ] ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 5 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , compute y_3 if the input is x_t = [ 7 14 8 ] .
If we are given the classifiers [ 1 4 1 ] and [ 1 1 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What is the value of theta times x plus theta_0 if x is ( 1 0 ), theta is ( negative 2 1 ) , and theta_0 is negative 3 ?
Given an image of length 51 and a filter of length 11 , compute the output from applying the filter if we have a stride length of 1 ?
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 2 ) , ( 1 0 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 0 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 3 and applies an ReLU on its output . Compute the output .
What is the value from applying a filter [ 3 2 0 ] directly on top of an image  [ 1 2 1 ] ?
Let a function f(theta) = ( negative 1 * theta + 3 ) ^ 4 . For theta = 4 and eta = 0.05 , calculate theta after one gradient descent step .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 4 and the maximum magnitude of a point is 4 .
What is the loss for the data point ( 0 2 ) if we use NLL . Let theta be 2 and theta_0 be 3 . Also use natural log where the base is 2.71828 .
What is the output y_5 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , and input x_t = [ 12 18 2 16 10 ] ?
Consider the point ( 2 2 ) , the theta 2 and the theta_0 1 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 4 , and wOC is 2 ?
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 2 with weight wOC being 3 . What is the output ?
A point 4 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 1 .
What is the result from applying a filter [ 0 1 0 ] to a row of an image [ 4 3 1 ] , where the filter has a ReLU activation on its output ?
After applying Q learning to q = 3 , what is its value ? Let the t be 4 and a be 0.1 .
Calculate the value of the function ( 2 * theta + 2 ) ^ 4 after updating the theta value in one step of gradient descent . Have theta be 4 and eta be 0.05 .
The left side of a region has 24 points . Of the 24 points , 4 are classified as positive . What is the entropy of the left region if there are 45 points in total ?
Given the values for theta as 2 and theta_0 as 1 , compute the NLL loss on the data point ( 2 1 ) . Use log base e of 2.71828 for the log .
There are 45 points on a 2D plane , 27 on the right side of a line and the rest on the left . 3 points on the left of the line are positive . What is the entropy of the left region ?
What is the total number of outputs for a zero-padded max pooling layer that has 10 inputs , a stride of 1 , and a pooling filter size of 1 ?
f(theta) is defined as 4 times theta plus 8 squared and theta is 2 . What is f(theta) ?
What is the NLL loss for the single data point ( negative 2 negative 2 ) where theta is 2 and theta_0 is 1 ? Let the log be natural log ( base is 2.71828 ) .
Now consider a zero-padded max pooling layer with 14 inputs , a pooling filter size of 4 and stride of 1 . How many total output units are there for this layer?
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 1 0 ) ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 3 . Neuron B has input 2 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 2 and a ReLU on its output . Compute the output of this neural network .
Compute the output of the sigmoid function when we pass in negative 23 . Let e be equal to 2.71828 .
What is the value of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 0.25 ?
Using a filter [ 1 0 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 3 3 1 ] .
If q is 7 , what is its updated value after applying Q learning if a is 0.2 and t is 2 ?
If we let theta be 3 and lda be 1 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 1 5 ) ] ?
Given a loss function , ( negative 2 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 4 and eta be 0.05 .
Calculate the value of y in the dataset [ ( 0 negative 1 ) , ( 1 negative 2 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 1 .
Given a loss function , ( negative 2 * theta + 3 ) ^ 4 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 2 and eta be 0.05 .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 140 outputs and 40 inputs .
If we have x equals ( 0 negative 1 ), theta equals ( negative 2 1 ), and theta_0 equals 3 , then what is the result of theta times x plus theta_0 ?
If an image has length 90 and filter has length 23 , compute the length of the output from applying the filter to the image ?
What is the updated Q value of a tuple ( s a ) if q is 8 , the a is 0.2 , and t is 8 ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 4 , and wOC is 3 ?
What is the length of the result from applying F to I if F has length 41 and I has length 60?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 0 , w is 1 , and x is [ 1 0 2 ] ?
Do the two classifiers [ 3 1 0 ] and [ 2 0 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Given the values for theta as 2 and theta_0 as 1 , compute the NLL loss on the data point ( 0 negative 1 ) . Use log base e of 2.71828 for the log .
Consider the input x_t = [ 8 0 16 3 7 7 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_6 if our initial conditions are s_0 is 2 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 2 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 2 with an offset of 1 .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 30 inputs and 190 outputs ?
If a point 4 with label negative 1 was classified by a classifier with theta negative 1 and theta_0 0 , what is the margin of this point ?
If f(theta) is 6 times theta plus 19 squared , what is f(theta) when theta is 2 ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_6 if we have s_0 being 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 3 * s_t , and we input [ 11 5 13 9 14 8 ] ?
Given theta be 0 and eta be 0.01 , calculate the value of the function ( 2 * theta + negative 2 ) ^ 4 after one step of gradient descent .
Given 48 points on a plane , 23 of them are on the right side of a line , and 3 of them that are on the left side are positive . Compute the entropy of the left side .
Let an input vector be [ 2 5 3 ] . What is its magnitude ?
Calculate the value of y in the dataset [ ( 0 negative 2 ) , ( 1 0 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 1 .
Given the dataset [ ( 0 0 ) , ( 1 1 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 0.5 ?
What does the sigmoid function return when  you pass into it 39 ? Hint: have e be 2.71828 .
If you are given two classifiers [ 1 0 1 ] and [ 2 3 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
What is f(theta) if f(theta) is theta times 6 plus 3 squared and theta is 2 ?
Calculate the value of y in the dataset [ ( 0 2 ) , ( 1 1 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
What is the size of the margin of a point 4 by a classifier with theta 1 and theta_0 0 if the point has label 1 ?
Consider a plane of 47 points , 26 of which are on the left side . Of the points on the left , 2 points are positive . Find the entropy of the left side .
If f(theta) is 5 times theta plus 6 squared and theta is 2 what is f(theta) ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 2 , w is 0.5 , and x is [ 0 3 1 ] , what is s_3 ?
What is the entropy of the left side of a region containing 26 points where the plane has 46 points in total and 2 points on the left are positive ?
Given the points  [ ( 2 0 )  and ( 1 1 ) ] , what is the mean squared error if theta is 1 and lda is 0.5 ?
Assume e is equal to 2.71828 . What do you get from passing the value negative 25 into the sigmoid function ?
Calculate the value of y in the dataset [ ( 0 0 ) , ( 1 negative 2 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
What is the NLL loss for the single data point ( 2 2 ) where theta is 2 and theta_0 is 2 ? Let the log be natural log ( base is 2.71828 ) .
Using a row of an image [ 2 3 1 ] and filter [ 2 4 0 ] , calculate the value from applying the filter which has a ReLU on its output .
Using a stride length of 1 , what is the output from applying a filter of length 19 to an image of length 50 ?
How much padding is needed on each side of a 50 by 50 input using a 25 by 25 filter to get an output the same size as the input ?
Consider the input x_t = [ 2 10 0 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_3 if our initial conditions are s_0 is 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t .
What is the value from applying a filter [ 1 2 0 ] directly on top of an image  [ 1 3 0 ] ?
If there are 46 points on a 2D plane , 23 of them on the right side split by a line , and 1 points on the left side that are positive , what is the entropy of the left region ?
If the classifiers [ 2 1 0 ] and [ 4 0 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Compute the mean squared error with the data points  [ ( 2 negative 2 )  and ( 2 5 ) ] , theta = 2 , and lda = 0.5 .
Compute the output of the sigmoid function when we pass in negative 35 . Let e be equal to 2.71828 .
What is the updated Q value of a tuple ( s a ) if q is 7 , the a is 0.1 , and t is 6 ?
If the margin of the dataset with respect to a separator is 4 and the maximum magnitude of a point is 6 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 4 , and wOC is 2 ?
What is the output y_5 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 13 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , and input x_t = [ 1 15 15 15 11 ] ?
Given a function ( 2 * theta + negative 1 ) ^ 3 , calculate the value of the function after one gradient descent update if theta is 0 and eta is 0.01 .
Given the input negative 9 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Using a filter [ 2 2 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 0 3 1 ] .
Let a function f(theta) = ( 1 * theta + 3 ) ^ 3 . For theta = 1 and eta = 0.05 , calculate theta after one gradient descent step .
What is the minimum number of padding needed to maintain the same output size if the input image is 80 by 80 and the filter is 35 by 35 ?
What is the margin of a classifier with theta being 1 and theta_0 being 2 on a point 4 with label 1 ?
Given the classifiers [ 1 0 1 ] and [ 0 0 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 3 with weight wOC being 2 . What is the output ?
f(theta) is the square of the sum of 3 and the product of 8 and theta , where theta is 2 . What is f(theta) ?
If the decision boundary of a classifier is theta , where theta is equal to ( 2 0 ) , how does it classify point p , where p is equal to ( 2 negative 2 ) ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 2 .
What is the result of applying the value 21 to the sigmoid function ? Let e be equal to 2.71828 .
If the decision boundary of a classifier is theta , where theta is equal to ( 2 0 ) , how does it classify point p , where p is equal to ( 1 negative 1 ) ?
Using the row of an image  [ 1 4 0 ] and a filter [ 1 2 0 ] , calculate the value of applying the filter on top of the image .
Given the input negative 7 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
What is the value of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is negative 1 ?
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 0 ) , ( 1 1 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
What does the sigmoid function return when  you pass into it negative 9 ? Hint: have e be 2.71828 .
If the decision boundary of a classifier is theta , where theta is equal to ( 2 4 ) , how does it classify point p , where p is equal to ( 3 0 ) ?
A point p is classified by a classifier whose decision boundary is theta = ( 2 3 ) . How does it classify p , where p is ( 0 negative 4 ) ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 20 inputs and 20 outputs ?
If we have a neural network layer with 30 inputs and 80 outputs , how many weights ( including biases ) are needed to describe each connection ?
If q is 3 , what is its updated value after applying Q learning if a is 0.1 and t is 6 ?
An image I has length 80 and filter F has length 31 , what is the length of the result of applying F to I ?
x is ( 0 0 ) , theta is ( negative 2 1 ) and theta_0 is 0.25 . What is the value of theta times x plus theta_0?
If a point 1 with label negative 1 was classified by a classifier with theta 1 and theta_0 0 , what is the margin of this point ?
Assume e is equal to 2.71828 . What do you get from passing the value 9 into the sigmoid function ?
If the margin of the dataset with respect to a separator is 4 and the maximum magnitude of a point is 16 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 4 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 5 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
Compute the loss from the datapoint ( 0 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 3 .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 160 outputs and 30 inputs .
How much padding is needed on each side of a 90 by 90 input using a 23 by 23 filter to get an output the same size as the input ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , what is the output y_5 after the inputs [ 15 12 15 5 5 ] ?
If we let theta be 2 and lda be 1 , what is the mean squared error of the given points  [ ( 2 negative 2 )  and ( 2 5 ) ] ?
Let theta be ( 1 negative 1 ) , theta_0 be 0.25, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .
What is the minimum number of padding needed to maintain the same output size if the input image is 50 by 50 and the filter is 19 by 19 ?
What does the sigmoid function return when  you pass into it 3 ? Hint: have e be 2.71828 .
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 negative 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
Determine how many pixels of padding we need on the input of size 90 by 90 to ensure our filter 35 by 35 gives an output of the same size .
If you are given two classifiers [ 1 3 0 ] and [ 2 2 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 negative 1 ) , ( 1 0 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
What is the RNN result s_3 if s_0 is 1.5 , w is 1.5 , and x is [ 2 2 0 ] if we let s_t = w * s_t-1 + x_t ?
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 2 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 and applies an ReLU on its output . Compute the output .
The function ( 2 * theta + 0 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.01 .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , what is the output y_6 after the inputs [ 7 18 9 6 2 17 ] ?
The function ( 2 * theta + 1 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.01 .
A left region has 4 points classified as positive. There are 48 points in the plane , and 23 points on the left . Compute the entropy .
x is ( negative 1 0 ) , theta is ( negative 2 1 ) and theta_0 is 0 . What is the value of theta times x plus theta_0?
What is f(theta) if f(theta) is theta times 5 plus 6 squared and theta is 2 ?
Consider a 1D classification line on a 2D plane . There is a total of 46 points, 23 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?
Compute the magnitude of [ 0 5 ] .
What is the RNN result s_3 if s_0 is 1.5 , w is 0.1 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
What is the most number of mistakes made by the perceptron algorithm if 12 is the maximum magnitude of a point in the dataset and the dataset has a margin of 3 to the separator .
The row of an image  [ 1 3 1 ] has a filter [ 3 3 0 ] applied to it . What is the resulting value if they both align ?
How much padding is needed on each side of a 90 by 90 input using a 35 by 35 filter to get an output the same size as the input ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1 , w is 0.5 , and x is [ 1 0 2 ] , what is s_3 ?
Consider a plane of 46 points , 25 of which are on the left side . Of the points on the left , 4 points are positive . Find the entropy of the left side .
Given an image of length 50 and a filter of length 13 , compute the output from applying the filter if we have a stride length of 2 ?
What is the length of the output when we use an image of length 52 and a filter of length 5 if we use a stride length of 1 ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 0 .
Given theta = 4 and lda = 1 , compute the mean squared error with the data points [ ( 2 negative 1 )  and ( 2 1 ) ] .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 1 negative 3 ) ?
What is the result of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 0.5 ?
Compute the output of the sigmoid function when we pass in negative 4 . Let e be equal to 2.71828 .
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 1.5 , w is 0.1 , and x is [ 0 3 1 ] ?
If f(theta) is 4 times theta plus 8 squared , what is f(theta) when theta is 2 ?
What is the most number of mistakes made by the perceptron algorithm if 20 is the maximum magnitude of a point in the dataset and the dataset has a margin of 2 to the separator .
What does the sigmoid function return when  you pass into it 20 ? Hint: have e be 2.71828 .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 50 inputs and 40 outputs .
Let theta be ( negative 2 1 ) , theta_0 be 6, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 40 inputs and 10 outputs ?
If we have x equals ( 0 0 ), theta equals ( negative 2 1 ), and theta_0 equals 2 , then what is the result of theta times x plus theta_0 ?
Let s_0 be 1 , w be 0.1 , and x be [ 2 2 0 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
What is the margin on a point 3 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 negative 2 ?
The function ( 2 * theta + negative 1 ) ^ 2 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 2 and eta be 0.05 .
An image I has length 90 and filter F has length 9 , what is the length of the result of applying F to I ?
What is the length of the result from applying F to I if F has length 29 and I has length 70?
A point p is classified by a classifier whose decision boundary is theta = ( 2 0 ) . How does it classify p , where p is ( 2 0 ) ?
Consider the point ( negative 2 1 ) , the theta 2 and the theta_0 0 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
What is the result from applying a filter [ 2 2 0 ] to a row of an image [ 4 3 0 ] , where the filter has a ReLU activation on its output ?
What is the RNN result s_2 if s_0 is 1 , w is 0.5 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
f(theta) is the square of the sum of 8 and the product of 9 and theta , where theta is 2 . What is f(theta) ?
Neurons A and B take inputs 1 and 4 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 1 . What is the output ?
Given the largest magnitude of a point as 8 and the margin of the dataset be 1 from the separator , compute the most number of mistakes made by the perceptron algotithm .
A max pooling layer has 24 inputs, a pooling filter length of 4 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
How much padding is needed on each side of a 50 by 50 input using a 39 by 39 filter to get an output the same size as the input ?
Given two classifiers [ 1 1 0 ] and [ 1 0 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
If q is 6 , what is its updated value after applying Q learning if a is 0.1 and t is 4 ?
Let a function f(theta) = ( 2 * theta + negative 1 ) ^ 4 . For theta = 2 and eta = 0.01 , calculate f(theta) after one gradient descent update .
What is the size of the margin of a point 3 by a classifier with theta negative 1 and theta_0 0 if the point has label 1 ?
A max pooling layer has 26 inputs, a pooling filter length of 5 , a stride length of 2 , and is zero-padded . Compute the number of output units for this layer .
What is the RNN result s_3 if s_0 is 2 , w is 0 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
Given the points  [ ( 2 0 )  and ( 2 4 ) ] , what is the mean squared error if theta is 2 and lda is 1 ?
Let theta be ( 1 negative 1 ) , theta_0 be 18, and x be ( 0 , 0 ) . Compute theta times x plus theta_0 .
Given the points  [ ( 2 negative 1 )  and ( 2 3 ) ] , what is the mean squared error if theta is 2 and lda is 0.5 ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 0 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 4 and applies an ReLU on its output . Compute the output .
Given the dataset [ ( 0 2 ) , ( 1 1 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 1 is minimal . What does y need to be if lambda is 1 ?
What is the size of the margin of a point 3 by a classifier with theta negative 1 and theta_0 negative 1 if the point has label negative 1 ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 2 . Neuron B has input 2 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
A point p is classified by a classifier whose decision boundary is theta = ( 1 4 ) . How does it classify p , where p is ( 2 0 ) ?
Given the values for theta as 2 and theta_0 as 0 , compute the NLL loss on the data point ( negative 1 0 ) . Use log base e of 2.71828 for the log .
If we have x equals ( 1 0 ), theta equals ( 1 negative 1 ), and theta_0 equals negative 1 , then what is the result of theta times x plus theta_0 ?
Given the dataset [ ( 0 negative 2 ) , ( 1 2 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 0.5 ?
Consider the point ( 1 1 ) , the theta 2 and the theta_0 3 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
If we let theta be 4 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 negative 1 )  and ( 2 3 ) ] ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 1 0 ) ?
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 0 ) , ( 1 1 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
What is the minimum number of padding needed to maintain the same output size if the input image is 80 by 80 and the filter is 11 by 11 ?
How much padding is needed on each side of a 60 by 60 input using a 35 by 35 filter to get an output the same size as the input ?
Let q = 6 . After Q learning, what is q if a is 0.2 and t is 6 ?
If f(theta) is 6 times theta plus 5 squared and theta is 1 what is f(theta) ?
Let q = 5 . After Q learning, what is q if a is 0.2 and t is 6 ?
Given a 80 by 80 image and 15 by 15 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
If we know the stride 2 of a max pooling layer , along with the filter length of 1 and input length of 26 , what is the number of outputs of this layer ?
What is the result from applying a filter [ 3 1 0 ] to a row of an image [ 3 3 1 ] , where the filter has a ReLU activation on its output ?
What is the size of the margin of a point 1 by a classifier with theta negative 1 and theta_0 negative 2 if the point has label negative 1 ?
Neurons A and B take inputs 1 and 0 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 4 . What is the output ?
An image I has length 70 and filter F has length 5 , what is the length of the result of applying F to I ?
Given that there are 18 inputs to a zero-padded max pooling layer and a stride length of 1 , compute the number of output units if we also know the pooling filter size of 3 ?
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 1 and a ReLU on its output . Compute the output of this neural network .
Given an image row [ 1 2 0 ] and filter [ 2 1 0 ] , what is the result from applying the filter to the image row such that they both align ?
If a region has 25 points on the left and 46 points total . 2 points that are on the left are positive. Compute the entropy .
Given a 80 by 80 image and 27 by 27 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 5 . Neuron B has input 3 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
What is the length of the output when we use an image of length 52 and a filter of length 17 if we use a stride length of 1 ?
Given a loss function , ( negative 1 * theta + 3 ) ^ 2 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 0 and eta be 0.01 .
Compute the value returned from aligning the filter  [ 1 1 0 ] to the image  [ 1 1 0 ] on top of one another .
Given the classifiers [ 1 3 0 ] and [ 1 2 1 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Using a filter [ 1 1 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 0 3 1 ] .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 190 outputs and 50 inputs .
Consider a plane of 47 points , 27 of which are on the left side . Of the points on the left , 4 points are positive . Find the entropy of the left side .
Using theta = 2 and lda = 0.5 , calculate the mean squared error of the points  [ ( 2 negative 2 )  and ( 1 3 ) ] .
What is the result from applying a filter [ 1 0 1 ] to a row of an image [ 4 3 1 ] , where the filter has a ReLU activation on its output ?
If the margin of the dataset with respect to a separator is 3 and the maximum magnitude of a point is 9 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
If you are given two classifiers [ 1 4 0 ] and [ 2 4 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
If the classifiers [ 1 1 1 ] and [ 2 0 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Determine how many pixels of padding we need on the input of size 70 by 70 to ensure our filter 11 by 11 gives an output of the same size .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , compute y_6 if the input is x_t = [ 5 12 1 16 6 19 ] .
Using a filter [ 1 1 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 0 3 0 ] .
Given theta = 4 and lda = 1 , compute the mean squared error with the data points [ ( 2 2 )  and ( 2 2 ) ] .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 0 .
x is ( 0 0 ) , theta is ( negative 2 1 ) and theta_0 is 6 . What is the value of theta times x plus theta_0?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 4 , and wOC is 2 ?
Determine if the following two classifiers represent the same hyperplane , [ 0 1 1 ] and [ 3 3 0 ] . If so , return 1 , and return anything else otherwise .
Compute the output of the sigmoid function when we pass in 34 . Let e be equal to 2.71828 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 4 , and wOC is 2 ?
If x = [ 6 2 1 ], what is || x || ?
If x = [ 0 5 1 ], what is || x || ?
If f(theta) is 4 times theta plus 3 squared and theta is 2 what is f(theta) ?
What is the updated Q value of a tuple ( s a ) if q is 5 , the a is 0.2 , and t is 2 ?
A neural network has inputs x1 = 1 with weight 1 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 1 . Compute the output .
Given 48 points on a plane , 23 of them are on the right side of a line , and 1 of them that are on the left side are positive . Compute the entropy of the left side .
Neurons A and B take inputs negative 1 and 4 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 2 , respectively , and with offset 2 . Neuron C also applies a ReLU on its output . What is the output ?
What is the most number of mistakes made by the perceptron algorithm if 10 is the maximum magnitude of a point in the dataset and the dataset has a margin of 2 to the separator .
What is the most number of mistakes made by the perceptron algorithm if 19 is the maximum magnitude of a point in the dataset and the dataset has a margin of 2 to the separator .
What is the entropy of the left side of a region containing 26 points where the plane has 44 points in total and 2 points on the left are positive ?
After applying Q learning to q = 2 , what is its value ? Let the t be 6 and a be 0.2 .
What is the result of applying the value negative 35 to the sigmoid function ? Let e be equal to 2.71828 .
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 2 ) , ( 1 negative 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
What is the length of the output when we use an image of length 50 and a filter of length 3 if we use a stride length of 2 ?
What is the NLL loss for the single data point ( negative 2 1 ) where theta is 2 and theta_0 is 1 ? Let the log be natural log ( base is 2.71828 ) .
Let theta be ( negative 2 1 ) , theta_0 be 0.5, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .
An image I has length 50 and filter F has length 17 , what is the length of the result of applying F to I ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 5 , and wOC is 2 ?
Let a function f(theta) = ( 1 * theta + 3 ) ^ 4 . For theta = 2 and eta = 0.05 , calculate theta after one gradient descent step .
f(theta) is defined as 4 times theta plus 5 squared and theta is 2 . What is f(theta) ?
What is the loss for the data point ( negative 2 negative 2 ) if we use NLL . Let theta be 2 and theta_0 be 3 . Also use natural log where the base is 2.71828 .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_3 after the inputs [ 14 16 15 ] ?
What is the most number of mistakes made by the perceptron algorithm if 5 is the maximum magnitude of a point in the dataset and the dataset has a margin of 1 to the separator .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 24 points on the right side , and 46 points total .
Using the row of an image  [ 1 3 1 ] and a filter [ 2 4 0 ] , calculate the value of applying the filter on top of the image .
If we let theta be 2 and lda be 1 , what is the mean squared error of the given points  [ ( 2 0 )  and ( 1 5 ) ] ?
If you let theta be 3 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( 0 * theta + 3 ) ^ 2 ?
Consider the classifier [ 4 1 0 ] and [ 1 3 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
After applying Q learning to q = 6 , what is its value ? Let the t be 8 and a be 0.1 .
Let an input vector be [ 9 0 ] . What is its magnitude ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 2 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , compute y_3 if the input is x_t = [ 17 10 14 ] .
Compute the value returned from aligning the filter  [ 1 4 0 ] to the image  [ 1 4 0 ] on top of one another .
If we have a neural network layer with 30 inputs and 160 outputs , how many weights ( including biases ) are needed to describe each connection ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 0 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
Determine how many pixels of padding we need on the input of size 50 by 50 to ensure our filter 7 by 7 gives an output of the same size .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 1 ) , ( 1 negative 2 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 20 inputs and 200 outputs .
A point p is classified by a classifier whose decision boundary is theta = ( 2 0 ) . How does it classify p , where p is ( 3 negative 1 ) ?
Do the classifiers [ 1 0 0 ] and [ 0 4 0 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
Determine if the following two classifiers represent the same hyperplane , [ 0 1 1 ] and [ 1 0 1 ] . If so , return 1 , and return anything else otherwise .
What is the length of the result from applying F to I if F has length 3 and I has length 90?
Given a 1D image I that is length 90 and a filter F that is length 9 , what is the length of the result from applying F to I ?
The left side of a region has 24 points . Of the 24 points , 2 are classified as positive . What is the entropy of the left region if there are 47 points in total ?
Using theta = 4 and lda = 1 , calculate the mean squared error of the points  [ ( 2 0 )  and ( 2 5 ) ] .
Given that there are 24 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 5 ?
Given the points  [ ( 2 negative 2 )  and ( 1 2 ) ] , what is the mean squared error if theta is 4 and lda is 0.5 ?
Determine if the following two classifiers represent the same hyperplane , [ 0 1 0 ] and [ 4 0 0 ] . If so , return 1 , and return anything else otherwise .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 2 negative 3 ) ?
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 30 inputs and 190 outputs .
Given an image of length 52 and a filter of length 13 , compute the output from applying the filter if we have a stride length of 2 ?
Let a function f(theta) = ( 1 * theta + 3 ) ^ 4 . For theta = 2 and eta = 0.01 , calculate theta after one gradient descent step .
Let a function f(theta) = ( negative 1 * theta + 3 ) ^ 4 . For theta = 4 and eta = 0.01 , calculate theta after one gradient descent step .
A fully-connected neural network has 140 outputs and 30 inputs . How many total weights are there including the biases ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 1 negative 2 ) ?
Given an image row [ 1 1 0 ] and filter [ 4 1 1 ] , what is the result from applying the filter to the image row such that they both align ?
If we have an image of size 80 by 80 and a filter of size 27 by 27 , how far out on each side should we pad to maintain the same output dimensions ?
If a is 0.2 and t is 8 , what is the Q learning value after applying one tuple ( s a ) if q is 4 ?
Given 48 points on a plane , 25 of them are on the right side of a line , and 1 of them that are on the left side are positive . Compute the entropy of the left side .
How much padding is needed on each side of a 90 by 90 input using a 29 by 29 filter to get an output the same size as the input ?
Consider a 1D classification line on a 2D plane . There is a total of 46 points, 27 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?
What is the updated Q value of a tuple ( s a ) if q is 6 , the a is 0.1 , and t is 6 ?
Calculate the updated theta after one gradient descent step if theta is 1 , eta is 0.05 , and the loss function is ( 2 * theta + 3 ) ^ 3 .
What is the result from applying a filter [ 0 3 1 ] to a row of an image [ 4 3 1 ] , where the filter has a ReLU activation on its output ?
A point 0 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 1 .
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 1 3 ) and p is ( 3 negative 4 ) ?
If x = [ 1 3 3 ], what is || x || ?
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 3 . Neuron A takes in value x1 = 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 3 with an offset of 1 .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 10 outputs and 50 inputs .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 4 . Neuron B has input 1 and offset 1 . Neuron A has input 1 and offset 1 with offset 0.5 .
Using the row of an image  [ 1 1 0 ] and a filter [ 0 4 1 ] , calculate the value of applying the filter on top of the image .
Let 2 be the margin of the dataset with respect to the separator . Also let 7 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 5 , and wOC is 2 ?
If an image has length 70 and filter has length 21 , compute the length of the output from applying the filter to the image ?
Using a filter [ 1 2 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 1 3 1 ] .
Given an image of length 52 and a filter of length 11 , compute the output from applying the filter if we have a stride length of 1 ?
Consider the classifier [ 2 1 1 ] and [ 0 2 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Determine how many pixels of padding we need on the input of size 70 by 70 to ensure our filter 31 by 31 gives an output of the same size .
Given a loss function , ( 1 * theta + 3 ) ^ 4 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 4 and eta be 0.01 .
If we know the stride 2 of a max pooling layer , along with the filter length of 3 and input length of 18 , what is the number of outputs of this layer ?
If q is 9 , what is its updated value after applying Q learning if a is 0.1 and t is 2 ?
Consider the point ( negative 2 negative 2 ) , the theta 2 and the theta_0 2 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
Given a 90 by 90 image and 17 by 17 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 2 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 2 and applies an ReLU on its output . Compute the output .
What is the margin of a classifier with theta being 1 and theta_0 being 0 on a point 3 with label negative 1 ?
Do the two classifiers [ 4 1 1 ] and [ 4 0 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
If we are given the classifiers [ 1 2 0 ] and [ 0 1 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 4 , and wOC is 3 ?
If filter F has length 11 and an image I has length 60 , what is the length of the result from applying F to I ?
The function ( 2 * theta + 2 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.01 .
If the classifiers [ 3 1 0 ] and [ 2 0 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Compute the loss from the datapoint ( 1 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Consider a filter [ 2 3 1 ] applied on an image [ 1 3 1 ] . What is the output if the filter has a ReLU activation ?
A classifier has a decision boundary where theta is ( 2 4 ) . What value does it classify p , where p is ( 1 negative 2 ) ?
Calculate the updated theta after one gradient descent step if theta is 3 , eta is 0.01 , and the loss function is ( negative 2 * theta + 3 ) ^ 4 .
Now consider a zero-padded max pooling layer with 22 inputs , a pooling filter size of 3 and stride of 1 . How many total output units are there for this layer?
If we have x equals ( 1 negative 1 ), theta equals ( negative 2 1 ), and theta_0 equals negative 1 , then what is the result of theta times x plus theta_0 ?
x is ( 1 negative 1 ) , theta is ( negative 2 1 ) and theta_0 is 6 . What is the value of theta times x plus theta_0?
Neuron A takes in value 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 1 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 3 . Compute the output of this neural network .
What is the most number of mistakes made by the perceptron algorithm if 5 is the maximum magnitude of a point in the dataset and the dataset has a margin of 5 to the separator .
If f(theta) is 10 times theta plus 19 squared , what is f(theta) when theta is 2 ?
Given the input negative 50 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 3 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
Compute the output length given the stride 2 , image length 54 , and filter length 11 .
If we are given the classifiers [ 1 0 0 ] and [ 0 4 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Compute the output of the sigmoid function when we pass in negative 16 . Let e be equal to 2.71828 .
A point 4 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be 2 .
Given an image row [ 1 3 0 ] and filter [ 3 3 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
A left region has 4 points classified as positive. There are 45 points in the plane , and 24 points on the left . Compute the entropy .
With lambda = 0.5 , the optimal theta is 2 . If the datapoints are [ ( 0 negative 1 ) , ( 1 0 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 4 ) , how does it classify point p , where p is equal to ( 0 0 ) ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 and applies an ReLU on its output . Compute the output .
Given an image of length 53 and a filter of length 15 , compute the output from applying the filter if we have a stride length of 1 ?
Consider the point ( 0 negative 1 ) , the theta 2 and the theta_0 0 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
If we have an image of size 60 by 60 and a filter of size 19 by 19 , how far out on each side should we pad to maintain the same output dimensions ?
Do the two classifiers [ 3 1 0 ] and [ 4 2 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Consider an image I of length 50 and filter F of length 13 . What is the length of the output if we have a stride length of 2 ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 14 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , compute y_5 if the input is x_t = [ 5 4 2 15 1 ] .
A point p is classified by a classifier whose decision boundary is theta = ( 2 0 ) . How does it classify p , where p is ( 2 negative 2 ) ?
If x = [ 2 1 3 ], what is || x || ?
The row of an image  [ 1 2 1 ] has a filter [ 0 2 1 ] applied to it . What is the resulting value if they both align ?
Compute the output length given the stride 2 , image length 53 , and filter length 19 .
What is the margin on a point 3 with a label negative 1 if it is classified by a classifier with theta 1 and theta_0 negative 2 ?
f(theta) is the square of the sum of 3 and the product of 10 and theta , where theta is 2 . What is f(theta) ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 1 4 ) and p is ( 0 0 ) ?
If we have an image of size 90 by 90 and a filter of size 35 by 35 , how far out on each side should we pad to maintain the same output dimensions ?
Using the row of an image  [ 1 4 0 ] and a filter [ 3 4 0 ] , calculate the value of applying the filter on top of the image .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 4 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
If a region has 27 points on the left and 45 points total . 2 points that are on the left are positive. Compute the entropy .
Given the largest magnitude of a point as 1 and the margin of the dataset be 3 from the separator , compute the most number of mistakes made by the perceptron algotithm .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 5 , and wOC is 2 ?
The left side of a region has 27 points . Of the 27 points , 2 are classified as positive . What is the entropy of the left region if there are 48 points in total ?
Let a function f(theta) = ( negative 2 * theta + 3 ) ^ 3 . For theta = 1 and eta = 0.01 , calculate theta after one gradient descent step .
If f(theta) is 2 times theta plus 8 squared , what is f(theta) when theta is 1 ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 negative 1 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
What is the length of the output when we use an image of length 52 and a filter of length 13 if we use a stride length of 1 ?
Given theta = 4 and lda = 0.5 , compute the mean squared error with the data points [ ( 2 0 )  and ( 1 5 ) ] .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 20 outputs and 10 inputs .
What is the most number of mistakes made by the perceptron algorithm if 13 is the maximum magnitude of a point in the dataset and the dataset has a margin of 4 to the separator .
Consider the classifier [ 1 0 0 ] and [ 4 3 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Using a stride length of 1 , what is the output from applying a filter of length 17 to an image of length 54 ?
What is the length of the result from applying F to I if F has length 23 and I has length 80?
How much padding is needed on each side of a 80 by 80 input using a 3 by 3 filter to get an output the same size as the input ?
Given that there are 26 inputs to a zero-padded max pooling layer and a stride length of 1 , compute the number of output units if we also know the pooling filter size of 4 ?
What is the NLL loss for the single data point ( negative 2 1 ) where theta is 2 and theta_0 is 0 ? Let the log be natural log ( base is 2.71828 ) .
Consider a filter [ 1 0 1 ] applied on an image [ 3 3 1 ] . What is the output if the filter has a ReLU activation ?
Compute the value returned from aligning the filter  [ 1 4 0 ] to the image  [ 1 4 0 ] on top of one another .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 0 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , compute y_3 if the input is x_t = [ 18 12 5 ] .
The function ( 2 * theta + 0 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 2 and eta be 0.05 .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
Given theta be 3 and eta be 0.05 , calculate the value of the function ( 2 * theta + negative 2 ) ^ 2 after one step of gradient descent .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 1 , and wOC is 2 ?
Using the row of an image  [ 1 3 0 ] and a filter [ 2 3 1 ] , calculate the value of applying the filter on top of the image .
Determine how many pixels of padding we need on the input of size 60 by 60 to ensure our filter 31 by 31 gives an output of the same size .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 1 points on the left side that are positive , 23 points on the right side , and 46 points total .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_3 if we have s_0 being 10 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 3 * s_t , and we input [ 14 13 15 ] ?
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 negative 1 ) , ( 1 0 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
If we have a neural network layer with 10 inputs and 30 outputs , how many weights ( including biases ) are needed to describe each connection ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 3 , and wOC is 3 ?
Given a 1D image I that is length 50 and a filter F that is length 35 , what is the length of the result from applying F to I ?
Given the points  [ ( 2 1 )  and ( 2 5 ) ] , what is the mean squared error if theta is 3 and lda is 0.5 ?
After applying Q learning to q = 2 , what is its value ? Let the t be 2 and a be 0.1 .
Let a function f(theta) = ( 1 * theta + 3 ) ^ 2 . For theta = 4 and eta = 0.05 , calculate theta after one gradient descent step .
Consider a 1D classification line on a 2D plane . There is a total of 47 points, 25 of which are on the right and the rest on the left of the boundary . 1 points on the left are classified positive . What is the entropy of the left region ?
What is the value of theta times x plus theta_0 if x is ( 0 0 ), theta is ( negative 2 1 ) , and theta_0 is 0.25 ?
If the decision boundary of a classifier is theta , where theta is equal to ( 2 3 ) , how does it classify point p , where p is equal to ( 1 negative 1 ) ?
A left region has 4 points classified as positive. There are 46 points in the plane , and 26 points on the left . Compute the entropy .
Compute the mean squared error with the data points  [ ( 2 0 )  and ( 2 1 ) ] , theta = 3 , and lda = 0.5 .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 5 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , compute y_3 if the input is x_t = [ 5 14 5 ] .
Given an image of length 54 and a filter of length 9 , compute the output from applying the filter if we have a stride length of 2 ?
What is the output y_5 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , and input x_t = [ 3 4 4 10 16 ] ?
Given an image row [ 0 3 0 ] and filter [ 1 3 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Given an image row [ 1 3 1 ] and filter [ 2 1 0 ] , what is the result from applying the filter to the image row such that they both align ?
If the classifiers [ 0 1 0 ] and [ 3 1 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
If you are given two classifiers [ 1 4 0 ] and [ 3 2 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 3 and applies an ReLU on its output . Compute the output .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 1 , and wOC is 2 ?
Let theta be ( 1 negative 1 ) , theta_0 be 3, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .
What is the NLL loss for the single data point ( 2 negative 2 ) where theta is 2 and theta_0 is 1 ? Let the log be natural log ( base is 2.71828 ) .
Given a 1D image I that is length 90 and a filter F that is length 11 , what is the length of the result from applying F to I ?
What is the RNN result s_3 if s_0 is 3 , w is 1.5 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
Compute the value returned from aligning the filter  [ 1 4 1 ] to the image  [ 1 4 1 ] on top of one another .
Given the values for theta as 2 and theta_0 as 2 , compute the NLL loss on the data point ( negative 2 2 ) . Use log base e of 2.71828 for the log .
A point p is classified by a classifier whose decision boundary is theta = ( 1 4 ) . How does it classify p , where p is ( 0 negative 3 ) ?
Calculate the entropy of the left region of a 2D plane, split by a line . There are 1 points on the left side that are positive , 26 points on the right side , and 45 points total .
What is the RNN result s_2 if s_0 is 0 , w is 0.1 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
If we let theta be 3 and lda be 1 , what is the mean squared error of the given points  [ ( 2 0 )  and ( 1 1 ) ] ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 4 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 4 with an offset of 1 .
Using a stride length of 1 , what is the output from applying a filter of length 5 to an image of length 53 ?
If we have an image of size 60 by 60 and a filter of size 41 by 41 , how far out on each side should we pad to maintain the same output dimensions ?
If x = [ 6 1 ] , what is || x || ?
What is the NLL loss for the single data point ( negative 2 negative 1 ) where theta is 2 and theta_0 is 2 ? Let the log be natural log ( base is 2.71828 ) .
What is the margin of a classifier with theta being 1 and theta_0 being negative 2 on a point 4 with label negative 1 ?
What is the length of the result from applying F to I if F has length 39 and I has length 90?
What is the NLL loss for the single data point ( 1 negative 2 ) where theta is 2 and theta_0 is 0 ? Let the log be natural log ( base is 2.71828 ) .
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 2 0 ) ?
Using theta = 1 and lda = 1 , calculate the mean squared error of the points  [ ( 2 0 )  and ( 1 4 ) ] .
Neurons A and B take inputs negative 1 and 2 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 2 , respectively , and with offset 5 . Neuron C also applies a ReLU on its output . What is the output ?
Consider a 1D classification line on a 2D plane . There is a total of 45 points, 27 of which are on the right and the rest on the left of the boundary . 1 points on the left are classified positive . What is the entropy of the left region ?
Let s_0 be 1.5 , w be 0.1 , and x be [ 0.25 0.5 ] . Compute s_2 if s_t is w * s_t-1 + x_t .
If the margin of the dataset with respect to a separator is 5 and the maximum magnitude of a point is 13 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Given the input negative 28 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
What is the loss for the data point ( 0 1 ) if we use NLL . Let theta be 2 and theta_0 be 3 . Also use natural log where the base is 2.71828 .
What is the length of the result from applying F to I if F has length 9 and I has length 80?
Consider a 1D classification line on a 2D plane . There is a total of 47 points, 23 of which are on the right and the rest on the left of the boundary . 1 points on the left are classified positive . What is the entropy of the left region ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 4 . Neuron B has input 1 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1 , w is 1.5 , and x is [ 2 2 0 ] , what is s_3 ?
What is the most number of mistakes made by the perceptron algorithm if 6 is the maximum magnitude of a point in the dataset and the dataset has a margin of 1 to the separator .
If x = [ 0 5 ] , what is || x || ?
If the decision boundary of a classifier is theta , where theta is equal to ( 1 3 ) , how does it classify point p , where p is equal to ( 2 negative 4 ) ?
Neuron A takes in value 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 3 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 2 . Compute the output of this neural network .
Given a function ( 2 * theta + 2 ) ^ 2 , calculate the value of the function after one gradient descent update if theta is 3 and eta is 0.05 .
Using a filter [ 0 0 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 1 3 0 ] .
Given a function ( negative 1 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 1 and eta is 0.05 .
Given the largest magnitude of a point as 3 and the margin of the dataset be 3 from the separator , compute the most number of mistakes made by the perceptron algotithm .
If you let theta be 0 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 2 * theta + 3 ) ^ 2 ?
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 2 ) , ( 1 negative 2 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Assume e is equal to 2.71828 . What do you get from passing the value negative 48 into the sigmoid function ?
What does the sigmoid function return when  you pass into it negative 34 ? Hint: have e be 2.71828 .
Compute the output length given the stride 2 , image length 52 , and filter length 7 .
Let theta be ( negative 2 1 ) , theta_0 be 0, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .
A classifier has a decision boundary where theta is ( 2 3 ) . What value does it classify p , where p is ( 2 0 ) ?
f(theta) is defined as 10 times theta plus 8 squared and theta is 2 . What is f(theta) ?
Let q = 4 . After Q learning, what is q if a is 0.1 and t is 2 ?
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 1.5 , w is 0.5 , and x is [ 2 2 0 ] ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 0 , w is 0.1 , and x is [ 0.25 0.5 ] , what is s_2 ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 1.5 , and x is [ 1 0 2 ] , what is s_3 ?
How much padding is needed on each side of a 70 by 70 input using a 27 by 27 filter to get an output the same size as the input ?
Given an image row [ 1 0 0 ] and filter [ 4 4 0 ] , what is the result from applying the filter to the image row such that they both align ?
Given a function ( 2 * theta + 2 ) ^ 4 , calculate the value of the function after one gradient descent update if theta is 1 and eta is 0.05 .
Given 46 points on a plane , 26 of them are on the right side of a line , and 3 of them that are on the left side are positive . Compute the entropy of the left side .
If we have x equals ( negative 1 0 ), theta equals ( 1 negative 1 ), and theta_0 equals 3 , then what is the result of theta times x plus theta_0 ?
If there are 48 points on a 2D plane , 25 of them on the right side split by a line , and 1 points on the left side that are positive , what is the entropy of the left region ?
If we let theta be 4 and lda be 1 , what is the mean squared error of the given points  [ ( 2 negative 1 )  and ( 1 4 ) ] ?
Neurons A and B take inputs 1 and 2 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 3 . What is the output ?
Compute the output length given the stride 1 , image length 54 , and filter length 5 .
If the classifiers [ 3 1 1 ] and [ 0 1 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Now consider a zero-padded max pooling layer with 10 inputs , a pooling filter size of 1 and stride of 2 . How many total output units are there for this layer?
Consider the classifier [ 1 1 0 ] and [ 2 4 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 1 with weight wOC being 2 . What is the output of neuron C ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 1 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , what is the output y_3 after the inputs [ 15 13 3 ] ?
If you let theta be 2 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( 2 * theta + 3 ) ^ 4 ?
Neurons A and B take inputs 1 and 3 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 3 . What is the output ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 1 ) , ( 1 0 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 3 , and wOC is 2 ?
The row of an image  [ 1 4 1 ] has a filter [ 3 2 1 ] applied to it . What is the resulting value if they both align ?
Given a 70 by 70 image and 25 by 25 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
What is the value of theta times x plus theta_0 if x is ( 1 0 ), theta is ( 1 negative 1 ) , and theta_0 is 6 ?
Compute the loss from the datapoint ( negative 2 0 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Given the input 33 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 4 and the maximum magnitude of a point is 2 .
Neurons A and B take inputs 1 and 2 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 5 . What is the output ?
Given an image row [ 3 3 0 ] and filter [ 3 4 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Given a loss function , ( 0 * theta + 3 ) ^ 4 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 0 and eta be 0.05 .
A point p is classified by a classifier whose decision boundary is theta = ( 2 4 ) . How does it classify p , where p is ( 1 0 ) ?
A point 3 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be 2 .
A classifier has a decision boundary where theta is ( 2 3 ) . What value does it classify p , where p is ( 0 negative 3 ) ?
If there are 47 points on a 2D plane , 26 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
Using a filter [ 1 3 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 1 3 1 ] .
Given a loss function , ( 0 * theta + 3 ) ^ 4 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 3 and eta be 0.05 .
Compute the loss from the datapoint ( 1 negative 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 2 .
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 4 ) and p is ( 2 0 ) ?
What is the loss for the data point ( 2 negative 2 ) if we use NLL . Let theta be 2 and theta_0 be 1 . Also use natural log where the base is 2.71828 .
What is the result of applying the value 35 to the sigmoid function ? Let e be equal to 2.71828 .
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 0.5 , and x is [ 1 0 2 ] , what is s_3 ?
With lambda = 1 , the optimal theta is 2 . If the datapoints are [ ( 0 negative 2 ) , ( 1 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
What is the total number of outputs for a zero-padded max pooling layer that has 18 inputs , a stride of 1 , and a pooling filter size of 4 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 1 and the maximum magnitude of a point is 16 .
Given a function ( 2 * theta + negative 1 ) ^ 2 , calculate the value of the function after one gradient descent update if theta is 2 and eta is 0.05 .
Let a function f(theta) = ( 0 * theta + 3 ) ^ 4 . For theta = 2 and eta = 0.01 , calculate theta after one gradient descent step .
Given a loss function , ( negative 1 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 2 and eta be 0.05 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 4 , and wOC is 3 ?
If the decision boundary of a classifier is theta , where theta is equal to ( 2 3 ) , how does it classify point p , where p is equal to ( 0 negative 2 ) ?
Given a function ( 2 * theta + 3 ) ^ 2 , compute theta after one gradient descent step if theta is 1 and eta is 0.01 .
If the margin of the dataset with respect to a separator is 5 and the maximum magnitude of a point is 15 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Using theta = 2 and lda = 1 , calculate the mean squared error of the points  [ ( 2 2 )  and ( 1 4 ) ] .
If you let theta be 3 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( 1 * theta + 3 ) ^ 3 ?
What is the result of applying the value 8 to the sigmoid function ? Let e be equal to 2.71828 .
If q is 6 , what is its updated value after applying Q learning if a is 0.1 and t is 6 ?
If you let theta be 2 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 1 * theta + 3 ) ^ 3 ?
How does a classifier with decision boundary theta classify a point p if theta is ( 2 4 ) and p is ( 1 negative 2 ) ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 1 with an offset of 1 .
A point 4 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be 0 .
An image I has length 50 and filter F has length 5 , what is the length of the result of applying F to I ?
Determine how many pixels of padding we need on the input of size 70 by 70 to ensure our filter 29 by 29 gives an output of the same size .
A point 0 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be 2 .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 1 with weight wOC being 2 . What is the output of neuron C ?
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 3 0 ) ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 14 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , what is the output y_4 after the inputs [ 7 3 6 19 ] ?
Let q = 8 . After Q learning, what is q if a is 0.1 and t is 8 ?
Given a loss function , ( 1 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 3 and eta be 0.05 .
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 1 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 and applies an ReLU on its output . Compute the output .
Using a filter [ 4 1 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 3 3 0 ] .
Assume e is equal to 2.71828 . What do you get from passing the value negative 30 into the sigmoid function ?
A neural network has inputs x1 = 1 with weight 1 and x2 = 1 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 . Compute the output .
Given the largest magnitude of a point as 20 and the margin of the dataset be 5 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Consider the classifier [ 0 1 1 ] and [ 4 4 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 3 . Neuron B has input 3 and offset 1 . Neuron A has input 1 and offset 1 with offset 0.5 .
Do the two classifiers [ 2 1 1 ] and [ 2 2 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 0 ) and p is ( 3 negative 3 ) ?
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 4 . Neuron A takes in value x1 = 1 with weight w1 = 1 and offset value oA = 0.5 . Neuron B takes in input x2 = 2 with an offset of 1 .
What is the magnitude of the vector [ 3 0 1 ] ?
If q is 9 , what is its updated value after applying Q learning if a is 0.2 and t is 2 ?
A point 0 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be negative 1 .
A left region has 4 points classified as positive. There are 46 points in the plane , and 23 points on the left . Compute the entropy .
Let q = 2 . After Q learning, what is q if a is 0.1 and t is 6 ?
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 3 with weight wOC being 2 . What is the output ?
Find the Euclidian length of [ 1 2 ] .
What is f(theta) if f(theta) is theta times 5 plus 8 squared and theta is 2 ?
What is the result of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 6 ?
Compute the mean squared error with the data points  [ ( 2 2 )  and ( 1 4 ) ] , theta = 3 , and lda = 1 .
Given the largest magnitude of a point as 13 and the margin of the dataset be 2 from the separator , compute the most number of mistakes made by the perceptron algotithm .
If an image has length 50 and filter has length 27 , compute the length of the output from applying the filter to the image ?
f(theta) is the square of the sum of 3 and the product of 2 and theta , where theta is 2 . What is f(theta) ?
x is ( 1 0 ) , theta is ( negative 2 1 ) and theta_0 is negative 1 . What is the value of theta times x plus theta_0?
How does a classifier with decision boundary theta classify a point p if theta is ( 1 3 ) and p is ( 1 negative 4 ) ?
Given a loss function , ( 1 * theta + 3 ) ^ 2 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 3 and eta be 0.05 .
If f(theta) is 5 times theta plus 8 squared and theta is 2 what is f(theta) ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 3 and the maximum magnitude of a point is 18 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 4 , and wOC is 2 ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 10 inputs and 30 outputs ?
What is the most number of mistakes made by the perceptron algorithm if 4 is the maximum magnitude of a point in the dataset and the dataset has a margin of 4 to the separator .
What is the loss for the data point ( 1 1 ) if we use NLL . Let theta be 2 and theta_0 be 0 . Also use natural log where the base is 2.71828 .
Given an image row [ 2 3 1 ] and filter [ 4 4 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Given theta be 3 and eta be 0.01 , calculate the value of the function ( 2 * theta + negative 2 ) ^ 4 after one step of gradient descent .
Do the two classifiers [ 3 1 1 ] and [ 3 1 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
What is the length of the output when we use an image of length 50 and a filter of length 5 if we use a stride length of 1 ?
Let theta be ( 1 negative 1 ) , theta_0 be 0.5, and x be ( 0 , 0 ) . Compute theta times x plus theta_0 .
Given a function ( 2 * theta + 1 ) ^ 4 , calculate the value of the function after one gradient descent update if theta is 2 and eta is 0.05 .
Given a loss function , ( 0 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 0 and eta be 0.05 .
Given a 90 by 90 image and 31 by 31 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Given the points  [ ( 2 2 )  and ( 2 3 ) ] , what is the mean squared error if theta is 3 and lda is 1 ?
Given the largest magnitude of a point as 13 and the margin of the dataset be 4 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Let q = 9 . After Q learning, what is q if a is 0.2 and t is 10 ?
Consider the input x_t = [ 11 6 19 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_3 if our initial conditions are s_0 is 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t .
Using a filter [ 3 0 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 2 3 0 ] .
Given the largest magnitude of a point as 11 and the margin of the dataset be 1 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Compute the loss from the datapoint ( 2 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 2 .
If q is 4 , what is its updated value after applying Q learning if a is 0.1 and t is 8 ?
What is the minimum number of padding needed to maintain the same output size if the input image is 70 by 70 and the filter is 33 by 33 ?
If f(theta) is 3 times theta plus 6 squared and theta is 1 what is f(theta) ?
Determine if the following two classifiers represent the same hyperplane , [ 3 1 1 ] and [ 4 2 1 ] . If so , return 1 , and return anything else otherwise .
The row of an image  [ 1 2 0 ] has a filter [ 3 4 1 ] applied to it . What is the resulting value if they both align ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1.5 , w = 0 , and x = [ 2 2 0 ] , what is s_3 ?
If the margin of the dataset with respect to a separator is 2 and the maximum magnitude of a point is 18 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Now consider a zero-padded max pooling layer with 18 inputs , a pooling filter size of 4 and stride of 2 . How many total output units are there for this layer?
If filter F has length 19 and an image I has length 70 , what is the length of the result from applying F to I ?
Calculate the value of y in the dataset [ ( 0 2 ) , ( 1 1 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 0.5 .
Consider the input x_t = [ 14 18 10 11 19 3 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_6 if our initial conditions are s_0 is 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t .
What is the NLL loss for the single data point ( 1 negative 2 ) where theta is 2 and theta_0 is 2 ? Let the log be natural log ( base is 2.71828 ) .
Compute the value returned from aligning the filter  [ 1 4 0 ] to the image  [ 1 4 0 ] on top of one another .
Using the row of an image  [ 1 1 1 ] and a filter [ 4 4 0 ] , calculate the value of applying the filter on top of the image .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 4 and the maximum magnitude of a point is 11 .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 negative 2 ) , ( 1 0 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Consider the classifier [ 1 2 0 ] and [ 0 1 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Given an image row [ 1 1 0 ] and filter [ 0 4 1 ] , what is the result from applying the filter to the image row such that they both align ?
With lambda = 1 , the optimal theta is 2 . If the datapoints are [ ( 0 negative 1 ) , ( 1 0 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Given 45 points on a plane , 26 of them are on the right side of a line , and 1 of them that are on the left side are positive . Compute the entropy of the left side .
Given a loss function , ( negative 2 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 3 and eta be 0.05 .
What is the magnitude of the vector [ 3 1 ] ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 50 inputs and 180 outputs ?
How does a classifier with decision boundary theta classify a point p if theta is ( 1 3 ) and p is ( 0 0 ) ?
Now consider a zero-padded max pooling layer with 12 inputs , a pooling filter size of 2 and stride of 2 . How many total output units are there for this layer?
Calculate the value of y in the dataset [ ( 0 negative 2 ) , ( 1 2 ) , ( 2 y ) ] if we know that the optimal theta 1 used mean squared error . Let lambda be 1 .
Given two classifiers [ 1 1 0 ] and [ 4 2 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Given the input negative 46 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Given a 70 by 70 image and 7 by 7 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Neurons A and B take inputs 1 and 4 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 2 . What is the output ?
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 50 inputs and 180 outputs .
Calculate the value of the function ( 2 * theta + 2 ) ^ 3 after updating the theta value in one step of gradient descent . Have theta be 3 and eta be 0.05 .
What is the value of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 18 ?
What is the size of the margin of a point 3 by a classifier with theta negative 1 and theta_0 negative 2 if the point has label negative 1 ?
Calculate the value of y in the dataset [ ( 0 negative 2 ) , ( 1 negative 2 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 0.5 .
After applying Q learning to q = 2 , what is its value ? Let the t be 2 and a be 0.2 .
x is ( negative 1 0 ) , theta is ( negative 2 1 ) and theta_0 is 0.5 . What is the value of theta times x plus theta_0?
What is the entropy of the left side of a region containing 27 points where the plane has 44 points in total and 2 points on the left are positive ?
Let theta be ( negative 2 1 ) , theta_0 be 6, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .
Let a function f(theta) = ( 2 * theta + 2 ) ^ 2 . For theta = 3 and eta = 0.01 , calculate f(theta) after one gradient descent update .
What is the total number of outputs for a zero-padded max pooling layer that has 22 inputs , a stride of 2 , and a pooling filter size of 4 ?
What is the minimum number of padding needed to maintain the same output size if the input image is 70 by 70 and the filter is 15 by 15 ?
Given a loss function , ( negative 2 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 2 and eta be 0.05 .
Consider a filter [ 4 1 0 ] applied on an image [ 0 3 1 ] . What is the output if the filter has a ReLU activation ?
If we have an image of size 80 by 80 and a filter of size 7 by 7 , how far out on each side should we pad to maintain the same output dimensions ?
Compute the output of the sigmoid function when we pass in negative 40 . Let e be equal to 2.71828 .
Determine how many pixels of padding we need on the input of size 80 by 80 to ensure our filter 33 by 33 gives an output of the same size .
Calculate the value of the function ( 2 * theta + negative 1 ) ^ 3 after updating the theta value in one step of gradient descent . Have theta be 4 and eta be 0.05 .
Given a 1D image I that is length 50 and a filter F that is length 25 , what is the length of the result from applying F to I ?
Neurons A and B take inputs 1 and 0 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 3 . What is the output ?
If a is 0.2 and t is 2 , what is the Q learning value after applying one tuple ( s a ) if q is 9 ?
Using the row of an image  [ 1 0 0 ] and a filter [ 0 0 1 ] , calculate the value of applying the filter on top of the image .
Given a 80 by 80 image and 11 by 11 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Given a loss function , ( 2 * theta + 3 ) ^ 2 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 1 and eta be 0.01 .
What is the size of the margin of a point 3 by a classifier with theta negative 1 and theta_0 1 if the point has label 1 ?
What is the loss for the data point ( 1 negative 1 ) if we use NLL . Let theta be 2 and theta_0 be 1 . Also use natural log where the base is 2.71828 .
An image I has length 80 and filter F has length 33 , what is the length of the result of applying F to I ?
What is the value of theta times x plus theta_0 if x is ( 1 0 ), theta is ( negative 2 1 ) , and theta_0 is 6 ?
If you are given two classifiers [ 1 3 0 ] and [ 4 1 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
If we have an image of size 80 by 80 and a filter of size 15 by 15 , how far out on each side should we pad to maintain the same output dimensions ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 3 , w is 1.5 , and x is [ 0.25 0.5 ] , what is s_2 ?
Using a row of an image [ 4 3 1 ] and filter [ 0 4 0 ] , calculate the value from applying the filter which has a ReLU on its output .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 3 , and wOC is 2 ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 2 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , compute y_6 if the input is x_t = [ 8 0 16 3 7 7 ] .
Given the points  [ ( 2 negative 1 )  and ( 1 4 ) ] , what is the mean squared error if theta is 1 and lda is 0.5 ?
Compute the output length given the stride 1 , image length 51 , and filter length 7 .
Consider the classifier [ 2 1 1 ] and [ 0 1 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Neurons A and B take inputs negative 1 and 2 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 3 . Neuron C also applies a ReLU on its output . What is the output ?
f(theta) is defined as 6 times theta plus 5 squared and theta is 2 . What is f(theta) ?
Using a filter [ 1 0 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 4 3 1 ] .
Neurons A and B take inputs negative 1 and 3 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 2 . Neuron C also applies a ReLU on its output . What is the output ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 2 , and wOC is 3 ?
Given the largest magnitude of a point as 5 and the margin of the dataset be 5 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 0 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 5 with weight wOC being 2 . What is the output of neuron C ?
Compute the magnitude of [ 3 4 1 ] .
If filter F has length 27 and an image I has length 90 , what is the length of the result from applying F to I ?
Determine how many pixels of padding we need on the input of size 60 by 60 to ensure our filter 41 by 41 gives an output of the same size .
What is the result of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is negative 3 ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 2 , w is 0.5 , and x is [ 0.25 0.5 ] , what is s_2 ?
Now consider a zero-padded max pooling layer with 22 inputs , a pooling filter size of 4 and stride of 1 . How many total output units are there for this layer?
If q is 8 , what is its updated value after applying Q learning if a is 0.1 and t is 10 ?
What is the output y_5 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 14 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , and input x_t = [ 5 4 2 15 1 ] ?
What is the magnitude of the vector [ 4 2 3 ] ?
What is the total number of outputs for a zero-padded max pooling layer that has 24 inputs , a stride of 1 , and a pooling filter size of 5 ?
The function ( 2 * theta + 0 ) ^ 2 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 3 and eta be 0.01 .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 20 inputs and 80 outputs ?
Given the points  [ ( 2 1 )  and ( 2 3 ) ] , what is the mean squared error if theta is 2 and lda is 1 ?
Given that there are 10 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 4 ?
Assume e is equal to 2.71828 . What do you get from passing the value 13 into the sigmoid function ?
Given the dataset [ ( 0 negative 2 ) , ( 1 negative 2 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 1 ?
What is f(theta) if f(theta) is theta times 4 plus 6 squared and theta is 1 ?
If we are given the classifiers [ 1 3 1 ] and [ 1 3 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What is the result of applying the value 10 to the sigmoid function ? Let e be equal to 2.71828 .
If f(theta) is 2 times theta plus 19 squared , what is f(theta) when theta is 2 ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 5 . Neuron B has input 1 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 1 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 3 and a ReLU on its output . Compute the output of this neural network .
A max pooling layer has 14 inputs, a pooling filter length of 2 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
Let s_0 be 2 , w be 0.5 , and x be [ 2 2 0 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
With lambda = 1 , the optimal theta is 1 . If the datapoints are [ ( 0 negative 1 ) , ( 1 0 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Compute the mean squared error with the data points  [ ( 2 negative 1 )  and ( 1 1 ) ] , theta = 0 , and lda = 1 .
A fully-connected neural network has 20 outputs and 40 inputs . How many total weights are there including the biases ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 2 , and wOC is 2 ?
What is the entropy of the left side of a region containing 23 points where the plane has 44 points in total and 4 points on the left are positive ?
With lambda = 0.5 , the optimal theta is 2 . If the datapoints are [ ( 0 0 ) , ( 1 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 3 , w is 0.1 , and x is [ 0.25 0.5 ] , what is s_2 ?
Given an image row [ 3 3 1 ] and filter [ 0 1 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 4 and applies an ReLU on its output . Compute the output .
What is the value of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 0.5 ?
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 1 ) , ( 1 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 5 and the maximum magnitude of a point is 8 .
What is the length of the result from applying F to I if F has length 21 and I has length 90?
A point p is classified by a classifier whose decision boundary is theta = ( 1 4 ) . How does it classify p , where p is ( 3 0 ) ?
Consider a plane of 45 points , 27 of which are on the left side . Of the points on the left , 4 points are positive . Find the entropy of the left side .
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 3 . Neuron B has input 3 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 2 . Neuron B has input 1 and offset 1 . Neuron A has input 1 and offset 1 with offset 0.5 .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 4 ) and p is ( 3 negative 1 ) ?
If we know the stride 2 of a max pooling layer , along with the filter length of 3 and input length of 20 , what is the number of outputs of this layer ?
What is the minimum number of padding needed to maintain the same output size if the input image is 70 by 70 and the filter is 39 by 39 ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 4 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 1 and applies an ReLU on its output . Compute the output .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 4 . Neuron B has input 0 and offset 1 . Neuron A has input 1 and offset 2 with offset 0.5 .
If the classifiers [ 1 1 1 ] and [ 3 1 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
If x = [ 5 1 1 ], what is || x || ?
Do the classifiers [ 1 2 0 ] and [ 1 0 1 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 4 ) , how does it classify point p , where p is equal to ( 3 negative 1 ) ?
Given the dataset [ ( 0 negative 1 ) , ( 1 1 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 2 is minimal . What does y need to be if lambda is 1 ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 1 ) , ( 1 negative 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1 , w = 1.5 , and x = [ 1 0 2 ] , what is s_3 ?
Compute the output of the sigmoid function when we pass in 9 . Let e be equal to 2.71828 .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 30 inputs and 180 outputs .
Given that there are 14 inputs to a zero-padded max pooling layer and a stride length of 1 , compute the number of output units if we also know the pooling filter size of 5 ?
Using a filter [ 0 2 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 0 3 0 ] .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 0 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 1 with weight wOC being 3 . What is the output ?
f(theta) is defined as 2 times theta plus 19 squared and theta is 1 . What is f(theta) ?
If a is 0.1 and t is 2 , what is the Q learning value after applying one tuple ( s a ) if q is 9 ?
What is the length of the result from applying F to I if F has length 17 and I has length 90?
Given a 1D image I that is length 60 and a filter F that is length 27 , what is the length of the result from applying F to I ?
If we have a neural network layer with 40 inputs and 10 outputs , how many weights ( including biases ) are needed to describe each connection ?
Let a function f(theta) = ( 2 * theta + 0 ) ^ 4 . For theta = 3 and eta = 0.01 , calculate f(theta) after one gradient descent update .
Find the Euclidean length of [ 2 6 1 ] .
If we have x equals ( 1 negative 1 ), theta equals ( 1 negative 1 ), and theta_0 equals 3 , then what is the result of theta times x plus theta_0 ?
Consider the input x_t = [ 5 14 13 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_3 if our initial conditions are s_0 is 14 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t .
How does a classifier with decision boundary theta classify a point p if theta is ( 1 4 ) and p is ( 1 negative 1 ) ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 1 , and wOC is 3 ?
Given an image row [ 4 3 1 ] and filter [ 1 0 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 24 points on the right side , and 44 points total .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 2 .
If there are 45 points on a 2D plane , 23 of them on the right side split by a line , and 1 points on the left side that are positive , what is the entropy of the left region ?
What is the length of the result from applying F to I if F has length 29 and I has length 80?
What is the output y_5 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 17 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , and input x_t = [ 4 17 12 18 9 ] ?
A fully-connected neural network has 40 outputs and 30 inputs . How many total weights are there including the biases ?
Do the two classifiers [ 0 1 1 ] and [ 4 1 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
A neural network has inputs x1 = 1 with weight 2 and x2 = 1 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 3 . Compute the output .
f(theta) is the square of the sum of 3 and the product of 9 and theta , where theta is 2 . What is f(theta) ?
What is the output y_5 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 12 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , and input x_t = [ 0 16 11 19 7 ] ?
Compute the mean squared error with the data points  [ ( 2 negative 1 )  and ( 1 4 ) ] , theta = 1 , and lda = 0.5 .
Determine how many pixels of padding we need on the input of size 70 by 70 to ensure our filter 15 by 15 gives an output of the same size .
Compute the value returned from aligning the filter  [ 1 0 0 ] to the image  [ 1 0 0 ] on top of one another .
Calculate the updated theta after one gradient descent step if theta is 4 , eta is 0.01 , and the loss function is ( negative 2 * theta + 3 ) ^ 3 .
What is f(theta) if f(theta) is theta times 10 plus 5 squared and theta is 1 ?
The function ( 2 * theta + negative 2 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 0 and eta be 0.01 .
If filter F has length 17 and an image I has length 60 , what is the length of the result from applying F to I ?
Compute the output of the sigmoid function when we pass in negative 6 . Let e be equal to 2.71828 .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 3 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 2 and a ReLU on its output . Compute the output of this neural network .
Let s_0 be 2 , w be 0.5 , and x be [ 1 0 2 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 27 points on the right side , and 44 points total .
Given a 70 by 70 image and 35 by 35 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
What is the NLL loss for the single data point ( negative 1 negative 1 ) where theta is 2 and theta_0 is 1 ? Let the log be natural log ( base is 2.71828 ) .
Let 3 be the margin of the dataset with respect to the separator . Also let 1 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_5 if we have s_0 being 4 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 2 * s_t , and we input [ 0 4 5 3 4 ] ?
If a is 0.2 and t is 4 , what is the Q learning value after applying one tuple ( s a ) if q is 1 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 4 and the maximum magnitude of a point is 20 .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 10 inputs and 200 outputs ?
Given an image row [ 1 0 0 ] and filter [ 3 4 1 ] , what is the result from applying the filter to the image row such that they both align ?
Now consider a zero-padded max pooling layer with 26 inputs , a pooling filter size of 3 and stride of 2 . How many total output units are there for this layer?
Let a function f(theta) = ( 2 * theta + 2 ) ^ 4 . For theta = 2 and eta = 0.01 , calculate f(theta) after one gradient descent update .
Using the row of an image  [ 1 1 0 ] and a filter [ 4 2 0 ] , calculate the value of applying the filter on top of the image .
What is the value of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 0.25 ?
Given a function ( 2 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 1 and eta is 0.05 .
What is the updated Q value of a tuple ( s a ) if q is 8 , the a is 0.1 , and t is 8 ?
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 0.5 , and x is [ 2 2 0 ] , what is s_3 ?
What is the result of applying the value 15 to the sigmoid function ? Let e be equal to 2.71828 .
The function ( 2 * theta + 2 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.01 .
With lambda = 1 , the optimal theta is 2 . If the datapoints are [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Given two classifiers [ 2 1 1 ] and [ 2 2 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
A classifier has a decision boundary where theta is ( 2 4 ) . What value does it classify p , where p is ( 0 negative 3 ) ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 3 , w = 0.1 , and x = [ 1 0 2 ] , what is s_3 ?
Given a 1D image I that is length 50 and a filter F that is length 9 , what is the length of the result from applying F to I ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , what is the output y_3 after the inputs [ 10 10 1 ] ?
If we know the stride 1 of a max pooling layer , along with the filter length of 5 and input length of 12 , what is the number of outputs of this layer ?
Consider the classifier [ 0 1 0 ] and [ 2 2 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
If x = [ 6 0 ] , what is || x || ?
What is the RNN result s_2 if s_0 is 1 , w is 1 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
Given an image of length 54 and a filter of length 15 , compute the output from applying the filter if we have a stride length of 2 ?
If the decision boundary of a classifier is theta , where theta is equal to ( 1 4 ) , how does it classify point p , where p is equal to ( 0 negative 4 ) ?
Compute the mean squared error with the data points  [ ( 2 negative 1 )  and ( 1 1 ) ] , theta = 0 , and lda = 0.5 .
The left side of a region has 27 points . Of the 27 points , 4 are classified as positive . What is the entropy of the left region if there are 48 points in total ?
What is the size of the margin of a point 1 by a classifier with theta negative 1 and theta_0 1 if the point has label 1 ?
What is the length of the result from applying F to I if F has length 39 and I has length 80?
Consider the classifier [ 1 1 0 ] and [ 1 4 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 1 and the maximum magnitude of a point is 3 .
After applying Q learning to q = 1 , what is its value ? Let the t be 2 and a be 0.2 .
Given the largest magnitude of a point as 20 and the margin of the dataset be 3 from the separator , compute the most number of mistakes made by the perceptron algotithm .
What does the sigmoid function return when  you pass into it negative 30 ? Hint: have e be 2.71828 .
Let 3 be the margin of the dataset with respect to the separator . Also let 6 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
If we have x equals ( 1 0 ), theta equals ( negative 2 1 ), and theta_0 equals 3 , then what is the result of theta times x plus theta_0 ?
Given a function ( 2 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 4 and eta is 0.05 .
The left side of a region has 23 points . Of the 23 points , 2 are classified as positive . What is the entropy of the left region if there are 48 points in total ?
Consider a plane of 47 points , 23 of which are on the left side . Of the points on the left , 4 points are positive . Find the entropy of the left side .
Compute the output of the sigmoid function when we pass in 13 . Let e be equal to 2.71828 .
What is the result from applying a filter [ 3 0 1 ] to a row of an image [ 2 3 0 ] , where the filter has a ReLU activation on its output ?
What is the total number of outputs for a zero-padded max pooling layer that has 16 inputs , a stride of 2 , and a pooling filter size of 1 ?
Given the values for theta as 2 and theta_0 as 0 , compute the NLL loss on the data point ( negative 2 negative 2 ) . Use log base e of 2.71828 for the log .
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 1 ) , ( 1 negative 1 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
What is the value from applying a filter [ 4 0 0 ] directly on top of an image  [ 1 1 1 ] ?
If we are given the classifiers [ 1 2 0 ] and [ 4 3 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 0 ) and p is ( 0 0 ) ?
Do the classifiers [ 1 4 0 ] and [ 1 3 0 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
What is the length of the output when we use an image of length 54 and a filter of length 9 if we use a stride length of 2 ?
Using theta = 3 and lda = 1 , calculate the mean squared error of the points  [ ( 2 2 )  and ( 2 3 ) ] .
If we have an image of size 60 by 60 and a filter of size 29 by 29 , how far out on each side should we pad to maintain the same output dimensions ?
If we know the stride 2 of a max pooling layer , along with the filter length of 3 and input length of 24 , what is the number of outputs of this layer ?
If x = [ 5 4 ] , what is || x || ?
Given a function ( 2 * theta + 2 ) ^ 4 , calculate the value of the function after one gradient descent update if theta is 2 and eta is 0.01 .
Consider an image I of length 50 and filter F of length 11 . What is the length of the output if we have a stride length of 1 ?
Given a function ( negative 1 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 3 and eta is 0.05 .
Given a function ( negative 1 * theta + 3 ) ^ 2 , compute theta after one gradient descent step if theta is 1 and eta is 0.05 .
Do the two classifiers [ 4 1 1 ] and [ 2 1 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Determine if the following two classifiers represent the same hyperplane , [ 0 1 0 ] and [ 2 3 1 ] . If so , return 1 , and return anything else otherwise .
What is the result of applying the value negative 30 to the sigmoid function ? Let e be equal to 2.71828 .
Using theta = 2 and lda = 1 , calculate the mean squared error of the points  [ ( 2 negative 1 )  and ( 2 5 ) ] .
Given a loss function , ( 0 * theta + 3 ) ^ 2 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 3 and eta be 0.01 .
If we are given the classifiers [ 1 2 0 ] and [ 4 2 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
If a is 0.2 and t is 8 , what is the Q learning value after applying one tuple ( s a ) if q is 6 ?
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 6 ?
What is the total number of outputs for a zero-padded max pooling layer that has 28 inputs , a stride of 2 , and a pooling filter size of 3 ?
After applying Q learning to q = 2 , what is its value ? Let the t be 4 and a be 0.2 .
What is the updated Q value of a tuple ( s a ) if q is 6 , the a is 0.1 , and t is 2 ?
Consider the input x_t = [ 7 1 0 14 19 6 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_6 if our initial conditions are s_0 is 8 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t .
If f(theta) is 3 times theta plus 5 squared , what is f(theta) when theta is 1 ?
If x = [ 7 1 ] , what is || x || ?
Given two classifiers [ 3 1 0 ] and [ 4 2 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Given the points  [ ( 2 1 )  and ( 2 5 ) ] , what is the mean squared error if theta is 0 and lda is 0.5 ?
Compute the output of the sigmoid function when we pass in negative 29 . Let e be equal to 2.71828 .
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 1 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 2 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
x is ( 1 0 ) , theta is ( 1 negative 1 ) and theta_0 is 0.25 . What is the value of theta times x plus theta_0?
If we have an image of size 70 by 70 and a filter of size 29 by 29 , how far out on each side should we pad to maintain the same output dimensions ?
If an image has length 60 and filter has length 9 , compute the length of the output from applying the filter to the image ?
Consider a 1D classification line on a 2D plane . There is a total of 48 points, 23 of which are on the right and the rest on the left of the boundary . 3 points on the left are classified positive . What is the entropy of the left region ?
If we have a neural network layer with 50 inputs and 180 outputs , how many weights ( including biases ) are needed to describe each connection ?
A neural network has inputs x1 = negative 1 with weight 1 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 5 and applies an ReLU on its output . Compute the output .
Given theta = 0 and lda = 1 , compute the mean squared error with the data points [ ( 2 1 )  and ( 1 5 ) ] .
Given two classifiers [ 0 1 1 ] and [ 1 0 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
f(theta) is defined as 6 times theta plus 19 squared and theta is 2 . What is f(theta) ?
What is f(theta) if f(theta) is theta times 1 plus 6 squared and theta is 2 ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 2 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 2 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 3 and a ReLU on its output . Compute the output of this neural network .
Let an input vector be [ 1 3 3 ] . What is its magnitude ?
If you let theta be 2 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 1 * theta + 3 ) ^ 2 ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 4 . Neuron B has input 4 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
Consider the classifier [ 3 1 0 ] and [ 2 4 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Given a 1D image I that is length 70 and a filter F that is length 39 , what is the length of the result from applying F to I ?
If a is 0.2 and t is 2 , what is the Q learning value after applying one tuple ( s a ) if q is 3 ?
Given the points  [ ( 2 2 )  and ( 2 3 ) ] , what is the mean squared error if theta is 0 and lda is 1 ?
Consider the classifier [ 1 3 0 ] and [ 1 2 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Given a function ( 0 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 4 and eta is 0.01 .
f(theta) is the square of the sum of 8 and the product of 10 and theta , where theta is 1 . What is f(theta) ?
What is the updated Q value of a tuple ( s a ) if q is 8 , the a is 0.1 , and t is 10 ?
Given the points  [ ( 2 2 )  and ( 1 4 ) ] , what is the mean squared error if theta is 4 and lda is 0.5 ?
What is the margin on a point 4 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 2 ?
Consider an image I of length 54 and filter F of length 11 . What is the length of the output if we have a stride length of 1 ?
What is the most number of mistakes made by the perceptron algorithm if 11 is the maximum magnitude of a point in the dataset and the dataset has a margin of 2 to the separator .
What is f(theta) if f(theta) is theta times 3 plus 3 squared and theta is 1 ?
Find the Euclidean length of [ 4 2 3 ] .
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 0 ) , ( 1 0 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Given a function ( negative 1 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 2 and eta is 0.05 .
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 3 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 5 and offset weight wOC being 3 and applies a ReLU function. Find the output of the neural network .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_5 after the inputs [ 17 2 12 2 14 ] ?
Compute the loss from the datapoint ( 2 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 1 .
What is the value from applying a filter [ 1 1 1 ] directly on top of an image  [ 1 4 1 ] ?
Compute the magnitude of [ 7 2 3 ] .
Now consider a zero-padded max pooling layer with 14 inputs , a pooling filter size of 5 and stride of 1 . How many total output units are there for this layer?
Calculate the value of the function ( 2 * theta + 0 ) ^ 3 after updating the theta value in one step of gradient descent . Have theta be 0 and eta be 0.05 .
If x = [ 5 1 ] , what is || x || ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 180 outputs and 50 inputs .
Let a function f(theta) = ( 2 * theta + 2 ) ^ 4 . For theta = 0 and eta = 0.05 , calculate f(theta) after one gradient descent update .
What is the length of the result from applying F to I if F has length 25 and I has length 70?
Calculate the value of y in the dataset [ ( 0 2 ) , ( 1 2 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
Neurons A and B take inputs 1 and 3 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 2 . What is the output ?
Let a function f(theta) = ( negative 1 * theta + 3 ) ^ 2 . For theta = 4 and eta = 0.01 , calculate theta after one gradient descent step .
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
If a point 3 with label 1 was classified by a classifier with theta 1 and theta_0 1 , what is the margin of this point ?
Let a function f(theta) = ( 2 * theta + 3 ) ^ 4 . For theta = 0 and eta = 0.05 , calculate theta after one gradient descent step .
A fully-connected neural network has 170 outputs and 30 inputs . How many total weights are there including the biases ?
If an image has length 50 and filter has length 13 , compute the length of the output from applying the filter to the image ?
Consider the classifier [ 2 1 1 ] and [ 2 4 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Compute the mean squared error with the data points  [ ( 2 0 )  and ( 2 5 ) ] , theta = 4 , and lda = 1 .
What is the minimum number of padding needed to maintain the same output size if the input image is 80 by 80 and the filter is 5 by 5 ?
Given two classifiers [ 0 1 1 ] and [ 3 3 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Let a function f(theta) = ( 0 * theta + 3 ) ^ 2 . For theta = 3 and eta = 0.01 , calculate theta after one gradient descent step .
If x = [ 0 4 1 ], what is || x || ?
A neural network has inputs x1 = negative 1 with weight 2 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 2 , respectively . Neuron C has offset value oC = 5 and applies an ReLU on its output . Compute the output .
Given a loss function , ( negative 2 * theta + 3 ) ^ 3 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 4 and eta be 0.01 .
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 2 . Neuron B has input 1 and offset 1 . Neuron A has input negative 1 and offset 2 with offset 0.5 .
The function ( 2 * theta + negative 1 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 4 and eta be 0.05 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 2 , and wOC is 2 ?
What does the sigmoid function return when  you pass into it 42 ? Hint: have e be 2.71828 .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 3 with weight wOC being 2 . What is the output ?
Now consider a zero-padded max pooling layer with 12 inputs , a pooling filter size of 4 and stride of 2 . How many total output units are there for this layer?
Given the input 17 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 2 . Neuron A takes in value x1 = 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 4 with an offset of 1 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 4 , and wOC is 2 ?
x is ( negative 1 0 ) , theta is ( 1 negative 1 ) and theta_0 is negative 3 . What is the value of theta times x plus theta_0?
Do the two classifiers [ 2 1 1 ] and [ 0 1 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Using a filter [ 4 3 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 4 3 0 ] .
There are 46 points on a 2D plane , 24 on the right side of a line and the rest on the left . 1 points on the left of the line are positive . What is the entropy of the left region ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 4 , and wOC is 2 ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 0 , w = 0.5 , and x = [ 2 2 0 ] , what is s_3 ?
What is the magnitude of the vector [ 6 1 3 ] ?
If f(theta) is 3 times theta plus 8 squared , what is f(theta) when theta is 1 ?
Find the Euclidian length of [ 0 0 ] .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 5 , and wOC is 2 ?
Given the largest magnitude of a point as 7 and the margin of the dataset be 4 from the separator , compute the most number of mistakes made by the perceptron algotithm .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 0 ) and p is ( 3 negative 4 ) ?
A point 1 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be 2 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 4 , and wOC is 3 ?
A fully-connected neural network has 160 outputs and 10 inputs . How many total weights are there including the biases ?
What is the length of the result from applying F to I if F has length 31 and I has length 80?
A fully-connected neural network has 80 outputs and 10 inputs . How many total weights are there including the biases ?
Consider the classifier [ 4 1 1 ] and [ 2 1 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 negative 2 ) , ( 1 0 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
What is the loss for the data point ( 2 2 ) if we use NLL . Let theta be 2 and theta_0 be 1 . Also use natural log where the base is 2.71828 .
If a is 0.2 and t is 6 , what is the Q learning value after applying one tuple ( s a ) if q is 4 ?
Now consider a zero-padded max pooling layer with 10 inputs , a pooling filter size of 2 and stride of 2 . How many total output units are there for this layer?
Using a stride length of 2 , what is the output from applying a filter of length 9 to an image of length 52 ?
A max pooling layer has 20 inputs, a pooling filter length of 2 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 1 with an offset of 1 .
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
Compute the value returned from aligning the filter  [ 1 2 0 ] to the image  [ 1 2 0 ] on top of one another .
The left side of a region has 24 points . Of the 24 points , 2 are classified as positive . What is the entropy of the left region if there are 44 points in total ?
What is f(theta) if f(theta) is theta times 8 plus 3 squared and theta is 1 ?
If a point 2 with label 1 was classified by a classifier with theta 1 and theta_0 negative 1 , what is the margin of this point ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 20 inputs and 60 outputs ?
Using a row of an image [ 2 3 1 ] and filter [ 3 2 0 ] , calculate the value from applying the filter which has a ReLU on its output .
If we have an image of size 50 by 50 and a filter of size 9 by 9 , how far out on each side should we pad to maintain the same output dimensions ?
Neuron A takes in value 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 3 . Compute the output of this neural network .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 23 points on the right side , and 48 points total .
Consider the classifier [ 1 0 0 ] and [ 0 4 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
What is the NLL loss for the single data point ( 0 2 ) where theta is 2 and theta_0 is 3 ? Let the log be natural log ( base is 2.71828 ) .
Compute the magnitude of [ 5 2 1 ] .
How much padding is needed on each side of a 70 by 70 input using a 21 by 21 filter to get an output the same size as the input ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 4 and the maximum magnitude of a point is 18 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 4 , and wOC is 2 ?
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 4 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 2 with an offset of 1 .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 40 inputs and 130 outputs .
Assume e is equal to 2.71828 . What do you get from passing the value 20 into the sigmoid function ?
Using a stride length of 2 , what is the output from applying a filter of length 21 to an image of length 51 ?
Determine how many pixels of padding we need on the input of size 50 by 50 to ensure our filter 5 by 5 gives an output of the same size .
Given the input negative 19 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Calculate the updated theta after one gradient descent step if theta is 2 , eta is 0.05 , and the loss function is ( negative 2 * theta + 3 ) ^ 3 .
What is the updated Q value of a tuple ( s a ) if q is 9 , the a is 0.2 , and t is 6 ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 3 ) and p is ( 0 negative 2 ) ?
What is f(theta) if f(theta) is theta times 9 plus 3 squared and theta is 1 ?
Let a function f(theta) = ( 2 * theta + 3 ) ^ 3 . For theta = 3 and eta = 0.01 , calculate theta after one gradient descent step .
If the margin of the dataset with respect to a separator is 2 and the maximum magnitude of a point is 5 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
What is the value from applying a filter [ 3 3 1 ] directly on top of an image  [ 1 1 0 ] ?
What is the loss for the data point ( 0 0 ) if we use NLL . Let theta be 2 and theta_0 be 1 . Also use natural log where the base is 2.71828 .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 12 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_6 after the inputs [ 18 12 18 5 17 15 ] ?
What does the sigmoid function return when  you pass into it 49 ? Hint: have e be 2.71828 .
What is the total number of outputs for a zero-padded max pooling layer that has 18 inputs , a stride of 2 , and a pooling filter size of 4 ?
An image I has length 60 and filter F has length 21 , what is the length of the result of applying F to I ?
Do the classifiers [ 1 1 0 ] and [ 0 3 1 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . What is the output of neuron C if x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 4 , and wOC is 2 ?
Given an image of length 53 and a filter of length 17 , compute the output from applying the filter if we have a stride length of 1 ?
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 1 . Neuron B has input 3 and offset 1 . Neuron A has input 1 and offset 2 with offset 0.5 .
Do the two classifiers [ 2 1 0 ] and [ 0 1 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Compute the value returned from aligning the filter  [ 1 4 1 ] to the image  [ 1 4 1 ] on top of one another .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 0 , w = 0.5 , and x = [ 0.25 0.5 ] , what is s_2 ?
Given the input 13 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Consider a plane of 45 points , 23 of which are on the left side . Of the points on the left , 2 points are positive . Find the entropy of the left side .
Given two classifiers [ 1 1 0 ] and [ 3 2 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Consider the classifier [ 4 1 0 ] and [ 4 1 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Using theta = 3 and lda = 1 , calculate the mean squared error of the points  [ ( 2 0 )  and ( 1 1 ) ] .
Let s_0 be 2 , w be 0.1 , and x be [ 1 0 2 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
What is the value from applying a filter [ 0 1 0 ] directly on top of an image  [ 1 1 0 ] ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 4 ) . How does it classify p , where p is ( 2 negative 1 ) ?
If there are 44 points on a 2D plane , 23 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
A point 0 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 2 .
A point 0 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 2 .
Given the input negative 12 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Given the dataset [ ( 0 0 ) , ( 1 1 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 1 is minimal . What does y need to be if lambda is 0.5 ?
Consider an image I of length 53 and filter F of length 7 . What is the length of the output if we have a stride length of 2 ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 0 ) , ( 1 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 5 , and wOC is 2 ?
If we know the stride 2 of a max pooling layer , along with the filter length of 2 and input length of 24 , what is the number of outputs of this layer ?
If you are given two classifiers [ 1 3 1 ] and [ 4 0 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Compute the output length given the stride 1 , image length 53 , and filter length 3 .
What is the output y_6 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 19 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , and input x_t = [ 5 13 4 10 6 19 ] ?
Consider the input x_t = [ 3 4 4 10 16 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_5 if our initial conditions are s_0 is 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t .
If we are given the classifiers [ 1 1 0 ] and [ 0 3 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What is the length of the output when we use an image of length 51 and a filter of length 5 if we use a stride length of 1 ?
Given the values for theta as 2 and theta_0 as 2 , compute the NLL loss on the data point ( 1 negative 1 ) . Use log base e of 2.71828 for the log .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 1 , and wOC is 2 ?
Given a function ( negative 2 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 2 and eta is 0.05 .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 1 points on the left side that are positive , 25 points on the right side , and 46 points total .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 negative 2 ) , ( 1 negative 1 ) , ( 2 y ) ] . If lambda is 1 , what is y ?
Given two classifiers [ 4 1 1 ] and [ 2 4 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
What is the margin on a point 0 with a label 1 if it is classified by a classifier with theta 1 and theta_0 2 ?
Given a loss function , ( 1 * theta + 3 ) ^ 4 , for gradient descent , compute the updated theta value after one gradient descent step . Let theta be 2 and eta be 0.05 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 1 , and wOC is 2 ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 6 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , compute y_5 if the input is x_t = [ 5 8 13 5 14 ] .
A max pooling layer has 10 inputs, a pooling filter length of 3 , a stride length of 2 , and is zero-padded . Compute the number of output units for this layer .
Consider the point ( 1 negative 2 ) , the theta 2 and the theta_0 0 . What is the NLL loss ? Use natural log , where the base is 2.71828 .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 4 ) and p is ( 1 negative 1 ) ?
Consider the classifier [ 1 1 1 ] and [ 1 0 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Given the input negative 42 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
A point 1 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be negative 1 and the theta_0 of the classifier be negative 1 .
Let theta be ( 1 negative 1 ) , theta_0 be 6, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .
If filter F has length 37 and an image I has length 50 , what is the length of the result from applying F to I ?
What is the length of the result from applying F to I if F has length 3 and I has length 60?
What is the length of the output when we use an image of length 53 and a filter of length 3 if we use a stride length of 2 ?
Determine how many pixels of padding we need on the input of size 70 by 70 to ensure our filter 41 by 41 gives an output of the same size .
If x = [ 6 3 ] , what is || x || ?
A max pooling layer has 12 inputs, a pooling filter length of 2 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
Let q = 0 . After Q learning, what is q if a is 0.1 and t is 10 ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , compute y_6 if the input is x_t = [ 16 15 3 13 18 11 ] .
What is the RNN result s_3 if s_0 is 2 , w is 0.5 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
Neuron A takes in value 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 4 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 3 . Compute the output of this neural network .
What is the result from applying a filter [ 2 1 0 ] to a row of an image [ 1 3 0 ] , where the filter has a ReLU activation on its output ?
Consider the classifier [ 1 0 1 ] and [ 2 3 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Do the two classifiers [ 1 1 0 ] and [ 4 4 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Compute the value returned from aligning the filter  [ 1 0 0 ] to the image  [ 1 0 0 ] on top of one another .
If you are given two classifiers [ 1 0 0 ] and [ 1 0 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
If we know the stride 1 of a max pooling layer , along with the filter length of 1 and input length of 10 , what is the number of outputs of this layer ?
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 0 .
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 3 , w is 0.1 , and x is [ 2 2 0 ] ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 3 negative 2 ) ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_3 if we have s_0 being 5 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 0 * s_t , and we input [ 5 14 5 ] ?
With lambda = 1 , the optimal theta is 2 . If the datapoints are [ ( 0 negative 1 ) , ( 1 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
What is the length of the output when we use an image of length 52 and a filter of length 5 if we use a stride length of 2 ?
Compute the loss from the datapoint ( negative 1 0 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 1 .
Consider a plane of 46 points , 26 of which are on the left side . Of the points on the left , 2 points are positive . Find the entropy of the left side .
A max pooling layer has 18 inputs, a pooling filter length of 4 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
The function ( 2 * theta + 0 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 0 and eta be 0.01 .
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 3 . Neuron A takes in value x1 = 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 1 with an offset of 1 .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 4 and a ReLU on its output . Compute the output of this neural network .
What is the margin of a classifier with theta being 1 and theta_0 being negative 1 on a point 4 with label negative 1 ?
What is the RNN result s_3 if s_0 is 1 , w is 0.1 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
Let an input vector be [ 0 4 ] . What is its magnitude ?
What is the length of the output when we use an image of length 54 and a filter of length 19 if we use a stride length of 2 ?
Using the row of an image  [ 1 1 0 ] and a filter [ 1 3 0 ] , calculate the value of applying the filter on top of the image .
A neural network has an input neuron A and output neuron C . Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 1 , and an input x1 being 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 2 . Find the output of the neural network .
What is the entropy of the left side of a region containing 25 points where the plane has 47 points in total and 4 points on the left are positive ?
There are 47 points on a 2D plane , 23 on the right side of a line and the rest on the left . 1 points on the left of the line are positive . What is the entropy of the left region ?
Let s_0 be 1.5 , w be 0 , and x be [ 0.25 0.5 ] . Compute s_2 if s_t is w * s_t-1 + x_t .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
If filter F has length 13 and an image I has length 90 , what is the length of the result from applying F to I ?
Consider a plane of 45 points , 26 of which are on the left side . Of the points on the left , 4 points are positive . Find the entropy of the left side .
What is the margin of a classifier with theta being negative 1 and theta_0 being 2 on a point 1 with label 1 ?
What is the result of applying the value negative 3 to the sigmoid function ? Let e be equal to 2.71828 .
Determine how many pixels of padding we need on the input of size 80 by 80 to ensure our filter 23 by 23 gives an output of the same size .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 1 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 3 with weight wOC being 2 . What is the output ?
If the decision boundary of a classifier is theta , where theta is equal to ( 2 3 ) , how does it classify point p , where p is equal to ( 2 negative 1 ) ?
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 3 with weight wOC being 2 . What is the output of neuron C ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 0 0 ) ?
If we let theta be 3 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 2 )  and ( 1 3 ) ] ?
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 9 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , compute y_6 if the input is x_t = [ 11 5 13 9 14 8 ] .
If we know the stride 1 of a max pooling layer , along with the filter length of 2 and input length of 16 , what is the number of outputs of this layer ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 4 ) and p is ( 1 negative 1 ) ?
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 1 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .
If filter F has length 15 and an image I has length 70 , what is the length of the result from applying F to I ?
Let theta be ( 1 negative 1 ) , theta_0 be 0.5, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .
If f(theta) is 4 times theta plus 6 squared and theta is 2 what is f(theta) ?
Do the classifiers [ 1 4 0 ] and [ 1 3 1 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
Calculate the entropy of the left region of a 2D plane, split by a line . There are 3 points on the left side that are positive , 27 points on the right side , and 45 points total .
Given a function ( negative 2 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 1 and eta is 0.01 .
Let an input vector be [ 0 1 1 ] . What is its magnitude ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 1 and the maximum magnitude of a point is 19 .
Consider the classifier [ 1 4 0 ] and [ 3 0 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 5 with weight wOC being 2 . What is the output ?
Given an image row [ 1 1 1 ] and filter [ 0 1 0 ] , what is the result from applying the filter to the image row such that they both align ?
Determine if the following two classifiers represent the same hyperplane , [ 1 1 0 ] and [ 2 4 0 ] . If so , return 1 , and return anything else otherwise .
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 0 , and x is [ 2 2 0 ] , what is s_3 ?
If f(theta) is 8 times theta plus 8 squared , what is f(theta) when theta is 2 ?
Given a 90 by 90 image and 13 by 13 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
A max pooling layer has 26 inputs, a pooling filter length of 4 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
If x = [ 5 2 ] , what is || x || ?
Calculate the value of the function ( 2 * theta + negative 2 ) ^ 2 after updating the theta value in one step of gradient descent . Have theta be 4 and eta be 0.05 .
How much padding is needed on each side of a 70 by 70 input using a 25 by 25 filter to get an output the same size as the input ?
Calculate the value of y in the dataset [ ( 0 1 ) , ( 1 2 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 1 .
Consider the classifier [ 1 3 1 ] and [ 1 3 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 10 inputs and 90 outputs ?
Calculate the value of the function ( 2 * theta + 1 ) ^ 4 after updating the theta value in one step of gradient descent . Have theta be 4 and eta be 0.01 .
If we have x equals ( negative 1 0 ), theta equals ( 1 negative 1 ), and theta_0 equals 18 , then what is the result of theta times x plus theta_0 ?
Given two classifiers [ 3 1 0 ] and [ 2 1 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Let theta be ( 1 negative 1 ) , theta_0 be 18, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .
A neural network has an input neuron A and output neuron C . Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 1 , and an input x1 being 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 3 and offset weight wOC being 2 . Find the output of the neural network .
Given a function ( negative 2 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 2 and eta is 0.05 .
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 50 inputs and 150 outputs .
Compute the magnitude of [ 0 7 3 ] .
The optimal theta value computed by mean squared error is 2 using the datapoints [ ( 0 negative 2 ) , ( 1 1 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Given theta be 1 and eta be 0.01 , calculate the value of the function ( 2 * theta + 2 ) ^ 3 after one step of gradient descent .
The function ( 2 * theta + 2 ) ^ 2 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 3 and eta be 0.01 .
Consider the input x_t = [ 12 9 4 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_3 if our initial conditions are s_0 is 0 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t .
The optimal theta value computed by mean squared error is 1 using the datapoints [ ( 0 1 ) , ( 1 1 ) , ( 2 y ) ] . If lambda is 0.5 , what is y ?
Let an input vector be [ 6 3 1 ] . What is its magnitude ?
If filter F has length 19 and an image I has length 80 , what is the length of the result from applying F to I ?
If we have an image of size 80 by 80 and a filter of size 35 by 35 , how far out on each side should we pad to maintain the same output dimensions ?
Using a filter [ 0 3 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 2 3 0 ] .
Consider the classifier [ 1 4 1 ] and [ 2 4 0 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
What is f(theta) if f(theta) is theta times 6 plus 5 squared and theta is 2 ?
Given two classifiers [ 2 1 1 ] and [ 2 1 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 5 . Neuron B has input 0 and offset 1 . Neuron A has input 1 and offset 1 with offset 0.5 .
Compute the output length given the stride 1 , image length 52 , and filter length 19 .
A max pooling layer has 12 inputs, a pooling filter length of 3 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
If we have x equals ( 0 negative 1 ), theta equals ( 1 negative 1 ), and theta_0 equals 0 , then what is the result of theta times x plus theta_0 ?
Given the points  [ ( 2 1 )  and ( 1 3 ) ] , what is the mean squared error if theta is 1 and lda is 1 ?
Compute the loss from the datapoint ( 2 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
Given an image row [ 1 0 0 ] and filter [ 1 2 1 ] , what is the result from applying the filter to the image row such that they both align ?
Given two classifiers [ 2 1 1 ] and [ 1 3 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Let theta be ( negative 2 1 ) , theta_0 be 6, and x be ( 0 , negative 1 ) . Compute theta times x plus theta_0 .
If f(theta) is 6 times theta plus 19 squared and theta is 1 what is f(theta) ?
What is the magnitude of the vector [ 5 0 ] ?
If the decision boundary of a classifier is theta , where theta is equal to ( 2 3 ) , how does it classify point p , where p is equal to ( 1 0 ) ?
Determine how many pixels of padding we need on the input of size 50 by 50 to ensure our filter 11 by 11 gives an output of the same size .
If a is 0.1 and t is 10 , what is the Q learning value after applying one tuple ( s a ) if q is 0 ?
Consider the classifier [ 1 1 1 ] and [ 4 3 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Compute the loss from the datapoint ( 1 negative 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 3 .
What does the sigmoid function return when  you pass into it negative 8 ? Hint: have e be 2.71828 .
What is the output y_6 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 16 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , and input x_t = [ 9 6 16 5 12 14 ] ?
Given the values for theta as 2 and theta_0 as 2 , compute the NLL loss on the data point ( negative 2 0 ) . Use log base e of 2.71828 for the log .
Given the dataset [ ( 0 negative 1 ) , ( 1 2 ) , ( 2 y ) ] , we get that the mean squared error for a theta = 1 is minimal . What does y need to be if lambda is 0.5 ?
What is the entropy of the left side of a region containing 26 points where the plane has 46 points in total and 4 points on the left are positive ?
Calculate the updated theta after one gradient descent step if theta is 4 , eta is 0.01 , and the loss function is ( 0 * theta + 3 ) ^ 3 .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 1 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 2 and a ReLU on its output . Compute the output of this neural network .
Let theta be ( negative 2 1 ) , theta_0 be 18, and x be ( 1 , 0 ) . Compute theta times x plus theta_0 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 2 , and wOC is 3 ?
If an image has length 70 and filter has length 25 , compute the length of the output from applying the filter to the image ?
Consider the classifier [ 0 1 0 ] and [ 2 4 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
Given the values for theta as 2 and theta_0 as 2 , compute the NLL loss on the data point ( negative 2 1 ) . Use log base e of 2.71828 for the log .
If q is 0 , what is its updated value after applying Q learning if a is 0.1 and t is 6 ?
Consider a 1D classification line on a 2D plane . There is a total of 47 points, 26 of which are on the right and the rest on the left of the boundary . 1 points on the left are classified positive . What is the entropy of the left region ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 30 inputs and 110 outputs ?
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 5 with weight wOC being 3 . What is the output ?
Given the values for theta as 2 and theta_0 as 1 , compute the NLL loss on the data point ( negative 1 0 ) . Use log base e of 2.71828 for the log .
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 3 , w is 1 , and x is [ 0.25 0.5 ] , what is s_2 ?
Using a filter [ 1 1 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 2 3 0 ] .
f(theta) is the square of the sum of 6 and the product of 10 and theta , where theta is 2 . What is f(theta) ?
If an image has length 80 and filter has length 13 , compute the length of the output from applying the filter to the image ?
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 2 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .
A point 0 has label 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 0 .
What is the entropy of the left side of a region containing 26 points where the plane has 48 points in total and 2 points on the left are positive ?
How much padding is needed on each side of a 60 by 60 input using a 39 by 39 filter to get an output the same size as the input ?
Compute the mean squared error with the data points  [ ( 2 2 )  and ( 2 4 ) ] , theta = 1 , and lda = 1 .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 1 and offset value oA being 0.5 and offset weight wOA being 2 .
x is ( 0 negative 1 ) , theta is ( 1 negative 1 ) and theta_0 is 18 . What is the value of theta times x plus theta_0?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 4 , and wOC is 2 ?
What is the NLL loss for the single data point ( negative 1 1 ) where theta is 2 and theta_0 is 0 ? Let the log be natural log ( base is 2.71828 ) .
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 4 .
A ReLU is applied to the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 2 and offset oC = 5 . Neuron A takes in value x1 = negative 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 0 with an offset of 1 .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 140 outputs and 50 inputs .
If we are given the classifiers [ 1 0 1 ] and [ 4 4 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
If x = [ 2 5 3 ], what is || x || ?
If a region has 27 points on the left and 45 points total . 4 points that are on the left are positive. Compute the entropy .
Let a function f(theta) = ( 2 * theta + 3 ) ^ 4 . For theta = 2 and eta = 0.05 , calculate theta after one gradient descent step .
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 1 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
What is the margin on a point 2 with a label 1 if it is classified by a classifier with theta 1 and theta_0 1 ?
Compute the loss from the datapoint ( negative 2 1 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 2 .
If you let theta be 1 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( 0 * theta + 3 ) ^ 4 ?
Consider the classifier [ 1 0 1 ] and [ 2 0 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
What is the margin of a classifier with theta being negative 1 and theta_0 being negative 1 on a point 1 with label 1 ?
Consider an image I of length 50 and filter F of length 9 . What is the length of the output if we have a stride length of 2 ?
Given the points  [ ( 2 0 )  and ( 2 2 ) ] , what is the mean squared error if theta is 0 and lda is 1 ?
Given the values for theta as 2 and theta_0 as 1 , compute the NLL loss on the data point ( negative 2 0 ) . Use log base e of 2.71828 for the log .
Using a stride length of 1 , what is the output from applying a filter of length 11 to an image of length 50 ?
After applying Q learning to q = 8 , what is its value ? Let the t be 10 and a be 0.2 .
What is the margin on a point 4 with a label negative 1 if it is classified by a classifier with theta 1 and theta_0 negative 2 ?
If you let theta be 3 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 1 * theta + 3 ) ^ 3 ?
What is the loss for the data point ( 2 1 ) if we use NLL . Let theta be 2 and theta_0 be 3 . Also use natural log where the base is 2.71828 .
If we have an image of size 80 by 80 and a filter of size 41 by 41 , how far out on each side should we pad to maintain the same output dimensions ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 3 , and wOC is 3 ?
Determine how many pixels of padding we need on the input of size 80 by 80 to ensure our filter 31 by 31 gives an output of the same size .
Given the values for theta as 2 and theta_0 as 2 , compute the NLL loss on the data point ( 0 1 ) . Use log base e of 2.71828 for the log .
The function ( 2 * theta + negative 1 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.01 .
A classifier has a decision boundary where theta is ( 2 4 ) . What value does it classify p , where p is ( 3 0 ) ?
If we let theta be 4 and lda be 1 , what is the mean squared error of the given points  [ ( 2 negative 1 )  and ( 2 1 ) ] ?
If f(theta) is 4 times theta plus 8 squared and theta is 2 what is f(theta) ?
Given the largest magnitude of a point as 5 and the margin of the dataset be 1 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 180 outputs and 30 inputs .
If we let theta be 1 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 2 )  and ( 1 2 ) ] ?
Compute the mean squared error with the data points  [ ( 2 negative 2 )  and ( 2 1 ) ] , theta = 4 , and lda = 0.5 .
What is the total number of outputs for a zero-padded max pooling layer that has 22 inputs , a stride of 2 , and a pooling filter size of 3 ?
Using a row of an image [ 3 3 1 ] and filter [ 0 3 0 ] , calculate the value from applying the filter which has a ReLU on its output .
A classifier has a decision boundary where theta is ( 2 3 ) . What value does it classify p , where p is ( 3 0 ) ?
Given theta be 4 and eta be 0.05 , calculate the value of the function ( 2 * theta + 2 ) ^ 4 after one step of gradient descent .
A neural network has inputs x1 = 1 with weight 2 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 5 . Compute the output .
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 1 ) , ( 1 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 4 , and wOC is 3 ?
What is the total number of outputs for a zero-padded max pooling layer that has 10 inputs , a stride of 1 , and a pooling filter size of 3 ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 120 outputs and 20 inputs .
Using a row of an image [ 1 3 0 ] and filter [ 2 4 0 ] , calculate the value from applying the filter which has a ReLU on its output .
Consider the input x_t = [ 0 18 8 7 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_4 if our initial conditions are s_0 is 0 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t .
Using a row of an image [ 1 3 1 ] and filter [ 0 0 1 ] , calculate the value from applying the filter which has a ReLU on its output .
Compute the magnitude of [ 6 0 ] .
A state machine is defined by the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Given the conditions s_0 = 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , compute y_3 if the input is x_t = [ 0 0 5 ] .
Let theta be ( negative 2 1 ) , theta_0 be 0.25, and x be ( 0 , 0 ) . Compute theta times x plus theta_0 .
What is the length of the result from applying F to I if F has length 17 and I has length 50?
Given the values for theta as 2 and theta_0 as 3 , compute the NLL loss on the data point ( negative 1 0 ) . Use log base e of 2.71828 for the log .
Determine how many pixels of padding we need on the input of size 50 by 50 to ensure our filter 15 by 15 gives an output of the same size .
After applying Q learning to q = 9 , what is its value ? Let the t be 6 and a be 0.2 .
Do the classifiers [ 1 2 0 ] and [ 0 1 0 ] represent the same classifier ? If so , return a 1 . If not, return anything but a 1 .
What is the size of the margin of a point 3 by a classifier with theta 1 and theta_0 0 if the point has label negative 1 ?
If the classifiers [ 0 1 1 ] and [ 3 4 0 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
A neural network has inputs x1 = 1 with weight 2 and x2 = 3 with weight 1 and offset value oA = 0.5 . Neuron B inputs x2 with offset 1 . Neuron C takes in the output of neurons A and B with offsets wAC = 1 and wBC = 3 , respectively . Neuron C has offset value oC = 4 . Compute the output .
After applying Q learning to q = 9 , what is its value ? Let the t be 2 and a be 0.2 .
Given a function ( negative 2 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 3 and eta is 0.05 .
If x = [ 4 3 ] , what is || x || ?
What is the minimum number of padding needed to maintain the same output size if the input image is 90 by 90 and the filter is 17 by 17 ?
f(theta) is defined as 7 times theta plus 19 squared and theta is 1 . What is f(theta) ?
Find the Euclidean length of [ 4 4 1 ] .
Given an image row [ 1 2 1 ] and filter [ 2 4 0 ] , what is the result from applying the filter to the image row such that they both align ?
Given theta = 3 and lda = 1 , compute the mean squared error with the data points [ ( 2 negative 1 )  and ( 1 3 ) ] .
Given two classifiers [ 2 1 0 ] and [ 4 0 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
With lambda = 1 , the optimal theta is 1 . If the datapoints are [ ( 0 1 ) , ( 1 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
If you let theta be 4 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 2 * theta + 3 ) ^ 3 ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 10 outputs and 30 inputs .
If a is 0.2 and t is 10 , what is the Q learning value after applying one tuple ( s a ) if q is 9 ?
If we are given the classifiers [ 1 0 0 ] and [ 1 2 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Compute the output of neuron C , which takes in outputs from neurons A with weight wAC = 1 and B with weight wBC = 3 and offset oC = 5 . Neuron A takes in value x1 = 1 with weight w1 = 2 and offset value oA = 0.5 . Neuron B takes in input x2 = 3 with an offset of 1 .
What is the updated Q value of a tuple ( s a ) if q is 5 , the a is 0.1 , and t is 6 ?
Compute the magnitude of [ 3 0 ] .
Consider a plane of 45 points , 26 of which are on the left side . Of the points on the left , 2 points are positive . Find the entropy of the left side .
What is the margin of a classifier with theta being negative 1 and theta_0 being 1 on a point 2 with label negative 1 ?
If we let theta be 4 and lda be 1 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 2 1 ) ] ?
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 2 . Neuron B has input 3 and offset 1 . Neuron A has input 1 and offset 2 with offset 0.5 .
Compute the output of the sigmoid function when we pass in negative 45 . Let e be equal to 2.71828 .
Given the largest magnitude of a point as 20 and the margin of the dataset be 1 from the separator , compute the most number of mistakes made by the perceptron algotithm .
A point 0 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be 0 .
What is the output y_6 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 0 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , and input x_t = [ 9 17 2 11 0 18 ] ?
Let an input vector be [ 4 3 ] . What is its magnitude ?
Assume e is equal to 2.71828 . What do you get from passing the value 4 into the sigmoid function ?
What is the result of applying the value negative 15 to the sigmoid function ? Let e be equal to 2.71828 .
Given a function ( 2 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 2 and eta is 0.01 .
If an image has length 90 and filter has length 33 , compute the length of the output from applying the filter to the image ?
Calculate the entropy of the left region of a 2D plane, split by a line . There are 1 points on the left side that are positive , 23 points on the right side , and 48 points total .
Compute the output of the sigmoid function when we pass in negative 28 . Let e be equal to 2.71828 .
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 1 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 0 .
Given a feedforward neural network layer , compute the total number of weights including biases if we have 10 outputs and 10 inputs .
Compute the loss from the datapoint ( 1 0 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 3 .
An image I has length 70 and filter F has length 13 , what is the length of the result of applying F to I ?
What is the margin on a point 4 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 1 ?
What is the loss for the data point ( 1 2 ) if we use NLL . Let theta be 2 and theta_0 be 0 . Also use natural log where the base is 2.71828 .
Neurons A and B take inputs negative 1 and 2 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 2 , respectively , and with offset 4 . Neuron C also applies a ReLU on its output . What is the output ?
What is the updated Q value of a tuple ( s a ) if q is 7 , the a is 0.1 , and t is 10 ?
If the classifiers [ 0 1 1 ] and [ 4 2 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
Given a 50 by 50 image and 5 by 5 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Neurons A and B take inputs 1 and 3 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 1 . What is the output ?
What is the total number of outputs for a zero-padded max pooling layer that has 18 inputs , a stride of 2 , and a pooling filter size of 3 ?
What does the sigmoid function return when  you pass into it negative 25 ? Hint: have e be 2.71828 .
Let 1 be the margin of the dataset with respect to the separator . Also let 3 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
What is the length of the output when we use an image of length 51 and a filter of length 3 if we use a stride length of 2 ?
The row of an image  [ 1 0 0 ] has a filter [ 1 2 1 ] applied to it . What is the resulting value if they both align ?
How does a classifier with decision boundary theta classify a point p if theta is ( 2 4 ) and p is ( 3 negative 2 ) ?
Given a function ( negative 2 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 0 and eta is 0.05 .
What is the RNN result s_2 if s_0 is 3 , w is 0.1 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
What is the RNN result s_3 if s_0 is 0 , w is 1.5 , and x is [ 0 3 1 ] if we let s_t = w * s_t-1 + x_t ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_6 if we have s_0 being 18 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 1 * s_t , and we input [ 16 15 14 3 10 8 ] ?
Given two classifiers [ 0 1 1 ] and [ 1 2 0 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
If you let theta be 0 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 2 * theta + 3 ) ^ 4 ?
If we know the stride 1 of a max pooling layer , along with the filter length of 1 and input length of 16 , what is the number of outputs of this layer ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 1 , and wOC is 2 ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 3 and the maximum magnitude of a point is 8 .
A fully-connected neural network has 120 outputs and 20 inputs . How many total weights are there including the biases ?
If a region has 23 points on the left and 46 points total . 2 points that are on the left are positive. Compute the entropy .
The function ( 2 * theta + negative 1 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 0 and eta be 0.05 .
Given an image row [ 1 3 0 ] and filter [ 1 2 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Consider the classifier [ 1 1 0 ] and [ 0 2 1 ] . Do they represent the same classifier ? Return 1 if true and another value if false .
What is the value from applying a filter [ 3 0 1 ] directly on top of an image  [ 1 0 1 ] ?
Let a function f(theta) = ( 1 * theta + 3 ) ^ 2 . For theta = 2 and eta = 0.05 , calculate theta after one gradient descent step .
A point 1 has label negative 1 . Compute the margin of a classifier on this point . Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 1 .
Given the largest magnitude of a point as 16 and the margin of the dataset be 5 from the separator , compute the most number of mistakes made by the perceptron algotithm .
Let a function f(theta) = ( 2 * theta + 3 ) ^ 3 . For theta = 4 and eta = 0.01 , calculate theta after one gradient descent step .
Let s_0 be 1 , w be 0 , and x be [ 0 3 1 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
Compute the output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 4 . Neuron B has input 3 and offset 1 . Neuron A has input 1 and offset 1 with offset 0.5 .
If we have a neural network layer with 10 inputs and 170 outputs , how many weights ( including biases ) are needed to describe each connection ?
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 30 inputs and 130 outputs .
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 4 , and an input x1 being negative 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
If we let theta be 0 and lda be 1 , what is the mean squared error of the given points  [ ( 2 2 )  and ( 2 3 ) ] ?
Given a function ( 2 * theta + 3 ) ^ 2 , compute theta after one gradient descent step if theta is 1 and eta is 0.05 .
What is the loss for the data point ( negative 2 1 ) if we use NLL . Let theta be 2 and theta_0 be 1 . Also use natural log where the base is 2.71828 .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 4 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t , what is the output y_5 after the inputs [ 7 0 8 18 6 ] ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1.5 , w = 0.1 , and x = [ 0.25 0.5 ] , what is s_2 ?
If a point 2 with label negative 1 was classified by a classifier with theta negative 1 and theta_0 1 , what is the margin of this point ?
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
What is the total number of outputs for a zero-padded max pooling layer that has 20 inputs , a stride of 1 , and a pooling filter size of 4 ?
What is the magnitude of the vector [ 5 3 3 ] ?
If a point 3 with label 1 was classified by a classifier with theta 1 and theta_0 negative 1 , what is the margin of this point ?
If we know the stride 2 of a max pooling layer , along with the filter length of 2 and input length of 14 , what is the number of outputs of this layer ?
Given an image of length 52 and a filter of length 17 , compute the output from applying the filter if we have a stride length of 1 ?
Given the input 21 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Neuron A takes in value negative 1 with weight 2 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 0 with weight 1 and offset 1 . Its output is passed into neuron C with weight 3. Neuron C has offset 5 and a ReLU on its output . Compute the output of this neural network .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 5 , and wOC is 2 ?
Determine how many pixels of padding we need on the input of size 50 by 50 to ensure our filter 19 by 19 gives an output of the same size .
Determine how many pixels of padding we need on the input of size 90 by 90 to ensure our filter 17 by 17 gives an output of the same size .
Now consider a zero-padded max pooling layer with 18 inputs , a pooling filter size of 2 and stride of 2 . How many total output units are there for this layer?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 30 outputs and 10 inputs .
Using a stride length of 2 , what is the output from applying a filter of length 7 to an image of length 51 ?
The function ( 2 * theta + negative 2 ) ^ 4 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 0 and eta be 0.05 .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 5 , and wOC is 3 ?
What is the size of the margin of a point 1 by a classifier with theta negative 1 and theta_0 1 if the point has label negative 1 ?
Compute the output length given the stride 2 , image length 51 , and filter length 17 .
What is the updated Q value of a tuple ( s a ) if q is 6 , the a is 0.2 , and t is 4 ?
Determine if the following two classifiers represent the same hyperplane , [ 3 1 0 ] and [ 2 4 0 ] . If so , return 1 , and return anything else otherwise .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 5 with weight wOC being 2 . What is the output of neuron C ?
If we have an image of size 80 by 80 and a filter of size 23 by 23 , how far out on each side should we pad to maintain the same output dimensions ?
If filter F has length 27 and an image I has length 60 , what is the length of the result from applying F to I ?
Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 1 , and an input x1 being negative 1 with weight w1 being 2 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 3 and offset weight wOC being 2 and applies a ReLU function. Find the output of the neural network .
Do the two classifiers [ 1 1 0 ] and [ 1 0 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
A fully-connected neural network has 30 outputs and 40 inputs . How many total weights are there including the biases ?
Determine if the following two classifiers represent the same hyperplane , [ 0 1 1 ] and [ 4 2 1 ] . If so , return 1 , and return anything else otherwise .
A point p is classified by a classifier whose decision boundary is theta = ( 2 0 ) . How does it classify p , where p is ( 3 negative 2 ) ?
If x = [ 1 3 ] , what is || x || ?
If an image has length 50 and filter has length 9 , compute the length of the output from applying the filter to the image ?
If we have an image of size 90 by 90 and a filter of size 13 by 13 , how far out on each side should we pad to maintain the same output dimensions ?
If you are given two classifiers [ 1 0 1 ] and [ 3 1 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 1 ) , ( 1 negative 2 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
Compute the output length given the stride 2 , image length 50 , and filter length 5 .
If an image has length 90 and filter has length 21 , compute the length of the output from applying the filter to the image ?
Given the classifiers [ 1 0 1 ] and [ 2 3 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Compute the magnitude of [ 4 2 3 ] .
What is the value from applying a filter [ 2 1 0 ] directly on top of an image  [ 1 2 1 ] ?
In a neural network where it is fully-connected and feedforward , how many total weights are there if we include the biases ? We have 20 inputs and 130 outputs .
Do the two classifiers [ 4 1 0 ] and [ 1 0 1 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Given the points  [ ( 2 negative 1 )  and ( 1 4 ) ] , what is the mean squared error if theta is 3 and lda is 0.5 ?
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 13 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 4 * s_t , what is the output y_4 after the inputs [ 8 5 10 14 ] ?
If a point 0 with label 1 was classified by a classifier with theta 1 and theta_0 negative 2 , what is the margin of this point ?
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 3 ) and p is ( 3 negative 4 ) ?
A fully-connected neural network has 20 outputs and 10 inputs . How many total weights are there including the biases ?
If a region has 25 points on the left and 46 points total . 4 points that are on the left are positive. Compute the entropy .
If we know the stride 1 of a max pooling layer , along with the filter length of 1 and input length of 12 , what is the number of outputs of this layer ?
Compute the magnitude of [ 6 1 ] .
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 0 , w = 1 , and x = [ 2 2 0 ] , what is s_3 ?
A classifier has a decision boundary where theta is ( 2 0 ) . What value does it classify p , where p is ( 2 negative 4 ) ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 5 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 1 .
f(theta) is the square of the sum of 3 and the product of 5 and theta , where theta is 1 . What is f(theta) ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 2 and offset 5 . Neuron B has input 2 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
If you let theta be 0 and eta be 0.01 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 1 * theta + 3 ) ^ 2 ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 110 outputs and 10 inputs .
Neuron A takes in value negative 1 with weight 1 and offset 0.5 . Its output is passed into neuron C with weight 1 . Neuron B takes in value 3 with weight 1 and offset 1 . Its output is passed into neuron C with weight 2. Neuron C has offset 3 and a ReLU on its output . Compute the output of this neural network .
Consider an image I of length 52 and filter F of length 17 . What is the length of the output if we have a stride length of 2 ?
Let q = 5 . After Q learning, what is q if a is 0.1 and t is 4 ?
The row of an image  [ 1 1 0 ] has a filter [ 4 2 0 ] applied to it . What is the resulting value if they both align ?
Using a stride length of 1 , what is the output from applying a filter of length 19 to an image of length 53 ?
What does the sigmoid function return when  you pass into it negative 21 ? Hint: have e be 2.71828 .
If we are given the classifiers [ 1 4 0 ] and [ 3 1 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Let theta be ( negative 2 1 ) , theta_0 be 0.5, and x be ( negative 1 , 0 ) . Compute theta times x plus theta_0 .
If we have a neural network layer with 50 inputs and 80 outputs , how many weights ( including biases ) are needed to describe each connection ?
f(theta) is defined as 8 times theta plus 6 squared and theta is 2 . What is f(theta) ?
Let a function f(theta) = ( 2 * theta + 2 ) ^ 4 . For theta = 2 and eta = 0.05 , calculate f(theta) after one gradient descent update .
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_3 if we have s_0 being 1 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 2 * s_t , and we input [ 17 3 8 ] ?
Given 47 points on a plane , 26 of them are on the right side of a line , and 1 of them that are on the left side are positive . Compute the entropy of the left side .
Consider the input x_t = [ 11 8 12 16 4 0 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_6 if our initial conditions are s_0 is 10 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t .
Given that there are 18 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 1 ?
Using a stride length of 2 , what is the output from applying a filter of length 21 to an image of length 53 ?
What is the length of the result from applying F to I if F has length 9 and I has length 90?
Compute the output length given the stride 1 , image length 50 , and filter length 15 .
x is ( 1 0 ) , theta is ( negative 2 1 ) and theta_0 is 0 . What is the value of theta times x plus theta_0?
Determine if the following two classifiers represent the same hyperplane , [ 2 1 1 ] and [ 2 2 1 ] . If so , return 1 , and return anything else otherwise .
After applying Q learning to q = 0 , what is its value ? Let the t be 8 and a be 0.2 .
If we let theta be 2 and lda be 1 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 2 3 ) ] ?
The row of an image  [ 1 1 1 ] has a filter [ 0 3 0 ] applied to it . What is the resulting value if they both align ?
Neuron A is the input neuron of a neural network . Neuron C is the output neuron of the same neural network and applies a ReLU function on its output . Neuron A takes in value x1 is negative 1 with weight w1 being 1 and offset value oA being 0.5 with weight wOA being 4 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 4 with weight wOC being 2 . What is the output ?
Compute the output of the sigmoid function when we pass in 36 . Let e be equal to 2.71828 .
What is the RNN result s_2 if s_0 is 1 , w is 0.1 , and x is [ 0.25 0.5 ] if we let s_t = w * s_t-1 + x_t ?
If we are given the classifiers [ 1 1 1 ] and [ 3 2 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
We define an RNN as s_t = w * s_t-1 + x_t . What is s_3 if s_0 is 1 , w is 0 , and x is [ 1 0 2 ] ?
Given a feedforward neural network layer , compute the total number of weights including biases if we have 130 outputs and 30 inputs .
Given the values for theta as 2 and theta_0 as 0 , compute the NLL loss on the data point ( 0 negative 2 ) . Use log base e of 2.71828 for the log .
Given a function ( 2 * theta + 1 ) ^ 2 , calculate the value of the function after one gradient descent update if theta is 1 and eta is 0.05 .
Let 4 be the margin of the dataset with respect to the separator . Also let 6 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
What is the result of theta times x plus theta_0 if x is ( negative 1 0 ), theta is ( negative 2 1 ) , and theta_0 is negative 3 ?
Let s_0 be 0 , w be 0 , and x be [ 0 3 1 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
What is the minimum number of padding needed to maintain the same output size if the input image is 80 by 80 and the filter is 13 by 13 ?
What is the minimum number of padding needed to maintain the same output size if the input image is 50 by 50 and the filter is 17 by 17 ?
The left side of a region has 25 points . Of the 25 points , 2 are classified as positive . What is the entropy of the left region if there are 45 points in total ?
Using a stride length of 2 , what is the output from applying a filter of length 3 to an image of length 53 ?
If the classifiers [ 1 1 0 ] and [ 2 1 1 ] both represent the same hyperplane , return 1 . Otherwise , return anything else .
If an image has length 70 and filter has length 37 , compute the length of the output from applying the filter to the image ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is 1 , w1 is 2 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 2 , and wOC is 2 ?
Let a function f(theta) = ( negative 1 * theta + 3 ) ^ 2 . For theta = 3 and eta = 0.05 , calculate theta after one gradient descent step .
What is the updated Q value of a tuple ( s a ) if q is 3 , the a is 0.1 , and t is 10 ?
Given an image row [ 3 3 0 ] and filter [ 3 3 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Given two classifiers [ 3 1 1 ] and [ 4 4 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Given the classifiers [ 1 0 1 ] and [ 0 2 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
What is the value of theta times x plus theta_0 if x is ( 0 0 ), theta is ( 1 negative 1 ) , and theta_0 is 0.5 ?
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 negative 2 ) , ( 1 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Consider an image I of length 51 and filter F of length 13 . What is the length of the output if we have a stride length of 2 ?
If we know the stride 1 of a max pooling layer , along with the filter length of 1 and input length of 28 , what is the number of outputs of this layer ?
A classifier has a decision boundary where theta is ( 1 4 ) . What value does it classify p , where p is ( 3 negative 2 ) ?
Using a filter [ 2 2 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 1 3 0 ] .
Let s_0 be 3 , w be 0.1 , and x be [ 0 3 1 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
A classifier has a decision boundary where theta is ( 1 3 ) . What value does it classify p , where p is ( 3 0 ) ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 2 with weight wOC being 3 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 0 .
What is the value of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 0.5 ?
Now consider a zero-padded max pooling layer with 16 inputs , a pooling filter size of 5 and stride of 1 . How many total output units are there for this layer?
A neural network has an input neuron A and output neuron C . Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 3 , and an input x1 being 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 1 and offset weight wOC being 2 . Find the output of the neural network .
Given that there are 24 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 4 ?
If x = [ 2 5 ] , what is || x || ?
If we know the stride 2 of a max pooling layer , along with the filter length of 2 and input length of 10 , what is the number of outputs of this layer ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 50 inputs and 20 outputs ?
Given the input 41 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Assume e is equal to 2.71828 . What do you get from passing the value 35 into the sigmoid function ?
Given two classifiers [ 1 1 0 ] and [ 0 0 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
If we let theta be 1 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 1 )  and ( 1 3 ) ] ?
Calculate the maximum number of possible mistakes made by the perceptron algorithm if the margin of the separator is 3 and the maximum magnitude of a point is 17 .
With lambda = 0.5 , the optimal theta is 2 . If the datapoints are [ ( 0 0 ) , ( 1 negative 1 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
If we let theta be 1 and lda be 1 , what is the mean squared error of the given points  [ ( 2 negative 1 )  and ( 1 1 ) ] ?
What is the length of the output when we use an image of length 50 and a filter of length 9 if we use a stride length of 1 ?
If we know the stride 1 of a max pooling layer , along with the filter length of 3 and input length of 10 , what is the number of outputs of this layer ?
What is the output y_4 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 19 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t , and input x_t = [ 11 0 2 7 ] ?
What is the margin on a point 3 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 0 ?
If a point 0 with label 1 was classified by a classifier with theta negative 1 and theta_0 0 , what is the margin of this point ?
If we are given the classifiers [ 1 2 0 ] and [ 4 3 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Compute the loss from the datapoint ( negative 2 2 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 0 .
What is the result of theta times x plus theta_0 if x is ( 0 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 0 ?
f(theta) is defined as 10 times theta plus 3 squared and theta is 2 . What is f(theta) ?
Given a 1D image I that is length 50 and a filter F that is length 3 , what is the length of the result from applying F to I ?
What is the value from applying a filter [ 1 3 0 ] directly on top of an image  [ 1 3 0 ] ?
What is the magnitude of the vector [ 5 2 1 ] ?
Given theta = 2 and lda = 0.5 , compute the mean squared error with the data points [ ( 2 1 )  and ( 1 1 ) ] .
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 2 ) , ( 1 2 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
Compute the output length given the stride 2 , image length 51 , and filter length 13 .
What is the margin of a classifier with theta being 1 and theta_0 being negative 1 on a point 1 with label negative 1 ?
If there are 44 points on a 2D plane , 24 of them on the right side split by a line , and 3 points on the left side that are positive , what is the entropy of the left region ?
Using a filter [ 2 2 0 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 4 3 0 ] .
If we are given the classifiers [ 1 0 0 ] and [ 0 4 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Given the input 16 , what is the output of the sigmoid function when we pass in the input ? Set e to be 2.71828 .
Using a row of an image [ 2 3 0 ] and filter [ 1 1 1 ] , calculate the value from applying the filter which has a ReLU on its output .
What is the magnitude of the vector [ 8 0 ] ?
If we let theta be 1 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 negative 2 )  and ( 2 5 ) ] ?
If a region has 27 points on the left and 47 points total . 4 points that are on the left are positive. Compute the entropy .
If we are given the classifiers [ 1 3 1 ] and [ 1 2 1 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
If we have an image of size 70 by 70 and a filter of size 11 by 11 , how far out on each side should we pad to maintain the same output dimensions ?
Consider the classifier [ 3 1 0 ] and [ 3 3 0 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
If we have an image of size 50 by 50 and a filter of size 39 by 39 , how far out on each side should we pad to maintain the same output dimensions ?
What is f(theta) if f(theta) is theta times 2 plus 6 squared and theta is 1 ?
Do the two classifiers [ 0 1 0 ] and [ 3 1 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
Calculate the updated theta after one gradient descent step if theta is 2 , eta is 0.05 , and the loss function is ( 2 * theta + 3 ) ^ 4 .
The function ( 2 * theta + 2 ) ^ 3 is the loss function when performing a gradient descent. Calculate the loss after one step of gradient descent. Let theta be 1 and eta be 0.05 .
If filter F has length 3 and an image I has length 60 , what is the length of the result from applying F to I ?
Compute the mean squared error with the data points  [ ( 2 negative 2 )  and ( 1 3 ) ] , theta = 1 , and lda = 1 .
If theta is the decision boundary for some classifier , how does the classifier classify a point p , where theta is ( 2 0 ) and p is ( 1 negative 2 ) ?
Assume e is equal to 2.71828 . What do you get from passing the value negative 31 into the sigmoid function ?
f(theta) is defined as 1 times theta plus 19 squared and theta is 2 . What is f(theta) ?
What is the loss for the data point ( 1 negative 2 ) if we use NLL . Let theta be 2 and theta_0 be 3 . Also use natural log where the base is 2.71828 .
Consider an image I of length 52 and filter F of length 15 . What is the length of the output if we have a stride length of 2 ?
What is the entropy of the left side of a region containing 26 points where the plane has 45 points in total and 2 points on the left are positive ?
Do the two classifiers [ 4 1 0 ] and [ 4 1 0 ] represent the same hyperplane ? Return 1 if true and anythin else otherwise .
The row of an image  [ 1 2 0 ] has a filter [ 1 0 0 ] applied to it . What is the resulting value if they both align ?
Consider a filter [ 4 0 1 ] applied on an image [ 2 3 1 ] . What is the output if the filter has a ReLU activation ?
Let q = 0 . After Q learning, what is q if a is 0.1 and t is 4 ?
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 4 , wAC is 1 , oC is 3 , and wOC is 2 ?
Calculate the updated theta after one gradient descent step if theta is 1 , eta is 0.01 , and the loss function is ( 2 * theta + 3 ) ^ 2 .
Given a 90 by 90 image and 15 by 15 filter , what is the minimum amount of padding needed on each side of the image to keep the output the same size as the input ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1.5 , w = 1 , and x = [ 2 2 0 ] , what is s_3 ?
What is the result from applying a filter [ 2 4 1 ] to a row of an image [ 3 3 1 ] , where the filter has a ReLU activation on its output ?
Let theta be ( 1 negative 1 ) , theta_0 be 6, and x be ( 1 , negative 1 ) . Compute theta times x plus theta_0 .
An RNN is defined as s_t = w * s_t-1 + x_t. If s_0 is 1.5 , w is 0.1 , and x is [ 0 3 1 ] , what is s_3 ?
Consider a plane of 45 points , 24 of which are on the left side . Of the points on the left , 4 points are positive . Find the entropy of the left side .
What is the length of the result from applying F to I if F has length 35 and I has length 80?
Compute the loss from the datapoint ( negative 2 0 ) using NLL and natural log , where the base is 2.71828 . Have theta be 2 and theta_0 be 2 .
Given an image row [ 3 3 0 ] and filter [ 3 0 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Consider the input x_t = [ 0 0 5 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_3 if our initial conditions are s_0 is 15 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 1 * s_t .
f(theta) is the square of the sum of 5 and the product of 5 and theta , where theta is 1 . What is f(theta) ?
Using a row of an image [ 3 3 0 ] and filter [ 3 0 1 ] , calculate the value from applying the filter which has a ReLU on its output .
What is the length of the output when we use an image of length 53 and a filter of length 7 if we use a stride length of 1 ?
A point p is classified by a classifier whose decision boundary is theta = ( 2 4 ) . How does it classify p , where p is ( 3 negative 1 ) ?
Using a stride length of 2 , what is the output from applying a filter of length 5 to an image of length 51 ?
What is the total number of outputs for a zero-padded max pooling layer that has 18 inputs , a stride of 2 , and a pooling filter size of 5 ?
Neurons A and B take inputs negative 1 and 3 with weights 1 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 3 , respectively , and with offset 4 . Neuron C also applies a ReLU on its output . What is the output ?
An image I has length 80 and filter F has length 29 , what is the length of the result of applying F to I ?
Given a function ( negative 2 * theta + 3 ) ^ 3 , compute theta after one gradient descent step if theta is 1 and eta is 0.01 .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 4 , and wOC is 2 ?
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 40 inputs and 90 outputs ?
What is the margin of a classifier with theta being 1 and theta_0 being 2 on a point 3 with label negative 1 ?
Neuron C is the output neuron which applies a ReLU on its output and neuron A is the input neuron to a neural network . Compute the output of a neural network with the given architecture and inputs . Neuron C takes in the offset value oC being 4 with weight wOC being 2 . Neuron C takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being negative 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 4 .
A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 0 negative 2 ) ?
A point p is classified by a classifier whose decision boundary is theta = ( 2 0 ) . How does it classify p , where p is ( 3 0 ) ?
Given an image of length 52 and a filter of length 9 , compute the output from applying the filter if we have a stride length of 2 ?
What is the magnitude of the vector [ 3 1 3 ] ?
f(theta) is the square of the sum of 8 and the product of 4 and theta , where theta is 1 . What is f(theta) ?
Consider a filter [ 3 3 1 ] applied on an image [ 1 3 0 ] . What is the output if the filter has a ReLU activation ?
What is the updated Q value of a tuple ( s a ) if q is 5 , the a is 0.2 , and t is 6 ?
What is the size of the margin of a point 2 by a classifier with theta negative 1 and theta_0 1 if the point has label negative 1 ?
Given theta be 3 and eta be 0.05 , calculate the value of the function ( 2 * theta + negative 2 ) ^ 2 after one step of gradient descent .
If a point 1 with label 1 was classified by a classifier with theta negative 1 and theta_0 1 , what is the margin of this point ?
What is the minimum number of padding needed to maintain the same output size if the input image is 50 by 50 and the filter is 41 by 41 ?
x is ( 0 0 ) , theta is ( 1 negative 1 ) and theta_0 is 2 . What is the value of theta times x plus theta_0?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 3 , and wOC is 3 ?
If we have x equals ( 0 negative 1 ), theta equals ( negative 2 1 ), and theta_0 equals negative 3 , then what is the result of theta times x plus theta_0 ?
Calculate the value of y in the dataset [ ( 0 0 ) , ( 1 1 ) , ( 2 y ) ] if we know that the optimal theta 2 used mean squared error . Let lambda be 0.5 .
In a fully-connected feedforward network , how many weights ( including biases ) are there for one layer with 20 inputs and 190 outputs ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_5 if we have s_0 being 4 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 2 * s_t , and we input [ 1 1 19 8 17 ] ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 2 , wAC is 1 , oC is 4 , and wOC is 3 ?
Compute the output of the sigmoid function when we pass in negative 3 . Let e be equal to 2.71828 .
Neurons A and B take inputs negative 1 and 2 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 2 , respectively , and with offset 1 . Neuron C also applies a ReLU on its output . What is the output ?
Given a 1D image I that is length 90 and a filter F that is length 31 , what is the length of the result from applying F to I ?
Given that there are 22 inputs to a zero-padded max pooling layer and a stride length of 2 , compute the number of output units if we also know the pooling filter size of 3 ?
A neural network has an input neuron A and output neuron C . Neuron A takes in an offset value oA being 0.5 , an offset weight wOA being 3 , and an input x1 being 1 with weight w1 being 1 . The output of neuron A is passed to neuron C , which takes it in with weight wAC being 1 . Neuron C also takes in offset value oC being 4 and offset weight wOC being 2 . Find the output of the neural network .
Using the row of an image  [ 1 0 1 ] and a filter [ 3 0 1 ] , calculate the value of applying the filter on top of the image .
What is the length of the result from applying F to I if F has length 29 and I has length 60?
What is the value of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( 1 negative 1 ) , and theta_0 is 0 ?
Using a stride length of 2 , what is the output from applying a filter of length 11 to an image of length 54 ?
How does a classifier with decision boundary theta classify a point p if theta is ( 2 0 ) and p is ( 1 negative 1 ) ?
Let a function f(theta) = ( negative 1 * theta + 3 ) ^ 3 . For theta = 3 and eta = 0.01 , calculate theta after one gradient descent step .
With lambda = 0.5 , the optimal theta is 2 . If the datapoints are [ ( 0 negative 1 ) , ( 1 negative 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Let 2 be the optimal theta by mean squared error. Given the datapoints [ ( 0 negative 1 ) , ( 1 1 ) , ( 2 y ) ] and lambda is 0.5 , compute the value of y .
Neuron A and Neuron C are the input and output neurons of a neural network . Neuron A takes in value x1 is 1 with weight w1 being 2 and offset value oA being 0.5 with weight wOA being 1 . Neuron C takes in the output of neuron A with weight wAC being 1 and offset value oC being 4 with weight wOC being 2 . What is the output of neuron C ?
The row of an image  [ 1 1 0 ] has a filter [ 2 4 0 ] applied to it . What is the resulting value if they both align ?
Consider a very simple RNN , defined by the following equation: s_t = w * s_ t-1 + x_t. Given s_0 = 1.5 , w = 0.1 , and x = [ 1 0 2 ] , what is s_3 ?
Compute the ReLU output of neuron C which takes the output of neuron A with weight 1 and neuron B with weight 3 and offset 1 . Neuron B has input 1 and offset 1 . Neuron A has input negative 1 and offset 1 with offset 0.5 .
If we have a neural network layer with 10 inputs and 90 outputs , how many weights ( including biases ) are needed to describe each connection ?
Let 5 be the margin of the dataset with respect to the separator . Also let 12 be the maximum magnitude of a point from the dataset . Compute the maximum number of mistakes made by the perceptron algorithm .
With lambda = 1 , the optimal theta is 2 . If the datapoints are [ ( 0 2 ) , ( 1 0 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
Consider an image I of length 51 and filter F of length 13 . What is the length of the output if we have a stride length of 1 ?
If we are given the classifiers [ 1 3 0 ] and [ 1 4 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
What is the minimum number of padding needed to maintain the same output size if the input image is 70 by 70 and the filter is 41 by 41 ?
If you are given two classifiers [ 1 1 1 ] and [ 3 2 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
If we have an image of size 50 by 50 and a filter of size 19 by 19 , how far out on each side should we pad to maintain the same output dimensions ?
Consider an image I of length 51 and filter F of length 3 . What is the length of the output if we have a stride length of 1 ?
A point p is classified by a classifier whose decision boundary is theta = ( 1 3 ) . How does it classify p , where p is ( 1 negative 4 ) ?
Using the row of an image  [ 1 0 0 ] and a filter [ 4 3 0 ] , calculate the value of applying the filter on top of the image .
Compute the output of the sigmoid function when we pass in 0 . Let e be equal to 2.71828 .
Given an image row [ 2 3 1 ] and filter [ 3 2 0 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Let a function f(theta) = ( 2 * theta + 1 ) ^ 2 . For theta = 1 and eta = 0.01 , calculate f(theta) after one gradient descent update .
Consider the classifier [ 2 1 1 ] and [ 4 0 1 ] . Do they represent the same hyperplane ? Return 1 if true and another value if false .
What is the magnitude of the vector [ 1 0 3 ] ?
Let an input vector be [ 1 6 ] . What is its magnitude ?
If q is 9 , what is its updated value after applying Q learning if a is 0.2 and t is 6 ?
Using the row of an image  [ 1 4 1 ] and a filter [ 2 3 0 ] , calculate the value of applying the filter on top of the image .
What is the value from applying a filter [ 2 3 1 ] directly on top of an image  [ 1 2 0 ] ?
x is ( 1 negative 1 ) , theta is ( negative 2 1 ) and theta_0 is 0.25 . What is the value of theta times x plus theta_0?
A max pooling layer has 26 inputs, a pooling filter length of 3 , a stride length of 1 , and is zero-padded . Compute the number of output units for this layer .
Compute the mean squared error with the data points  [ ( 2 negative 1 )  and ( 2 1 ) ] , theta = 4 , and lda = 1 .
Using a filter [ 3 3 1 ] with a ReLU on its output , compute the result from applying it right on top of the image  [ 3 3 0 ] .
Using a row of an image [ 2 3 1 ] and filter [ 4 4 1 ] , calculate the value from applying the filter which has a ReLU on its output .
What is the total number of outputs for a zero-padded max pooling layer that has 26 inputs , a stride of 2 , and a pooling filter size of 1 ?
If f(theta) is 6 times theta plus 5 squared and theta is 2 what is f(theta) ?
With lambda = 0.5 , the optimal theta is 1 . If the datapoints are [ ( 0 2 ) , ( 1 2 ) , ( 2 y ) ] , what is the value of y ? The optimal theta is computed by mean squared error .
If we have x equals ( 1 negative 1 ), theta equals ( 1 negative 1 ), and theta_0 equals 0.5 , then what is the result of theta times x plus theta_0 ?
A max pooling layer has 24 inputs, a pooling filter length of 4 , a stride length of 2 , and is zero-padded . Compute the number of output units for this layer .
Let s_0 be 1.5 , w be 0.1 , and x be [ 1 0 2 ] . Compute s_3 if s_t is w * s_t-1 + x_t .
If you are given two classifiers [ 1 2 0 ] and [ 4 2 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
Let an input vector be [ 7 0 1 ] . What is its magnitude ?
Determine if the following two classifiers represent the same hyperplane , [ 4 1 0 ] and [ 1 3 0 ] . If so , return 1 , and return anything else otherwise .
If the margin of the dataset with respect to a separator is 5 and the maximum magnitude of a point is 19 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
Let 1 be the optimal theta by mean squared error. Given the datapoints [ ( 0 2 ) , ( 1 2 ) , ( 2 y ) ] and lambda is 1 , compute the value of y .
Consider a filter [ 3 0 0 ] applied on an image [ 1 3 1 ] . What is the output if the filter has a ReLU activation ?
What is the minimum number of padding needed to maintain the same output size if the input image is 60 by 60 and the filter is 33 by 33 ?
Let theta be ( negative 2 1 ) , theta_0 be negative 1, and x be ( 0 , 0 ) . Compute theta times x plus theta_0 .
What is the value from applying a filter [ 1 1 0 ] directly on top of an image  [ 1 0 0 ] ?
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 2 , oA is 0.5 , wOA is 1 , wAC is 1 , oC is 1 , and wOC is 2 ?
If x = [ 0 3 3 ], what is || x || ?
What is the result of applying the value negative 44 to the sigmoid function ? Let e be equal to 2.71828 .
Determine how many pixels of padding we need on the input of size 50 by 50 to ensure our filter 39 by 39 gives an output of the same size .
If the margin of the dataset with respect to a separator is 3 and the maximum magnitude of a point is 1 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
The row of an image  [ 1 0 1 ] has a filter [ 4 0 0 ] applied to it . What is the resulting value if they both align ?
If we have a state machine , defined as s_t = f(s_(t-1), x_t) and y_t = g(s_t) , where x_t is the input , what is the output y_6 if we have s_0 being 3 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , g(s_t) = 0 * s_t , and we input [ 8 1 8 15 16 0 ] ?
Given two classifiers [ 3 1 0 ] and [ 2 1 1 ] , determine if they are the same hyperplane. Return 1 if true and a different value if false .
Let an input vector be [ 0 6 ] . What is its magnitude ?
What is the most number of mistakes made by the perceptron algorithm if 10 is the maximum magnitude of a point in the dataset and the dataset has a margin of 5 to the separator .
Neurons A and B take inputs negative 1 and 1 with weights 2 and 1 , respectively . Neuron A has offset 0.5 and neuron B has offset 1 . Neuron C takes in the output of A and B with weights 1 and 2 , respectively , and with offset 2 . Neuron C also applies a ReLU on its output . What is the output ?
If you are given two classifiers [ 1 2 0 ] and [ 0 4 1 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
In a neural network , neuron A outputs the sum of x1 times w1 and oA times wOA and neuron C outputs the ReLU of the sum of the product between the input from neuron A and wAC and the product between oC and wOC . What is the output of neuron C if we are given that x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 3 , wAC is 1 , oC is 3 , and wOC is 2 ?
A fully-connected neural network has 200 outputs and 50 inputs . How many total weights are there including the biases ?
What is the length of the result from applying F to I if F has length 31 and I has length 60?
If the margin of the dataset with respect to a separator is 4 and the maximum magnitude of a point is 12 , what is the worst-case theoretical bound for the number of mistakes the perceptron algorithm would make ?
What is the entropy of the left side of a region containing 27 points where the plane has 45 points in total and 2 points on the left are positive ?
Given theta be 4 and eta be 0.01 , calculate the value of the function ( 2 * theta + 1 ) ^ 4 after one step of gradient descent .
If x = [ 5 2 1 ], what is || x || ?
What is the total number of outputs for a zero-padded max pooling layer that has 28 inputs , a stride of 1 , and a pooling filter size of 1 ?
There are 45 points on a 2D plane , 23 on the right side of a line and the rest on the left . 3 points on the left of the line are positive . What is the entropy of the left region ?
If f(theta) is 6 times theta plus 6 squared and theta is 2 what is f(theta) ?
Given theta = 3 and lda = 1 , compute the mean squared error with the data points [ ( 2 negative 1 )  and ( 2 2 ) ] .
If you let theta be 3 and eta be 0.05 , what is the updated theta value after one gradient descent step if the loss function is given by ( negative 2 * theta + 3 ) ^ 3 ?
What is the result of theta times x plus theta_0 if x is ( 1 negative 1 ), theta is ( negative 2 1 ) , and theta_0 is 0.25 ?
Given a 1D image I that is length 50 and a filter F that is length 7 , what is the length of the result from applying F to I ?
Given an image row [ 1 3 0 ] and filter [ 2 1 1 ] , what is the result from applying the filter to the image row after applying ReLU activation on the filter’s output ?
Compute the output length given the stride 2 , image length 54 , and filter length 9 .
Consider the input x_t = [ 19 8 8 9 4 ] to a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) . Compute y_5 if our initial conditions are s_0 is 7 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 3 * s_t .
Given the values for theta as 2 and theta_0 as 0 , compute the NLL loss on the data point ( 1 2 ) . Use log base e of 2.71828 for the log .
If the decision boundary of a classifier is theta , where theta is equal to ( 1 4 ) , how does it classify point p , where p is equal to ( 3 negative 3 ) ?
Find the Euclidean length of [ 5 0 3 ] .
Given a function ( negative 2 * theta + 3 ) ^ 4 , compute theta after one gradient descent step if theta is 2 and eta is 0.01 .
How does a classifier with decision boundary theta classify a point p if theta is ( 2 0 ) and p is ( 2 negative 1 ) ?
Neuron C is the output neuron and neuron A takes the input . Compute the output with the given architecture and inputs . Neuron C takes in the offset value oC being 3 with weight wOC being 2 . Neuron C also takes in the output of neuron A with weight wAC being 1 . Neuron A takes in the input value x1 being 1 with weight w1 being 2 and offset value oA being 0.5 and offset weight wOA being 3 .
What is the output y_6 of a state machine with equations s_t = f(s_(t-1), x_t) and y_t = g(s_t) , conditions s_0 = 2 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , and input x_t = [ 8 0 16 3 7 7 ] ?
If you are given two classifiers [ 1 0 0 ] and [ 1 2 0 ] , can you determine if they are the same classifier ? Return 1 if so and anything but a 1 if not .
What is the length of the output when we use an image of length 54 and a filter of length 17 if we use a stride length of 1 ?
If f(theta) is 2 times theta plus 8 squared and theta is 1 what is f(theta) ?
Given the classifiers [ 1 1 0 ] and [ 1 2 0 ] , determine if they are the same classifier . Return 1 if so and anything else if not .
Given theta = 0 and lda = 0.5 , compute the mean squared error with the data points [ ( 2 2 )  and ( 2 2 ) ] .
A neural network has input x1 with weight w1 that goes into neuron A . Neuron A also has input oA that has weight wOA . Neuron C inputs the output of neuron A with weight wAC . Neuron C has also has input oC that has weight wOC . Neuron C applies a ReLU on its output . What is the output of neuron C if x1 is negative 1 , w1 is 1 , oA is 0.5 , wOA is 0 , wAC is 1 , oC is 1 , and wOC is 3 ?
x is ( negative 1 0 ) , theta is ( negative 2 1 ) and theta_0 is 0.25 . What is the value of theta times x plus theta_0?
Given the largest magnitude of a point as 16 and the margin of the dataset be 3 from the separator , compute the most number of mistakes made by the perceptron algotithm .
The row of an image  [ 1 0 0 ] has a filter [ 0 0 1 ] applied to it . What is the resulting value if they both align ?
Given that there are 20 inputs to a zero-padded max pooling layer and a stride length of 1 , compute the number of output units if we also know the pooling filter size of 2 ?
Find the Euclidean length of [ 3 1 3 ] .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 0 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 0 * s_t , what is the output y_3 after the inputs [ 12 9 4 ] ?
If we let theta be 3 and lda be 0.5 , what is the mean squared error of the given points  [ ( 2 negative 2 )  and ( 1 4 ) ] ?
If we are given the classifiers [ 1 3 1 ] and [ 0 2 0 ] , can you determine if they represent the same classifier ? Return 1 if true and anything else if not .
Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 3 , f(s_(t-1), x_t) = max ( s_(t-1) , x_t ) , and g(s_t) = 2 * s_t , what is the output y_6 after the inputs [ 11 9 14 4 5 0 ] ?
An image I has length 80 and filter F has length 11 , what is the length of the result of applying F to I ?
What is the length of the output when we use an image of length 53 and a filter of length 11 if we use a stride length of 1 ?