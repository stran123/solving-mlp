{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "You do not have to follow our installation instructions if you have roughly equivalent setups / environments already.\n",
    "\n",
    "We will use Conda and Pip to help us install packages for this homework. If you do not have Miniconda or Anaconda, you can install Miniconda from here https://docs.conda.io/en/latest/miniconda.html.\n",
    "\n",
    "```\n",
    "conda create --name exercise2 python=3.7\n",
    "conda activate exercise2\n",
    "\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "Go to https://pytorch.org/ to install PyTorch if you don't have it already\n",
    "\n",
    "To install the Hugging Face `transformers` library, run\n",
    "```\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "Follow the instructions from https://docs.dgl.ai/en/0.4.x/install/ to install Deep Graph Library (DGL).\n",
    "\n",
    "Spin up jupyter notebook with\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "# Exercise\n",
    "Our exercise is an implementation of the paper [Graph-to-Tree Learning for Solving Math Word Problems](https://www.aclweb.org/anthology/2020.acl-main.362.pdf), which solves math word problems in the MAWPS dataset. Please run `demo.ipynb` for some visualizations of the overall pipeline. We recommend that you read the original paper as well if necessary.\n",
    "\n",
    "## Provided Components\n",
    "1. We provide the entire input and output processing pipeline for you, as described in `demo.ipynb`.\n",
    "2. We provide a fully implemented custom implementation of the transformer in the `TransformerBlock` class.\n",
    "3. We provide a partially implemented graph convolutional network in the `GCN` class.\n",
    "4. We provide a fully implemented tree decoding network in `TreeDecoder`. The tree decoding logic in `train` and `evaluate` is fully implemented.\n",
    "5. If `use_t5 = 'small'`, `setup` will load in a pretrained `t5-small` into the variable `t5_model`.\n",
    "\n",
    "## Tasks\n",
    "Your tasks are\n",
    "1. Use Deep Graph Library (DGL) to complete the graph convolution network. Keep `use_t5 = None` for this part. The baseline performance obtained by the TA is 0.74 test value accuracy. Report test accuracies for at least 5 sets of hyperparameters.\n",
    "2. Use Hugging Face `transformers` library to replace the custom transformer base model with a pre-trained `t5-small` model. Set `use_t5 = 'small'` for this part. The baseline performance obtained by the TA is 0.78 test value accuracy. Report test accuracies for at least 5 sets of hyperparameters.\n",
    "3. Change any part of the code (e.g. hyperparameter, architecture, training data, etc.) to optimize the performance of at least one of the transformers (custom or T5) to be better than the baseline performance.\n",
    "\n",
    "Note that for parts 1 and 2, you should not change any provided component at all. For part 3, you may change any part of the code as long as your model is not \"cheating\" (e.g. fitting on the test set).\n",
    "\n",
    "For each of these parts, please run all the cells below (they are all definition cells except the last cell). When you run the training loop without completing some required part of the exercise, the code will throw a `NotImplementedError`; you should fill out the required code to fix this error, then run the training loop again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece==0.1.91\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.92\n",
      "    Uninstalling sentencepiece-0.1.92:\n",
      "      Successfully uninstalled sentencepiece-0.1.92\n",
      "Successfully installed sentencepiece-0.1.91\n"
     ]
    }
   ],
   "source": [
    "# !pip install 'sentencepiece==0.1.91' --force-reinstall \n",
    "# run this if some error occurs; code breaks with newer package version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer,T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:38:46.536166Z",
     "start_time": "2020-10-29T08:38:37.253954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from tqdm import tqdm, trange\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "false = False\n",
    "true = True\n",
    "NaN = float(\"NaN\")\n",
    "\n",
    "from util import setup, check_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Inputs to Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:30:17.523815Z",
     "start_time": "2020-10-29T08:30:17.503632Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensorize_data(train_data, test_data):\n",
    "    for d in itertools.chain(train_data, test_data):\n",
    "        d['in_idxs'] = torch.tensor([in_vocab.token2idx.get(x, in_vocab.unk) for x in d['in_tokens']])\n",
    "        d['out_idxs'] = torch.tensor([out_vocab.token2idx.get(x, out_vocab.unk) for x in d['out_tokens']])\n",
    "        d['n_in'] = n_in = len(d['in_idxs'])\n",
    "        d['n_out'] = len(d['out_idxs'])\n",
    "        d['n_nP'] = n_nP = len(d['nP'])\n",
    "        d['nP_in_mask'] = mask = torch.zeros(n_in, dtype=torch.bool)\n",
    "        mask[d['nP_positions']] = True\n",
    "        d['nP_out_mask'] = mask = torch.zeros(n_max_nP, dtype=torch.bool)\n",
    "        mask[:n_nP] = True\n",
    "        d['qcomp_edges'] = get_quantity_comparison_edges(d)\n",
    "        d['qcell_edges'] = get_quantity_cell_edges(d)\n",
    "\n",
    "def get_quantity_comparison_edges(d):\n",
    "    quants = [float(x) for x in d['nP']]\n",
    "    quant_positions = d['nP_positions']\n",
    "#     assert max(quant_positions) < d['n_in']\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=np.bool)\n",
    "    for x, x_pos in zip(quants, quant_positions):\n",
    "        for y, y_pos in zip(quants, quant_positions):\n",
    "            adj_matrix[x_pos, y_pos] |= x > y\n",
    "    \"\"\"\n",
    "    Convert the adjacency matrix of the directed graph into a tuple of (src_edges, dst_edges), which\n",
    "    is the input format of dgl.graph (see https://docs.dgl.ai/generated/dgl.graph.html).\n",
    "    Hint: check out the 'nonzero' function\n",
    "    \"\"\"\n",
    "    return adj_matrix.nonzero(as_tuple=True)\n",
    "\n",
    "def get_quantity_cell_edges(d):\n",
    "    in_idxs = d['in_idxs']\n",
    "    quant_positions = d['nP_positions']\n",
    "    quant_cell_positions = d['quant_cell_positions']\n",
    "    assert max(quant_cell_positions) < d['n_in']\n",
    "    word_cells = set(quant_cell_positions) - set(quant_positions)\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=torch.bool)\n",
    "    for w_pos in word_cells:\n",
    "        for q_pos in quant_positions:\n",
    "            if abs(w_pos - q_pos) < 4:\n",
    "                adj_matrix[w_pos, q_pos] = adj_matrix[q_pos, w_pos] = True\n",
    "    pos_idxs = in_idxs[quant_cell_positions]\n",
    "    for idx1, pos1 in zip(pos_idxs, quant_cell_positions):\n",
    "        for idx2, pos2 in zip(pos_idxs, quant_cell_positions):\n",
    "            if idx1 == idx2:\n",
    "                adj_matrix[pos1, pos2] = adj_matrix[pos2, pos1] = True\n",
    "    \"\"\"\n",
    "    Convert the adjacency matrix of the directed graph into a tuple of (src_edges, dst_edges), which\n",
    "    is the input format of dgl.graph (see https://docs.dgl.ai/generated/dgl.graph.html).\n",
    "    Hint: check out the 'nonzero' function\n",
    "    \"\"\"\n",
    "    return adj_matrix.nonzero(as_tuple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     102
    ]
   },
   "outputs": [],
   "source": [
    "class TransformerAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Used in Transformer Block\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qkv = nn.Linear(n_hid, n_head * (n_k * 2 + n_v))\n",
    "        self.out = nn.Linear(n_head * n_v, n_hid)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        n_batch, n_batch_max_in, n_hid = x.shape\n",
    "        q_k_v = self.qkv(x).view(n_batch, n_batch_max_in, n_head, 2 * n_k + n_v).transpose(1, 2)\n",
    "        q, k, v = q_k_v.split([n_k, n_k, n_v], dim=-1)\n",
    "\n",
    "        q = q.reshape(n_batch * n_head, n_batch_max_in, n_k)\n",
    "        k = k.reshape_as(q).transpose(1, 2)\n",
    "        qk = q.bmm(k) / np.sqrt(n_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            qk = qk.view(n_batch, n_head, n_batch_max_in, n_batch_max_in).transpose(1, 2)\n",
    "            qk[~mask] = -np.inf\n",
    "            qk = qk.transpose(1, 2).view(n_batch * n_head, n_batch_max_in, n_batch_max_in)\n",
    "        qk = qk.softmax(dim=-1)\n",
    "        v = v.reshape(n_batch * n_head, n_batch_max_in, n_v)\n",
    "        qkv = qk.bmm(v).view(n_batch, n_head, n_batch_max_in, n_v).transpose(1, 2).reshape(n_batch, n_batch_max_in, n_head * n_v)\n",
    "        out = self.out(qkv)\n",
    "        return x + out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = TransformerAttention()\n",
    "        n_inner = n_hid * 4\n",
    "        self.inner = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_inner),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_inner, n_hid)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.attn(x, mask=mask)\n",
    "        return x + self.inner(x)\n",
    "    \n",
    "class GCNBranch(nn.Module):\n",
    "    def __init__(self, n_hid_in, n_hid_out, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define a branch of the graph convolution with\n",
    "        1. GraphConv from n_hid_in to n_hid_in\n",
    "        2. ReLU\n",
    "        3. Dropout\n",
    "        4. GraphConv from n_hid_in to n_hid_out\n",
    "        \n",
    "        Note: your should call GraphConv with allow_zero_in_degree=True\n",
    "        \"\"\"\n",
    "        self.gc1 = GraphConv(n_hid_in, n_hid_in, allow_zero_in_degree=True)\n",
    "        self.drelu = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.gc2 = GraphConv(n_hid_in, n_hid_out, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, x, graph):\n",
    "        \"\"\"\n",
    "        Forward pass of your defined branch above\n",
    "        \"\"\"\n",
    "        return self.gc2(graph, self.drelu(self.gc1(graph, x)))\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, n_head=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList(GCNBranch(n_hid, n_hid // n_head, dropout) for _ in range(n_head))\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_hid),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hid, n_hid)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(n_hid)\n",
    "\n",
    "    def forward(self, h, gt_graph, attr_graph):\n",
    "        x = h.reshape(-1, n_hid)\n",
    "        graphs = [gt_graph, gt_graph, attr_graph, attr_graph]\n",
    "        x = torch.cat([branch(x, g) for branch, g in zip(self.branches, graphs)], dim=-1).view_as(h)\n",
    "        x = h + self.layer_norm(x)\n",
    "        return x + self.feed_forward(x)\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(Gate, self).__init__()\n",
    "        self.t = nn.Linear(n_in, n_out)\n",
    "        self.s = nn.Linear(n_in, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.t(x).tanh() * self.s(x).sigmoid()\n",
    "\n",
    "class TreeDecoder(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "        self.constant_embedding = nn.Parameter(torch.randn(1, out_vocab.n_constants, n_hid))\n",
    "\n",
    "        self.qp_gate = nn.Sequential(drop, Gate(n_hid, n_hid))\n",
    "        self.gts_right = nn.Sequential(drop, Gate(2 * n_hid, n_hid))\n",
    "\n",
    "        self.attn_fc = nn.Sequential(drop,\n",
    "            nn.Linear(2 * n_hid, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1)\n",
    "        )\n",
    "        self.quant_fc = nn.Sequential(drop,\n",
    "            nn.Linear(n_hid * 3, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1, bias=False)\n",
    "        )\n",
    "        self.op_fc = nn.Sequential(drop, nn.Linear(n_hid * 2, out_vocab.n_ops))\n",
    "\n",
    "        self.op_embedding = nn.Embedding(out_vocab.n_ops + 1, n_hid, padding_idx=out_vocab.n_ops)\n",
    "        self.gts_left = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "        self.gts_left_qp = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid), self.qp_gate)\n",
    "\n",
    "        self.subtree_gate = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "\n",
    "    def gts_attention(self, q, zbar, in_mask=None):\n",
    "        attn_score = self.attn_fc(\n",
    "            torch.cat([q.unsqueeze(1).expand_as(zbar), zbar], dim=2)\n",
    "        ).squeeze(2)\n",
    "        if in_mask is not None:\n",
    "            attn_score[~in_mask] = -np.inf\n",
    "        attn = attn_score.softmax(dim=1)\n",
    "        return (attn.unsqueeze(1) @ zbar).squeeze(1) # (n_batch, n_hid)\n",
    "\n",
    "    def gts_predict(self, qp_Gc, quant_embed, nP_out_mask=None):\n",
    "        quant_score = self.quant_fc(\n",
    "            torch.cat([qp_Gc.unsqueeze(1).expand(-1, quant_embed.size(1), -1), quant_embed], dim=2)\n",
    "        ).squeeze(2)\n",
    "        op_score = self.op_fc(qp_Gc)\n",
    "        pred_score = torch.cat((op_score, quant_score), dim=1)\n",
    "        if nP_out_mask is not None:\n",
    "            pred_score[:, out_vocab.base_nP:][~nP_out_mask] = -np.inf\n",
    "        return pred_score\n",
    "\n",
    "    def merge_subtree(self, op, tl, yr):\n",
    "        return self.subtree_gate(torch.cat((op, tl, yr), dim=-1))\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "\n",
    "        if use_t5:\n",
    "            \"\"\"\n",
    "            Use t5_model.encoder as the encoder for this model. Note that unlike the custom transformer, you don't\n",
    "            need to use an external positional embedding for the T5 transformer (i.e. don't define self.pos_emb)\n",
    "            \n",
    "            You may specify layer weights to freeze during finetuning by modifying the freeze_layers global variable\n",
    "            \"\"\"\n",
    "            self.t5_encoder = t5_model.encoder\n",
    "            \n",
    "            for i_layer, block in enumerate(self.t5_encoder.block):\n",
    "                if i_layer in freeze_layers:\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "        else:\n",
    "            self.in_embed = nn.Sequential(nn.Embedding(in_vocab.n, n_hid, padding_idx=in_vocab.pad), drop)\n",
    "            self.pos_embed = nn.Embedding(1 + n_max_in, n_hid) # Use the first position as global vector\n",
    "            self.transformer_layers = nn.ModuleList(TransformerBlock() for _ in range(n_layers))\n",
    "\n",
    "        self.gcn = GCN()\n",
    "\n",
    "        self.decoder = TreeDecoder()\n",
    "\n",
    "        if not use_t5:\n",
    "            self.apply(self.init_weight)\n",
    "\n",
    "    def init_weight(self, m):\n",
    "        if type(m) in [nn.Embedding]:\n",
    "            nn.init.normal_(m.weight, 0, 0.1)\n",
    "\n",
    "    def encode(self, in_idxs, n_in, gt_graph, attr_graph, in_mask=None):\n",
    "        in_idxs_pad = F.pad(in_idxs, (1, 0), value=in_vocab.pad)\n",
    "        if use_t5:\n",
    "            \"\"\"\n",
    "            Call your T5 encoder\n",
    "            \"\"\"\n",
    "#             h, = self.t5_encoder(in_idxs_pad)\n",
    "            h = self.t5_encoder(in_idxs_pad).last_hidden_state\n",
    "        else:\n",
    "            x = self.in_embed(in_idxs_pad) # (n_batch, n_batch_max_in, n_hid)\n",
    "            h = x + self.pos_embed(torch.arange(x.size(1), device=x.device))\n",
    "            for layer in self.transformer_layers:\n",
    "                h = layer(h, mask=in_mask)\n",
    "        zg, h = h[:, 0], h[:, 1:]\n",
    "        zbar = self.gcn(h, gt_graph, attr_graph)\n",
    "        return zbar, zg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:31:12.383238Z",
     "start_time": "2020-10-29T08:31:12.342661Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, up):\n",
    "        self.up = up\n",
    "        self.is_root = up is None\n",
    "        self.left = self.right = None\n",
    "        self.ql = self.tl = self.op = None\n",
    "\n",
    "def train(batch, model, opt):\n",
    "    n_batch = len(batch)\n",
    "\n",
    "    n_in = [d['n_in'] for d in batch]\n",
    "    pad = lambda x, value: nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=value)\n",
    "    in_idxs = pad([d['in_idxs'] for d in batch], in_vocab.pad).to(device)\n",
    "    in_mask = pad([torch.ones(n, dtype=torch.bool) for n in n_in], False).to(device)\n",
    "    nP_in_mask = pad([d['nP_in_mask'] for d in batch], False).to(device)\n",
    "    nP_out_mask = torch.stack([d['nP_out_mask'] for d in batch]).to(device)\n",
    "    \n",
    "    qcomp_graph, qcell_graph = [], []\n",
    "    for d in batch:\n",
    "        \"\"\"\n",
    "        Create qcomp_graph and qcell_graph from d['qcomp_edges'] and d['qcell_edges'] by calling dgl.graph\n",
    "        (see https://docs.dgl.ai/generated/dgl.graph.html)\n",
    "\n",
    "        Note that num_nodes needs to be set to the maximum input length in this batch\n",
    "        \"\"\"\n",
    "        ### Your code here ###\n",
    "        qcomp_graph_i = dgl.graph(d['qcomp_edges'], num_nodes=in_idxs.size(1), device=device)\n",
    "        qcell_graph_i = dgl.graph(d['qcell_edges'], num_nodes=in_idxs.size(1), device=device)\n",
    "        \n",
    "        qcomp_graph.append(qcomp_graph_i)\n",
    "        qcell_graph.append(qcell_graph_i)\n",
    "    qcomp_graph = dgl.batch(qcomp_graph)\n",
    "    qcell_graph = dgl.batch(qcell_graph)\n",
    "    \n",
    "    label = pad([d['out_idxs'] for d in batch], out_vocab.pad)\n",
    "    nP_candidates = [d['nP_candidates'] for d in batch]\n",
    "\n",
    "    zbar, qroot = model.encode(in_idxs, n_in, qcomp_graph, qcell_graph, in_mask=None)\n",
    "    z_nP = zbar.new_zeros((n_batch, n_max_nP, n_hid))\n",
    "    z_nP[nP_out_mask] = zbar[nP_in_mask]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    n_quant = out_vocab.n_constants + n_max_nP\n",
    "    quant_embed = torch.cat([decoder.constant_embedding.expand(n_batch, -1, -1), z_nP], dim=1) # (n_batch, n_quant, n_hid)\n",
    "\n",
    "    nodes = np.array([Node(None) for _ in range(n_batch)])\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "    quant_min, quant_max = out_vocab.base_quant, out_vocab.base_quant + n_quant\n",
    "\n",
    "    # Initialize root node vector according to zg (the global context)\n",
    "    qp = decoder.qp_gate(qroot)\n",
    "    scores = []\n",
    "    for i, label_i in enumerate(label.T): # Iterate over the output positions\n",
    "        Gc = decoder.gts_attention(qp, zbar, in_mask)\n",
    "        qp_Gc = torch.cat([qp, Gc], dim=1) # (n_batch, 2 * n_hid)\n",
    "\n",
    "        score = decoder.gts_predict(qp_Gc, quant_embed, nP_out_mask)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Whether the label is an operator\n",
    "        is_op = (op_min <= label_i) & (label_i < op_max)\n",
    "        # Whether the label is a quantity\n",
    "        is_quant = ((quant_min <= label_i) & (label_i < quant_max)) | (label_i == out_vocab.unk)\n",
    "\n",
    "        op_embed = decoder.op_embedding((label_i[is_op] - out_vocab.base_op).to(device))\n",
    "        qp_Gc_op = torch.cat([qp_Gc[is_op], op_embed], dim=1)\n",
    "\n",
    "        is_left = np.zeros(n_batch, dtype=np.bool)\n",
    "        qleft_qp = decoder.gts_left_qp(qp_Gc_op)\n",
    "        qleft = decoder.gts_left(qp_Gc_op)\n",
    "        for j, ql, op in zip(is_op.nonzero(as_tuple=True)[0], qleft, op_embed):\n",
    "            node = nodes[j]\n",
    "            nodes[j] = node.left = Node(node)\n",
    "            node.op = op\n",
    "            node.ql = ql\n",
    "            is_left[j] = True\n",
    "\n",
    "        is_right = np.zeros(n_batch, dtype=np.bool)\n",
    "        nP_score = score[:, out_vocab.base_nP:].detach().cpu()\n",
    "        ql_tl = []\n",
    "        for j in is_quant.nonzero(as_tuple=True)[0]:\n",
    "            if label_i[j] == out_vocab.unk:\n",
    "                candidates = nP_candidates[j][i]\n",
    "#                 label_i[j] = out_vocab.base_nP + candidates[nP_score[j, candidates].argmax()]\n",
    "                label_i[j] = torch.from_numpy(np.array(out_vocab.base_nP + candidates[nP_score[j, candidates].argmax()])).to(label_i)\n",
    "\n",
    "            node = nodes[j]\n",
    "            pnode = node.up\n",
    "            t = quant_embed[j, label_i[j] - out_vocab.base_quant]\n",
    "            while pnode and pnode.right is node:\n",
    "                t = decoder.merge_subtree(pnode.op, pnode.tl, t) # merge operator, left subtree, and right child\n",
    "                node, pnode = pnode, pnode.up # backtrack to parent node\n",
    "            if pnode is None: # Finished traversing tree of j\n",
    "                continue\n",
    "            # Now pnode.left is node. t is the tl representing the left subtree of pnode\n",
    "            pnode.tl = t\n",
    "            ql_tl.append(torch.cat([pnode.ql, pnode.tl])) # For computing qright\n",
    "            nodes[j] = pnode.right = Node(pnode)\n",
    "            is_right[j] = True\n",
    "\n",
    "        qp = torch.zeros((n_batch, n_hid), device=device)\n",
    "        qp[is_left] = qleft_qp\n",
    "        if ql_tl:\n",
    "            qp[is_right] = decoder.gts_right(torch.stack(ql_tl))\n",
    "\n",
    "    label = label.to(device).view(-1)\n",
    "    scores = torch.stack(scores, dim=1).view(-1, out_vocab.n_ops + n_quant)\n",
    "    loss = F.cross_entropy(scores, label, ignore_index=out_vocab.pad)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamNode(Node):\n",
    "    def __init__(self, up, prev, qp, token=None):\n",
    "        super().__init__(up)\n",
    "        self.prev = prev\n",
    "        self.qp = qp\n",
    "        self.token = token\n",
    "\n",
    "    def trace_tokens(self, *last_token):\n",
    "        if self.prev is None:\n",
    "            return list(last_token)\n",
    "        tokens = self.prev.trace_tokens()\n",
    "        tokens.append(self.token)\n",
    "        tokens.extend(last_token)\n",
    "        return tokens\n",
    "\n",
    "def evaluate(d, model, beam_size=5, n_max_out=45):\n",
    "    in_idxs = d['in_idxs'].unsqueeze(0).to(device=device)\n",
    "    \"\"\"\n",
    "    Create qcomp_graph and qcell_graph from d['qcomp_edges'] and d['qcell_edges'] by calling dgl.graph\n",
    "    (see https://docs.dgl.ai/generated/dgl.graph.html)\n",
    "    \"\"\"\n",
    "#     qcomp_graph = dgl.graph(d['gt_edges'], device=device)\n",
    "#     qcell_graph = dgl.graph(d['attr_edges'], device=device)\n",
    "    qcomp_graph = dgl.graph(d['qcomp_edges'], device=device)\n",
    "    qcell_graph = dgl.graph(d['qcell_edges'], device=device)\n",
    "\n",
    "    zbar, qroot = model.encode(in_idxs, [d['n_in']], qcomp_graph, qcell_graph)\n",
    "    z_nP = zbar[:, d['nP_positions']]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    quant_embed = torch.cat([decoder.constant_embedding, z_nP], dim=1) # (1, n_quant, n_hid)\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "\n",
    "    best_done_beam = (-np.inf, None, None)\n",
    "    beams = [(0, BeamNode(up=None, prev=None, qp=decoder.qp_gate(qroot)))]\n",
    "    for _ in range(n_max_out):\n",
    "        new_beams = []\n",
    "        for logp_prev, node in beams:\n",
    "            Gc = decoder.gts_attention(node.qp, zbar)\n",
    "            qp_Gc = torch.cat([node.qp, Gc], dim=1) # (2 * n_hid,)\n",
    "\n",
    "            log_prob = decoder.gts_predict(qp_Gc, quant_embed).log_softmax(dim=1)\n",
    "            top_logps, top_tokens = log_prob.topk(beam_size, dim=1)\n",
    "            for logp_token_, out_token_ in zip(top_logps.unbind(dim=1), top_tokens.unbind(dim=1)):\n",
    "                out_token = out_token_.item()\n",
    "                logp = logp_prev + logp_token_.item()\n",
    "                if op_min <= out_token < op_max:\n",
    "                    op_embed = decoder.op_embedding(out_token_)\n",
    "                    qp_Gc_op = torch.cat([qp_Gc, op_embed], dim=1)\n",
    "                    prev_node = copy(node)\n",
    "                    next_node = prev_node.left = BeamNode(\n",
    "                        up=prev_node, prev=prev_node,\n",
    "                        qp=decoder.gts_left_qp(qp_Gc_op),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                    prev_node.op = op_embed\n",
    "                    prev_node.ql = decoder.gts_left(qp_Gc_op)\n",
    "                else:\n",
    "                    pnode, prev_node = node.up, node\n",
    "                    t = quant_embed[:, out_token - out_vocab.base_quant]\n",
    "                    while pnode and pnode.tl is not None:\n",
    "                        t = decoder.merge_subtree(pnode.op, pnode.tl, t)\n",
    "                        node, pnode = pnode, pnode.up\n",
    "                    if pnode is None:\n",
    "                        best_done_beam = max(best_done_beam, (logp, prev_node, out_token))\n",
    "                        continue\n",
    "                    pnode = copy(pnode)\n",
    "                    pnode.tl = t\n",
    "                    next_node = pnode.right = BeamNode(\n",
    "                        up=pnode, prev=prev_node,\n",
    "                        qp=decoder.gts_right(torch.cat([pnode.ql, pnode.tl], dim=1)),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                new_beams.append((logp, next_node))\n",
    "        beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "        done_logp, done_node, done_last_token = best_done_beam\n",
    "        if not len(beams) or done_logp >= beams[0][0]:\n",
    "            break\n",
    "    return done_node.trace_tokens(done_last_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expression': '(0-8/(61-23))*((8/(61-23))l2)+(0-(61-23-8)/(61-23))*(((61-23-8)/(61-23))l2)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], 'processed_question': 'Consider a 1D classification line on a 2D plane. There is a total of 61 points, 23 of which are on the right and the rest on the left of the boundary. 8 points on the left are classified positive. What is the entropy of the left region?', 'raw_question': 'Consider a 1D classification line on a 2D plane. There is a total of 61 points, 23 of which are on the right and the rest on the left of the boundary. 8 points on the left are classified positive. What is the entropy of the left region?', 'is_quadratic': False, 'Id': 29207, 'Expected': 0.7424875695421236}\n",
      "{'expression': '9+(0.2*(4-9))', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'processed_question': 'If q is 9, what is its updated value after applying Q learning if a is 0.2 and t is 4?', 'raw_question': 'If q is 9, what is its updated value after applying Q learning if a is 0.2 and t is 4?', 'is_quadratic': False, 'Id': 27281, 'Expected': 8.0}\n",
      "{'expression': '((3^2)+(8^2)+(15^2))^0.5', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'processed_question': 'Let an input vector be [3 8 15]. What is its magnitude?', 'raw_question': 'Let an input vector be [3 8 15]. What is its magnitude?', 'is_quadratic': False, 'Id': 1276, 'Expected': 17.26267650163207}\n",
      "{'expression': '3*(((6m9)m6)m3)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], 'processed_question': 'Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 6, f(s_(t-1), x_t) = (s_(t-1))m(x_t), and g(s_t) = 3*s_t, what is the output y_3 after the inputs [9, 6, 3]?', 'raw_question': 'Let a state machine be described with the equations s_t = f(s_(t-1), x_t) and y_t = g(s_t), where x_t is the input. If s_0 is 6, f(s_(t-1), x_t) = (s_(t-1))m(x_t), and g(s_t) = 3*s_t, what is the output y_3 after the inputs [9, 6, 3]?', 'is_quadratic': False, 'Id': 24929, 'Expected': 27}\n",
      "{'expression': '((3^2)+(7^2)+(1^2))^0.5', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6], 'processed_question': 'Compute the magnitude of [3 7 1].', 'raw_question': 'Compute the magnitude of [3 7 1].', 'is_quadratic': False, 'Id': 1108, 'Expected': 7.681145747868608}\n",
      "{'expression': '3+(0.8*(8-3))', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], 'processed_question': 'What is the updated Q value of a tuple (s, a) if q is 3, the a is 0.8, and t is 8?', 'raw_question': 'What is the updated Q value of a tuple (s, a) if q is 3, the a is 0.8, and t is 8?', 'is_quadratic': False, 'Id': 25940, 'Expected': 7.0}\n",
      "{'expression': '((((1*1.5)+0.25)*1.5)+0.5)', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], 'processed_question': 'An RNN is defined as s_t = w*s_t-1 + x_t. If s_0 is 1, w is 1.5, and x is [ 0.25 0.5 ] , what is s_2?', 'raw_question': 'An RNN is defined as s_t = w*s_t-1 + x_t. If s_0 is 1, w is 1.5, and x is [ 0.25 0.5 ] , what is s_2?', 'is_quadratic': False, 'Id': 20801, 'Expected': 3.125}\n",
      "{'expression': '1*(3-0-9)*0-1', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], 'processed_question': 'A point 3 has label negative 1. Compute the margin of a classifier on this point. Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 9.', 'raw_question': 'A point 3 has label negative 1. Compute the margin of a classifier on this point. Let the theta of the classifier be 1 and the theta_0 of the classifier be negative 9.', 'is_quadratic': False, 'Id': 5194, 'Expected': -12}\n",
      "{'expression': '0*0+3*0-4', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], 'processed_question': 'How does a classifier with decision boundary theta classify a point p if theta is (0, 3) and p is (0 negative 4)?', 'raw_question': 'How does a classifier with decision boundary theta classify a point p if theta is (0, 3) and p is (0 negative 4)?', 'is_quadratic': False, 'Id': 2800, 'Expected': -12}\n",
      "{'expression': '0-1*(3-9)*0-1', 'quant_cell_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], 'processed_question': 'What is the margin on a point 3 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 9?', 'raw_question': 'What is the margin on a point 3 with a label negative 1 if it is classified by a classifier with theta negative 1 and theta_0 9?', 'is_quadratic': False, 'Id': 7342, 'Expected': -6}\n"
     ]
    }
   ],
   "source": [
    "# use_t5 = 'small' # Value should be None, 'small', or 'base'\n",
    "use_t5 = None\n",
    "usingT5 = \"\" if use_t5 is None else \"_t5\"\n",
    "dataset_name = \"ml_data_12_topics\"\n",
    "\n",
    "n_max_in = 100\n",
    "n_epochs = 30\n",
    "n_batch = 64\n",
    "learning_rate = 1e-3\n",
    "if use_t5:\n",
    "    # T5 hyperparameters\n",
    "    freeze_layers = []\n",
    "    weight_decay = 1e-5\n",
    "    n_hid = dict(small=512, base=768)[use_t5] # Do not modify unless you want to try t5-large\n",
    "else:\n",
    "    # Custom transformer hyperparameters\n",
    "    n_layers = 3\n",
    "    n_hid = 512\n",
    "    n_k = n_v = 64\n",
    "    n_head = 8\n",
    "    weight_decay = 0\n",
    "# device = 'cuda:0'\n",
    "device = 'cpu'\n",
    "\n",
    "train_data, test_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5, path=f'data/{dataset_name}/train.json')\n",
    "\n",
    "tensorize_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/375 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f2e9c979b3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-10f0b240e58e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batch, model, opt)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mnP_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nP_candidates'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mzbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqcomp_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqcell_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mz_nP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_max_nP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mz_nP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnP_out_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzbar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnP_in_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d7f04308dbde>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, in_idxs, n_in, gt_graph, attr_graph, in_mask)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mzg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mzbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d7f04308dbde>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGCNBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "model.to(device)\n",
    "\n",
    "epoch = 0\n",
    "while epoch < n_epochs:\n",
    "    print('Epoch:', epoch + 1)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for start in trange(0, len(train_data), n_batch):\n",
    "        batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "        loss = train(batch, model, opt)\n",
    "        losses.append(loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    print('Training loss:', np.mean(losses))\n",
    "\n",
    "    epoch += 1\n",
    "    if epoch % 2 == 0:\n",
    "        model.eval()\n",
    "        value_match, equation_match = [], []\n",
    "        with torch.no_grad():\n",
    "            for d in tqdm(test_data):\n",
    "                if d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "                    val_match = eq_match = False\n",
    "                else:\n",
    "                    pred = evaluate(d, model)\n",
    "                    d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                    val_match, eq_match = check_match(pred, d)\n",
    "                value_match.append(val_match)\n",
    "                equation_match.append(eq_match)\n",
    "        print(f'Test equation accuracy {np.mean(equation_match):.3g}')\n",
    "        print(f'Test value accuracy {np.mean(value_match):.3g}')\n",
    "        torch.save(model.state_dict(), f'models/{dataset_name}{usingt5}/epoch-{epoch}.pth') # 2.5k each, 12 topics\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Model()\n",
    "loaded_model.load_state_dict(torch.load(\"models/ml_data_12_topics/epoch-4.pth\")) # model after 4 epochs without pretrained t5\n",
    "# loaded_model.load_state_dict(torch.load(\"models/ml_data_12_topics_t5/epoch-20.pth\")) # model after 20 epochs with pretrained t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [35:37<00:00,  2.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equation accuracy 0.845\n",
      "Test value accuracy 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model.eval()\n",
    "value_match, equation_match = [], []\n",
    "wrong_val, wrong_eqn = [], []\n",
    "with torch.no_grad():\n",
    "    for d in tqdm(test_data):\n",
    "        if d['is_quadratic']: # This method is not equiped to handle equations with quadratics\n",
    "            val_match = eq_match = False\n",
    "        else:\n",
    "            pred = evaluate(d, loaded_model)\n",
    "            d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "            val_match, eq_match = check_match(pred, d)\n",
    "        value_match.append(val_match)\n",
    "        equation_match.append(eq_match)\n",
    "        if val_match != 0:\n",
    "            wrong_val.append(d['raw_question'])\n",
    "        if equation_match != 0:\n",
    "            wrong_eqn.append(d['raw_question'])\n",
    "print(f'Test equation accuracy {np.mean(equation_match):.3g}')\n",
    "print(f'Test value accuracy {np.mean(value_match):.3g}') # v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Accuracy Rates per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_val_2 = []\n",
    "wrong_eqn_2 = []\n",
    "\n",
    "for elt in wrong_val:\n",
    "    elt = elt.replace(\",\",\"\")\n",
    "    elt = elt.replace(\".\", \"\")\n",
    "    elt = elt.replace(\" \",\"\")\n",
    "    elt = elt.replace(\"negative\", \"\")\n",
    "    elt = elt.replace(\"-\", \"\")\n",
    "    for i in range(10):\n",
    "        elt = elt.replace(str(i),\"\")\n",
    "    wrong_val_2.append(elt)\n",
    "for elt in wrong_eqn:\n",
    "    elt = elt.replace(\",\",\"\")\n",
    "    elt = elt.replace(\".\", \"\")\n",
    "    elt = elt.replace(\" \",\"\")\n",
    "    elt = elt.replace(\"negative\", \"\")\n",
    "    elt = elt.replace(\"-\", \"\")\n",
    "    for i in range(10):\n",
    "        elt = elt.replace(str(i),\"\")\n",
    "    wrong_eqn_2.append(elt)\n",
    "    \n",
    "wrong_val_counts = dict()\n",
    "wrong_eqn_counts = dict()\n",
    "for elt in wrong_val_2:\n",
    "    wrong_val_counts[elt] = wrong_val_counts.get(elt, 0) + 1\n",
    "for elt in wrong_eqn_2:\n",
    "    wrong_eqn_counts[elt] = wrong_eqn_counts.get(elt, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_to_topic = {'Whatisthemagnitudeofthevector[]?': 'b', 'Letaninputvectorbe[]Whatisitsmagnitude?': 'b', 'Ifx=[]whatis||x||?': 'b', 'Computethemagnitudeof[]': 'b', 'FindtheEuclidianlengthof[]': 'b', 'Howdoesaclassifierwithdecisionboundarythetaclassifyapointpifthetais()andpis()?': 'p', 'Aclassifierhasadecisionboundarywherethetais()Whatvaluedoesitclassifypwherepis()?': 'p', 'Ifthedecisionbounaryofaclassifieristhetawherethetaisequalto()howdoesitclassifypointpwherepisequalto()?': 'p', 'Apointpisclassifiedbyaclassifierwhosedecisionboundaryistheta=()Howdoesitclassifypwherepis()?': 'p', 'Ifthetaisthedecisionboundaryforsomeclassifierhowdoestheclassifierclassifyapointpwherethetais()andpis()?': 'p', 'Whatisthemarginofaclassifierwiththetabeingandtheta_beingonapointwithlabel?': 'f', 'Ifapointwithlabelwasclassifiedbyaclassifierwiththetaandtheta_whatisthemarginofthispoint?': 'f', 'Whatisthemarginonapointwithalabelifitisclassifiedbyaclassifierwiththetaandtheta_?': 'f', 'Whatisthesizeofthemarginofapointbyaclassifierwiththetaandtheta_ifthepointhaslabel?': 'f', 'ApointhaslabelComputethemarginofaclassifieronthispointLetthethetaoftheclassifierbeandthetheta_oftheclassifierbe': 'f', 'xis()thetais()andtheta_isWhatisthevalueofthetatimesxplustheta_?': 'lg', 'Whatisthevalueofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Letthetabe()theta_beandxbe()Computethetatimesxplustheta_': 'lg', 'Whatistheresultofthetatimesxplustheta_ifxis()thetais()andtheta_is?': 'lg', 'Ifwehavexequals()thetaequals()andtheta_equalsthenwhatistheresultofthetatimesxplustheta_?': 'lg', 'Iff(theta)istimesthetaplussquaredandthetaiswhatisf(theta)?': 'r', 'f(theta)isdefinedastimesthetaplussquaredandthetaisWhatisf(theta)?': 'r', 'f(theta)isthesquareofthesumofandtheproductofandwherethetaisWhatisf(theta)?': 'r', 'Whatisf(theta)iff(theta)isthetatimesplussquaredandthetais?': 'r', 'Iff(theta)istimesthetaplussquaredwhatisf(theta)whenthetais?': 'r', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_i', 'AneuralnetworkhasinputxwithweightwthatgoesintoneuronANeuronAalsohasinputoAthathasweightwOANeuronCinputstheoutputofneuronAwithweightwACNeuronChasalsohasinputoCthathasweightwOCNeuronCappliesaReLUonitsoutputNeuronsoutputthesumtheproductsofeachinputwiththeirrespectiveweightWhatistheoutputofneuronCifsiswisoAiswOAiswACisoCisandwOCis?': 'nn_ii', 'IhaslengthandFhaslengthwhatisthelengthoftheresultofapplyingFtoI?': 'cnn', 'IislengthandFislengthWhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'IfFhaslengthandIhaslengthwhatisthelengthoftheresultfromapplyingFtoI?': 'cnn', 'WhatisthelengthoftheresultfromapplyingFtoIifFhaslengthandIhaslength?': 'cnn', 'IfIislengthandFislengthcomputethelengthoftheoutputfromapplyingFtoI?': 'cnn', 'ConsideraverysimpleRNNdefinedbythefollowingequation:s_t=w*s_t+x_tGivens_=w=andx=[]whatiss_?': 'rnn', 'AnRNNisdefinedass_t=w*s_t+x_tIfs_iswisandxis[]whatiss_?': 'rnn', 'WhatistheRNNresults_ifs_iswisandxis[]ifwelets_t=w*s_t+x_t?': 'rnn', 'WedefineanRNNass_t=w*s_t+x_tWhatiss_ifs_iswisandxis[]?': 'rnn', 'Lets_bewbeandxbe[]Computes_ifs_tisw*s_t+x_t': 'rnn', 'Letastatemachinebedescribedwiththeequationss_t=f(s_(t)x_t)andy_t=g(s_t)wherex_tistheinputIfs_isf(s_(t)x_t)=(s_(t))m(x_t)andg(s_t)=*s_twhatistheoutputy_aftertheinputs[]?': 'sm_mdp', 'WhatistheupdatedQvalueofatuple(sa)ifqistheaisandtis?': 'rl', 'IfqiswhatisitsupdatedvalueafterapplyingQlearningifaisandtis?': 'rl', 'Letq=AfterQlearningwhatisqifaisandtis?': 'rl', 'IfaisandtiswhatistheQlearningvalueafterapplyingonetuple(sa)ifqis?': 'rl', 'AfterapplyingQlearningtoq=whatisitsvalue?Letthetbeandabe': 'rl', 'ConsideraDclassificationlineonaDplaneThereisatotalofpointsofwhichareontherightandtherestontheleftoftheboundarypointsontheleftareclassifiedpositiveWhatistheentropyoftheleftregion?': 'dtnn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_to_wrong_val = dict()\n",
    "topic_to_wrong_eqn = dict()\n",
    "for question in wrong_val_counts:\n",
    "    topic = question_to_topic[question]\n",
    "    topic_to_wrong_val[topic] = topic_to_wrong_val.get(topic, 0) + wrong_val_counts[question]\n",
    "for question in wrong_eqn_counts:\n",
    "    topic = question_to_topic[question]\n",
    "    topic_to_wrong_eqn[topic] = topic_to_wrong_eqn.get(topic, 0) + wrong_eqn_counts[question]\n",
    "topic_to_wrong_val_percent_correct = {k:1 - topic_to_wrong_val[k]/len(test_data) for k in topic_to_wrong_val}\n",
    "topic_to_wrong_eqn_percent_correct = {k:1 - topic_to_wrong_eqn[k]/len(test_data) for k in topic_to_wrong_eqn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8534230769230771\n",
      "0.9245416666666668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b': 0.913,\n",
       " 'p': 0.9656666666666667,\n",
       " 'f': 0.9231666666666667,\n",
       " 'rl': 0.9305,\n",
       " 'nn_i': 0.9146666666666666,\n",
       " 'lg': 0.9468333333333333,\n",
       " 'cnn': 0.9196666666666666,\n",
       " 'nn_ii': 0.915,\n",
       " 'r': 0.9165,\n",
       " 'rnn': 0.916,\n",
       " 'dtnn': 0.9161666666666667,\n",
       " 'sm_mdp': 0.9173333333333333}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum([topic_to_wrong_val_percent_correct[elt] for elt in topic_to_wrong_val_percent_correct])/(len(topic_to_wrong_val_percent_correct)+1))\n",
    "print(sum([topic_to_wrong_val_percent_correct[elt] for elt in topic_to_wrong_val_percent_correct])/(len(topic_to_wrong_val_percent_correct)))\n",
    "topic_to_wrong_val_percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n",
      "0.9166666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b': 0.913,\n",
       " 'p': 0.9173333333333333,\n",
       " 'f': 0.9183333333333333,\n",
       " 'rl': 0.9151666666666667,\n",
       " 'nn_i': 0.9146666666666666,\n",
       " 'lg': 0.9213333333333333,\n",
       " 'cnn': 0.9196666666666666,\n",
       " 'nn_ii': 0.915,\n",
       " 'r': 0.916,\n",
       " 'rnn': 0.916,\n",
       " 'dtnn': 0.9161666666666667,\n",
       " 'sm_mdp': 0.9173333333333333}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum([topic_to_wrong_eqn_percent_correct[elt] for elt in topic_to_wrong_eqn_percent_correct])/(len(topic_to_wrong_eqn_percent_correct)+1))\n",
    "print(sum([topic_to_wrong_eqn_percent_correct[elt] for elt in topic_to_wrong_eqn_percent_correct])/(len(topic_to_wrong_eqn_percent_correct)))\n",
    "topic_to_wrong_eqn_percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percent Correct')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAE2CAYAAABx36txAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debxN1f/H8dfHdeUqQoYKuSoNMmWIqIgUKhRCUppo0vAdSvM8qX5N3waalYQmkvRNw1eiQimhUiIaZB4y8/n9sfe9zp3P5Z57zrnez8fDw9lrr73355x7+Zy19tprmbsjIiIiyadUvAMQERGRXaMkLiIikqSUxEVERJKUkriIiEiSUhIXERFJUkriIiIiSUpJXETiwsw6mtlP8Y4jP2Z2mZmNiXccInlREhfJhZmtj/izw8w2Rmz33Y3zfm5m50RRr2J4zbd29Vp7CjP7KOJns9XMNkdsP7I753b3J929Z1HFKlLUSsc7AJFE5O77ZLw2s4XARe4+qRhD6AVsADqb2X7uvqK4Lmxmpd19W3Fdb3e5e7uM12b2GvCdu98Vx5BEio1a4iK7wMxSzOxmM1tgZsvNbISZVQz37W1mr5nZSjNbbWZfmFklM3sIaA48G7YSH8rnEucBjwA/A32yXTvdzMaG110eeZ6w+/d7M1tnZrPNrIGZlTUzN7OaEfVeM7Obwtcdzeyn8P0sBZ4ys6pm9p6ZLQvfx1gzOyDi+CpmNtzM/jSzVWY2Kiz/ycw6RNQra2ZrzOzIfD7L28Nr/GJmPcOy481ssZlZRL2zzeyLfH8weV/jmvD8y81sjJlVCcsrhp/NZWb2q5n9ZWa3Rhx3tZmNj9huamb/C9/z72Y2aFfiESkqSuIiu+ZfwMnAcUBNYCvwcLjvIoJerhpAFeAKYIu7/xOYTtCq3yfczsHMDgNaAq8CIwgSesa+VOA9YB5wEFALeCPc1w+4jiDpVwB6AKuifD/pQGp4visJ/m94OrxGnbDOwxH1RwEGHAFUB54Iy4cDkbcLugI/uvu8fK5bBtgfuBh4yczqAFOALUDbiLr9wvMXipmdSfDzOjV8fxuAF7JV6wTUB1oDF5lZj1zOUxWYBLxC8J7rAdMKG49IUVISF9k1lwCD3f13d98E3A70CluOW4GqwCHuvs3dp7v734U497nAl+7+M0EibxbRkj2OIEHf4O4b3H2ju08N910E3OPuX3vgB3dfEuU1NwN3uvuW8JxL3X1s+HoNcC/QBiBMsscDl7n76vCYyeF5hgPdzCwt3O4HvJzPdbcBt4fnmESQJHt4sKhD5hcCM6seXn9UlO8nUl/gCXef6+4bgWuB0zJ6TkJ3u/tad58PPEW23o9QD2CWuz8Txrva3WfsQjwiRUZJXKSQwkRdC5gQdpevBr4m+Pe0H/Ac8D/gdTNbYmb3mFlKIc7dj6AFjrv/QtDay2iN1wJ+cfcduRxei6D7fVf86e5bI+Iob2bPh13Ma4H/EvQqZFznL3dfl/0k7r6Q4LPoFrZc2wGv5XPdZeGXoAyLgAPD18OBM82sLEFS/cDdl+/CezswPG9GjEsJvrTUiKizOI8YIu3O5ysSE0riIoUUthJ/A9q5e8WIP2Xdfbm7b3b3W9z9COAEoCfQO+PwAk5/IkEX9m3h/eY/gUbAOWZWiiDZpIevs1sMHJJL+RaC3oFyEWX7Z39b2bYHE9wmaO7uFQhuHWTcn14MVDOzfcjdSwQt6N7AR+7+Vx71AKqESTrDQcDvkPkF5lvgdApu0efnd6B2xoaZVQP2IvgZZqiVWwzZ5PX5isSNkrjIrnkauM/MakGQGMzs9PD1SWZWL0y0awm6jDNazkuBg/M573nAeOAooHH4pxFQGWhPcK94HXCnmZUzszQzaxUe+yww2MwaWeAwM6sZttpnA30tGJDXBTi2gPdXnuDe8epwENhNGTvC5DoZ+I+Z7WtmZczshIhjXyfo9r+Ugu9hpwI3h+doB3QgvMcfGg7cTPCZvVPAufIyErjUzI4Iu/nvA95199URda4Pex8ODePOrdv+daCxmV1gZqnhoLimuxiTSJFQEhfZNUMI7t9+ZGbrgKlAk3BfDWAsQbL9DpjAzqTwMHBuOLp5SOQJw5Ztd+Axd/8z4s9PBF3S54Vd3p0JEvsS4FfgDAB3fxn4P4Jksy78O+O+7xUEj62tAroRfFHIz4ME3ecrCL44TMi2vw9BAp4P/EmQ+AjjWEeQcA8ExhVwnYUEX3L+BJ4Hznf3BRH7xwCHAqPdfXMB58qVu79OMNJ/IsFnVgG4IFu194E5BLcuXgyvm/08ywi+ZJwPLAvrt9yVmESKigU9gyIiRcfM7gGquftFu3meUgRfVHq7+5QiCS7r+SsSfLGpuov320XiSpO9iEiRCge09Sdo8e+uPsDaWCRwkZJA3ekiUmTM7AqCLvIx7v7lbp7rc+AhglsBIpILdaeLiIgkKbXERUREklTM7omb2fPAaQSTQtTPZb8BjxKMtN0A9Hf3rwo6b5UqVTw9Pb2IoxUREUlMM2fOXO7uVXPbF8uBbS8C/yHv50Q7AXXDPy0IpjpsUdBJ09PTmTFDMx2KiMiewcwW5bUvZt3p4VzKK/Op0hUYHs7x/DlQMXKVJBEREclfPO+J1yDrfMVLyDqXcSYzG2BmM8xsxrJly4olOBERkUSXFAPb3H2Yuzdz92ZVq+Z6W0BERGSPE88k/htZFx2oSdYFCURERCQf8Uzi4wjmkDYzawmscfc/4hiPiIhIUonlI2YjgbYESw0uAW4lWDABd3+aYEGFzsBPBI+YnR+rWEREREqimCVxd+9TwH4HLo/V9UVEREq6pBjYJiIiIjkpiYuIiCSpErkUafrgd6Oqt/C+U2MciYiISOyoJS4iIpKklMRFRESSlJK4iIhIkiqR98QTVTT36nWfXkREoqWWuIiISJJSEhcREUlS6k7fw6mLX0QkeaklLiIikqTUEk80t+0bRZ01sY8jjhKxdyCqmMqeHd3JSvjPT0SKz56dxJUwo5OIn1M0MUGJ/vlFPTNhNF8uivBzKrIvPIqp2L8YJmJMkr89O4mLiEhC05fV/OmeuIiISJJKupb4gmV/02votCxlpzU8gH7HprNxy3b6v/Bl1OfqtfkmAM4pPYnTUz7nd6/MNVsuy1pp6DQuPv5gTqpXnZ+XreeGN2fnOM+gdnU5rm4V5vy+hjvemZtj/7UdD6dp7cqFiinSPanPcUipP5i0vQnPbOsM2d7/w70ac2DFNN755nde+XxRjuOfOqcplfcuw5gZi3l95pKo4sjNsG2n8uH2o7OUlbUtvFRmCACPfTifz35anmV/pXJleLpfUwDun/g9Xy1alWX/AfuW5ZHewTlvf2cOc39fG1UsGZ9TvVKLuDX1ZQCu3nIZf3jWz7nJxO+5ruMRAFzy8kxWbdiSZX/rQ6twZfu6AJz3/Jds2ro9y/72R1ZjwAmHFCqmSD1SJtOz9GRWenku3XJVUBjx8zunZW1Ob3Qgv6/eyDWjZuU4vqDfvWjN3FGXIVt75Si/JfVljiq1iCnzl/P4R/Nz7L/nzAYcUnUfJs1dyjOfLsixv6DfvbxkfFYvlhlCmm3h5W0nMX57y6yVhk5j1MBjARg2+Wc+nPdXlt1lU1N46YJjgIJ/9woTU4aDS/3JvanPAnD91otYsGP/LD+7egdW4NbTjwLg6te+5o81m7Ic36R2pXx/9wojt9+t01I+p1/pSWz0MvTP9n8CQI+mNenZrBYr/97Cpa/MzLG/oN+9gmIZVPptjkv5jjk7anPH1n456l27aCVNa1dm5qKVDJn4Q479t5xej6MO3LfA373CxpXhqTKPUtnWMWbbCby+/YSgMOJzevH8Y0grk8LL0xYy/ts/cpyvoN+9aN2/tRdf7aibpewAW8kjZZ4Ecv9/7+Cqe3PvmQ0BuP7Nb/M9v1riIiIiScrcPd4xFEqzZs18xowZ+dbRPZToleiYoEQP+NHvefRKdEyg33OS+OcXRUxmNtPdm+W2Ty1xERGRJKUkLiIikqSUxEVERJKUkriIiEiSUhIXERFJUkriIiIiSUpJXEREJEkpiYuIiCQpJXEREZEkpSQuIiKSpJTERUREkpSSuIiISJJSEhcREUlSSuIiIiJJSklcREQkSSmJi4iIJKmYJnEz62hmP5jZT2Y2OJf9B5nZx2b2tZl9a2adYxmPiIhISRKzJG5mKcATQCegHtDHzOplq3YTMNrdjwZ6A0/GKh4REZGSJpYt8WOAn9x9gbtvAV4Dumar40CF8PW+wO8xjEdERKREiWUSrwEsjtheEpZFug04x8yWABOAQbmdyMwGmNkMM5uxbNmyWMQqIiKSdOI9sK0P8KK71wQ6Ay+bWY6Y3H2Yuzdz92ZVq1Yt9iBFREQSUSyT+G9ArYjtmmFZpAuB0QDuPg0oC1SJYUwiIiIlRiyT+HSgrpnVMbMyBAPXxmWr8yvQHsDMjiRI4uovFxERiULMkri7bwOuAN4H5hGMQp9jZneYWZew2j+Bi83sG2Ak0N/dPVYxiYiIlCSlY3lyd59AMGAtsuyWiNdzgdaxjEFERKSkivfANhEREdlFSuIiIiJJSklcREQkSSmJi4iIJCklcRERkSSlJC4iIpKklMRFRESSlJK4iIhIklISFxERSVJK4iIiIklKSVxERCRJKYmLiIgkKSVxERGRJKUkLiIikqSUxEVERJKUkriIiEiSUhIXERFJUkriIiIiSUpJXEREJEkpiYuIiCSpApO4md0fTZmIiIgUr2ha4h1yKetU1IGIiIhI4ZTOa4eZXQpcBhxiZt9G7CoPTI11YCIiIpK/PJM48CrwHnAvMDiifJ27r4xpVCIiIlKgPLvT3X2Nuy8EHgVWuvsid18EbDOzFsUVoIiIiOQumnviTwHrI7bXh2UiIiISR9EkcXN3z9hw9x3k3w0vIiIixSCaJL7AzK40s9Twz1XAglgHJiIiIvmLJolfArQCfgOWAC2AAbEMSkRERApWYLe4u/8F9C6GWERERKQQopmx7TAz+9DMvgu3G5rZTbEPTURERPITTXf6M8D1wFYAd/8WtcxFRETiLpokXs7dv8xWti0WwYiIiEj0okniy83sEMABzKwH8EdMoxIREZECRZPELweGAkeY2W/A1QQj1gtkZh3N7Acz+8nMBudR5ywzm2tmc8zs1agjFxER2cPlOzrdzEoBzdz9JDPbGyjl7uuiObGZpQBPEKyCtgSYbmbj3H1uRJ26BPfbW7v7KjOrtqtvREREZE+Tb0s8nJ3t2vD139Em8NAxwE/uvsDdtwCvAV2z1bkYeMLdV4XX+KsQ5xcREdmjRdOdPsnM/mVmtcyscsafKI6rASyO2F4SlkU6DDjMzD4zs8/NrGNuJzKzAWY2w8xmLFu2LIpLi4iIlHzRzIHeK/z78ogyBw4uouvXBdoCNYHJZtbA3VdHVnL3YcAwgGbNmnn2k4iIiOyJorknfo67f7YL5/4NqBWxXTMsi7QE+MLdtwK/mNmPBEl9+i5cT0REZI8SzT3x/+ziuacDdc2sjpmVIZggZly2Om8TtMIxsyoE3etaXEVERCQK0dwT/9DMupuZFebE7r4NuAJ4H5gHjHb3OWZ2h5l1Cau9D6wws7nAx8C/3X1FYa4jIiKyp4rmnvhA4B/AdjPbCBjg7l6hoAPdfQIwIVvZLRGvPTz3PwoTtIiIiES3iln54ghERERECiealjhh9/cJ4eYn7j4+diGJiIhINKJZivQ+4CpgbvjnKjO7N9aBiYiISP6iaYl3BhqHI9Uxs5eArwmmSxUREZE4iWZ0OkDFiNf7xiIQERERKZxoWuL3Al+b2ccEI9NPAHJdkUxERESKTzSj00ea2SdA87DoOnf/M6ZRiYiISIHyTOJmdgpQ3t1fd/c/CGdbM7MeZrbG3T8oriBFREQkp/zuid8C/C+X8k+AO2ISjYiIiEQtvyS+l7vnWPfT3ZcDe8cuJBEREYlGfkm8gpnl6G43s1QgLXYhiYiISDTyS+JvAs+YWWar28z2AZ4O94mIiEgc5ZfEbwKWAovMbKaZzQR+AZaF+0RERCSO8hydHi4lOtjMbgcODYt/cveNxRKZiIiI5Cua58Q3ArOLIRYREREphGinXRUREZEEoyQuIiKSpKJZivTDaMpERESkeOU37WpZoBxQxcwqESx+AlABqFEMsYmIiEg+8hvYNhC4GjgQmMnOJL4W+E+M4xIREZEC5PeI2aPAo2Y2yN0fL8aYREREJArRPGL2uJm1AtIj67v78BjGJSIiIgUoMImb2cvAIcAsYHtY7ICSuIiISBwVmMSBZkA9d/dYByMiIiLRi+Y58e+A/WMdiIiIiBRONC3xKsBcM/sS2JxR6O5dYhaViIiIFCiaJH5brIMQERGRwotmdPr/zKw2UNfdJ5lZOSAl9qGJiIhIfqKZdvVi4HVgaFhUA3g7lkGJiIhIwaIZ2HY50JpgpjbcfT5QLZZBiYiISMGiSeKb3X1LxoaZlSZ4TlxERETiKJok/j8zuwFIM7MOwBjgndiGJSIiIgWJJokPBpYBswkWRZkA3BTLoERERKRg0TxilgY87+7PAJhZSli2IZaBiYiISP6iaYl/SJC0M6QBk6I5uZl1NLMfzOwnMxucT73uZuZm1iya84qIiEh0Sbysu6/P2AhflyvooLDF/gTQCagH9DGzernUKw9cBXwRbdAiIiISXRL/28yaZGyYWVNgYxTHHQP85O4LwtHtrwFdc6l3J3A/sCmKc4qIiEgomnviVwFjzOx3wAgWQ+kVxXE1gMUR20uAFpEVwi8Htdz9XTP7d14nMrMBwACAgw46KIpLi4iIlHz5JnEzKwWUAY4ADg+Lf3D3rbt74fDc/wf0L6iuuw8DhgE0a9ZMz6iLiIhQQHe6u+8AnnD3re7+Xfgn2gT+G1ArYrtmWJahPFAf+MTMFgItgXEa3CYiIhKdqEanh6PHrZDnng7UNbM6ZlYG6A2My9jp7mvcvYq7p7t7OvA50MXdZxTyOiIiInukaJL4QIJZ2raY2VozW2dmaws6yN23AVcA7wPzgNHuPsfM7jAzrUUuIiKym6JZirT8rp7c3ScQzPAWWXZLHnXb7up1RERE9kTRLEVqZnaOmd0cbtcys2NiH5qIiIjkJ5ru9CeBY4Gzw+31BJO4iIiISBxF85x4C3dvYmZfA7j7qnCgmoiIiMRRNC3xreEUqg5gZlWBHTGNSkRERAoUTRJ/DHgLqGZmdwNTgHtiGpWIiIgUKJrR6SPMbCbQnmDa1W7uPi/mkYmIiEi+8kziZlYWuAQ4FJgNDA2f/RYREZEEkF93+ktAM4IE3gl4sFgiEhERkajk151ez90bAJjZc8CXxROSiIiIRCO/lnjmQifqRhcREUk8+bXEG0XMkW5AWrhtgLt7hZhHJyIiInnKM4m7e0pxBiIiIiKFE81z4iIiIpKAlMRFRESSlJK4iIhIklISFxERSVJK4iIiIklKSVxERCRJKYmLiIgkKSVxERGRJKUkLiIikqSUxEVERJKUkriIiEiSUhIXERFJUkriIiIiSUpJXEREJEkpiYuIiCSpPNcTFxGR4lVhr1IMalGJ2hVTMYx5Njq6A+fNK5LrP9PlgIIvlYAxQZRxFVFMUISfVURMZcuWpWbNmqSmpkYdh5K4iEiCGNSiEk0OOZDS5cpjZhxZyqI78MAji+T6W5esLrBOIsYEUcZVRDFBEX5WYUzuzooVK1iyZAl16tSJOg51p4uIJIjaFVMzE7jsWcyM/fbbj02bNhXqOCVxEZEEYZgS+B5sV372SuIiIiJJSklcREQyjXjuac5sfyxntD+WV559KrN8zapVDDz7DOq27kqH3peyavVaAN5490OOOrEHx59xAStWBveJf164mF69euV7nVmzZmFmTJw4MXZvZg+gJC4iIgDM/34ub7z6EiPGf8iY9z9l8ofv8+svCwB4/smHOab1Ccz/bCztjzuG+554AYDHX3iN6RNeZuA53Xn17SAh3zTkSe666658rzVy5EiOO+44Ro4cGdP3tG3btpieP95iOjrdzDoCjwIpwLPufl+2/f8ALgK2AcuAC9x9USxjEhFJFr3eWJ6j7LS6afRruDcbt+6g/7iVQWGZaZn7ezStSc9mtVj59xYufWVmlmNHDTw23+v98tOPNDi6GWlp5QBo2qI1H058h/MvvYqP//sez41+B9jIeT1Po22PAdx/41WUMmPz5q1s2LiJ1NKl+fSLr9i/6n7UrVs3z+u4O2PGjOGDDz7g+OOPZ9OmTZQtWxaA4cOH8+CDD2JmNGzYkH/f+zgrlv3Fndf/g99+XQjAjfc8RNXqBzCofy/e/DB47w8+PZz1f2/gtn9eQtseF9O43mFMmT6LPl07ctjBB3HXY8+xxUuz3377MWLECKpXr8769esZNGgQM2bMwMy49dZbWbNmDd9++y2PPPIIAM888wxz587l4Ycfzvezi5eYJXEzSwGeADoAS4DpZjbO3edGVPsaaObuG8zsUmAIkH8fjIiIxMShhx/J40PuYvWqlexVtixTPv6Aeg0bA7By+V9Urb4/8Av7V6vC0uUrALh+0AWc1PsSDqxelVcev4ueA6/jtSfvzfc6U6dOpU6dOhxyyCG0bduWd999l+7duzNnzhzuuusupk6dSpUqVVi5ciVLNsB9twymWcvWPPLsK2zfvp0Nf69n7Zo1+V5jy9ZtzHhvBACrVq/l83dewmo04dlnn2XIkCE89NBD3Hnnney7777Mnj07qLdqFampqdx999088MADpKam8sILLzB06NDd/GRjJ5Yt8WOAn9x9AYCZvQZ0BTKTuLt/HFH/c+CcGMYjIpJURnWvkue+tNRSO/cfeHSO/ZX3LlNgyzu7g+sezvmXXcUlfc8kLa0ch9erT0pKSo56ZjtH0Xc4oSUdTmgJwPAx4+ncrjU/LljEg7f2oFKlSjz66KOUK1cuy/EjR46kd+/eAPTu3Zvhw4fTvXt3PvroI3r27EmVKsH7qly5Mks2rGb61Mnc/Uhwfz4lJYXyFfYtMIn36nJy5uslfyyl16WD+WPlerZs2ZL5HPakSZN47bXXMutVqlQJgHbt2jF+/HiOPPJItm7dSoMGDaL/EItZLO+J1wAWR2wvCcvyciHwXm47zGyAmc0wsxnLli0rwhBFRCTSmb378dqET3jhjQlU2LcitescAkDlKtVYtvRPAP5Yuoxq+1XOctyGjRt5cfQ4Lu9/Frc+9DQvvfQSxx13HCNGjMhSb/v27bzxxhvccccdpKenM2jQICZOnMi6desKFWfp0im4e+b2pk1bsuzfu1xa5utBNw/hivN7MXv2bIYOHVrgs9gXXXQRL774Ii+88ALnn39+oeIqbgkxsM3MzgGaAQ/ktt/dh7l7M3dvVrVq1eINTkRkD7JiedBQ+uO3xXw4cTyduvUEoG2Hjox7PRiE9tKY8XQ9pU2W4x54ajhXXtiH1NRUNm7ajJlRqlQpNmzYkKXehx9+SMOGDVm8eDELFy5k0aJFdO/enbfeeot27doxZswYVqwIuupXrgzu+R/T+gRGv/w8EHwJWLd2DZWrVGPl8mWsXrWSLZs3M37S5Dzf05q166mxf5A7XnrppczyDh068MQTT2Rur1q1CoAWLVqwePFiXn31Vfr06VPIT7B4xTKJ/wbUitiuGZZlYWYnATcCXdx9cwzjERGRAvxzwLmc0a4lV57fhxvueoAK++4LwAWXX8Pnn35C3dZdmfTpFwy+fGcL9fc/l/Hl13Po1vFEAAad35vmzZvz9NNPc/bZZ2c5/8iRIznjjDOylHXv3p2RI0dy1FFHceONN9KmTRsaNWrEP/7xDwCuu/0+pk/9lO4ntaJP57YsmP8DqampDLj6Wvqe1p6BZ5/BEYfmPVXpbf8cSM+B19G0adPMrnqAm266iVWrVlG/fn0aNWrExx/vvMN71lln0bp168wu9kQVy3vi04G6ZlaHIHn3BrL8NM3saGAo0NHd/4phLCIiEoUX38z1riYVK1XmmdfG0rDULzn2Hbh/Vd59+bHM7Z6nd6DnwGtzPc8LL7yQo6xLly506dIFgPPOO4/zzjsvc9+3S1azX9VqPPr8qzmO63vBQPpeMBAgS1yfvP5MlnpdT2lL11Pa5hg7sM8++2RpmUeaMmUK11xzTa77EknMWuLuvg24AngfmAeMdvc5ZnaHmXUJqz0A7AOMMbNZZjYuVvGIiIgUZPXq1Rx22GGkpaXRvn37eIdToJg+J+7uE4AJ2cpuiXh9UiyvLyIiUhgVK1bkxx9/jHcYUUuIgW0iIiJSeEriIiIiSUpJXEREJEkpiYuIiCSpmA5sExGRXZf+2O9R1oyu3sL7Ts13/4Vnnc4Fl11N67Y7R2W/8uxTLPx5Pjfd+395HrdP3dasn/9ZdKFGoXHjxhxxxBFZpkSV3KklLiIiAHTq2p2J497MUjZx3Jt06tq92GKYN28e27dv59NPP+Xvv/+O2XVKyhKlSuIiIgJAh85d+fSj/7J1SzAP+W+Lf2XZ0j9o0qIVG/5ez8W9u9LklLNp0P4sxr7/SY7jP5k6g9POvTJz+4orruDFF18EYObMmbRp04amTZtyyimn8Mcff+Qaw8iRI+nXrx8nn3wyY8eOzSz/9ZcFDOjTjZ4nH0evTm1YvDCY3OX5Jx+h+0mtaHRSLwbfE0w407bHxcz4Jlhra/nKVaS3CHogXnzxRbp06UK7du1o374969evp3379jRp0oQGDRpkud7w4cNp2LAhjRo1ol+/fqxbt446deqwdetWANavW0unVo0yt+NF3ekiIgLAvpUqUb9xE6Z8PIkTT+nMxHFvcPJpZ2BmlNmrLA8/8zKt9l3B8pWraHn6eXQ5uU3mamb52bp1K4MGDWLs2LFUrVqVUaNGceONN/L888/nqDtq1Cg++OADvv/+ex5//HHuPqEzANdfOYALLrua9p1OY/OmTezwHUz5+AM++e8EXnlnEi32XsrKVfmvbAbw1Vdf8e2331K5cmW2bdvGW2+9RYUKFVi+fDktW7akS5cuzJ07N8eSqOXLl89cNrVbt25MHPcm7TueTmpqauE/6CKkJC4iIpmCLvU3OPGUzrw/7k1ue+BxANydx/KNpF0AABVOSURBVO6/k0u+/IRSVorf/lzG0mUr2L9a3sulZvjhhx/47rvv6NChAxAsYnLAAQfkqDdjxgyqVKnCQQcdRI0aNbjgggtYs2oVpVNL89eff9C+02kA7FW2LACff/o/up7Vl7S0YKnTypX2LTCWDh06ULly5cz3dMMNNzB58mRKlSrFb7/9xtKlS3NdEhWC1c2GDBlCt27dGDv6VW65/5ECrxdrSuIiIpLpxJM788DtNzJv9jds3LiReg0bAzDhrTGsWrGCme+NIDU1lfQWp7Jpc9blP0uXTmFHluVBgyU/3Z2jjjqKadOm5XvtkSNH8v3335Oeng7A2rVrmfTeODp2ObNQ76F0Sgo7duwIY8i2ROnee2e+HjFiBMuWLWPmzJnBe0pPz3eZ0tatW7Nw4UI++eQTtm/fTt0j6hUqrljQPXEREclUbu99aH7s8dz6ryuyDGhbv24tlatUITU1lY8/m86iJTnvadeucQBzf1zA5s1bWL16NR9++CEAhx9+OMuWLctM4lu3bmXOnDlZjt2xYwejR49m9uzZLFy4kIULFzJ27FjeG/sGe+9TnuoHHMhHE98FYMvmzWzcuIFjj2/L2NEj2LgxWO40ozs9vdaBzPx2HgCvvzspz/e6Zs0aqlWrFrynjz9m0aJFAHkuiQpw7rnncvbZZ9PtrLNzPWdxU0tcRCRBLbzywOgqZluda3d16tqday4+h/ufeC6zrPMZPbny/D40aH8WzRoeyRGHpuc4rlaN/Tnr9A7Ub9eTOnWP4Oijg7jKlCnD66+/zpVXXsmaNWvYtm0bV199NUcddVTmsZ9++ik1atTgwAN3vucTTjiBBfN/YNnSP7n70ae5c/A1PPnQPZROTeXBp16k9Ykn8f3c2Zx9ajvKpzqd27XmnusH8a9L+nHWJdcxbMSbnNr+uDzfZ9++fTn99NNp0KABzZo144gjjgDIsiRqSkoKRx99dOYAvb59+3LTTTfRsWuP3fmIi4ySuIiIZNGu46l8s3hVlrJKlffj5bH/zXUp0shnxIfcdDVDbro6xxeLxo0bM3ny5Dyv2aZNGz7//PMsZSkpKXz01Q+Z28+OyrnQ5YWXX8OFl1+TJa4jDq3Dt5NGZ27fdd3lAPTv35/+/ftnllepUiXPLv7sS6JmmDJlCj169MhcZz3elMRFRESiMGjQIN577z0mTJhA3nfOi5eSuIiISBQef/zxzNffLlkdx0h20sA2ERGRJKUkLiIikqSUxEVERJKUkriIiEiS0sA2EZFENaxt0Z7vtoLnFj+69n5ZZiI7pcuZXHj5NUUaxj333MMNN9yQud2qVSumTp1aJOfetm0bBxx9Mhf26cZ9N1xZ8AFJTklcREQy7VU2jdHvfxrTa2RP4kWVwAE+mPwFhx1cmzHjJ3Hv9YOiWqBlV2zbto3SpeOfQtWdLiIiBfrs40l0bXsMTU45mytvHpK55OhtDz3Ng08Pz6xXv11PFi7+HYBu3brRtGlTjjrqKIYNGwbA4MGD2bhxI40bN6Zv374A7LPPPkAwx/q///1v6tevT4MGDRg1ahQA06dN4cKep/HPgefRte0xXD/oYjxijvZII9+eyFUX9uGgA/dn2oxvM8unz5pDq1ataNSoEccccwzr1q1j+/bt/Otf/6J+/fo0bNgw8xGy9PR0li9fDgSLsrRt2zZ4r7fdRr9+/WjdujU3XjWQ3xb/Sv8zO9GrUxt6dWrDrBlfZF7v+ScfoUH7szKXSP154WKanLJzqtb5C37Nsr2r4v81QkREEsbmTRs565TjM7cvuPwaTjy5M7dfdxXPjBrHaQcbvS4ZHNW5nn/+eSpXrszGjRtp3rw53bt357777uM///kPs2bNylH/zTffZNasWXzzzTcsX76c5s2b88JbjQD4fs63vPnhNKpWP4DzzujI19M/p8kxx2Y5ftOmzUya8gVD77+R1WvXMXLsRFo1b8SWLVvpdelgRr3+Fs2bN2ft2rWkpaUxbNgwFi5cyKxZsyhdunSWOdLzMnfuXKZMmcL8FcH87UNffYu9ypZl0S8/M/jyixg54ePMJVK/GP8S5dLSWLlqDZUr7cu+5fdh1nc/0Lj+4bwwaizn9+oS1eeYH7XERUQkU0Z3esafjl3O5Jef51OjVm1q1zkEM+Oc7p2jOtdjjz1Go0aNaNmyJYsXL2b+/Pn51p8yZQp9+vQhJSWF6tWr06ZNG+Z88xUA9Rs3pfoBNShVqhSH16vP70t+zXH8+EmfcmKr5qSllaV75/a8PTFYbeyHnxdyQLUqNG/eHIAKFSpQunRpJk2axMCBAzO7xTOWHM1Ply5dSEtLA2Db1q3cft1VdD+pFf++pD8L5gdTxGYskVourJexROpFZ3fjhdHj2L59O6Pe+YCzu3WM5mPMl1riIiKyy0qnlM5c9hNg0+bNAHzyySdMmjSJadOmUa5cOdq2bZvvMp8FSS1TJvN1qZQUtm/bnqPOyLETmfLlLNJbnArAilVr+Oiz6exfdb9CXat06dIRS5lmjTlyKdNXnn2K/apUY8x/p7Bjxw6OOXT/fM/bvXN7bv+/YbRr3ZymDY5kv8oVCxVXbtQSFxGRfNU5pC6/L/mVxQuDRUZGvj0xc196rQP4avb3AHw1ex6//BrcD1+zZg2VKlWiXLlyfP/991kWN0lNTWXr1q05rnP88cczatQotm/fzrJly5g8eTL1GzeNKsa169bz6Rdf8+uXE1j4xbss/OJdnrjnOka+PZHDD0nnj7+WM336dADWrVvHtm3b6NChA0OHDmXbtm3AziVH09PTmTlzJgBvvPFGntdcv3YtVapVp1SpUox/I4gbyFwidcPGjcF5wyVSy5bdi1PaHsul199TJF3poJa4iEjiGvBJdPWKcCnS7PfEW7Vtz9XX38Yt9z3CFf17cXNaCse3OJp16/8Ggtbl8Nff5agTe9Di6PocdvBBAHTs2JGnn36aI488ksMPP5yWLVtmnnPAgAE0bNiQJk2aMGLEiMzyM844g2nTptGoUSPMjCFDhlClWnV++Tn/bniAt977mHatm7PXXjtb7F1Pbsu1dz3KU/fewKin7mPQoEFs3LiRtLQ0Jk2axEUXXcSPP/5Iw4YNSU1N5eKLL+aKK67g1ltv5cILL+Tmm2/OHNSWm7POu5B/DjiX8W+8Rqu27UkrF7TSM5ZIbdbpHMqkpmYukQrQ94xOvPXex5zcpmWe5y0My2uEX6Jq1qyZz5gxI9866YPfjepcC8tGMTIwiucqoxVNXIqpCGOCIosrWWOCJP757YExPdPlAKofdHDmdm7LfuaqiJJ4NIt6NCz1C59MncGDTw9n/PDHEiKmjLgKVIRfdqL9rLJ78OnhrFm7njuvvSzXmObNm8eRRx6ZpczMZrp7s9yuoZa4iIhIMTjjwn/y86LFfDR6aJGdU0lcREQKpW2rZrRtlWvDUPLx1nMPFfk5NbBNRCRBOJ7nJCZS8u3Kz15JXEQkQSxavZVtG9Yqke+B3J0VK1ZQtmzZQh2n7nQRkQTx+BerGATUrrgcw5hny6I7cM28Irn+0lUbC6yTiDFBlHEVUUxQhJ9VRExly5alZs2ahYpDSVxEJEGs3byDuyevyNwu7iceOiXgUxjRxATF/3RBkX1WuxlTTLvTzayjmf1gZj+ZWY7Jds1sLzMbFe7/wszSYxmPiIhISRKzJG5mKcATQCegHtDHzOplq3YhsMrdDwUeBu6PVTwiIiIlTSxb4scAP7n7AnffArwGdM1WpyvwUvj6daC9xWrxVxERkRImZjO2mVkPoKO7XxRu9wNauPsVEXW+C+ssCbd/Dussz3auAcCAcPNw4IciCrMKsLzAWsVLMUVHMUUvEeNSTNFRTNFLxLiKKqba7l41tx1JMbDN3YcBw4r6vGY2I6+p7OJFMUVHMUUvEeNSTNFRTNFLxLiKI6ZYdqf/BtSK2K4ZluVax8xKA/sCKxAREZECxTKJTwfqmlkdMysD9AbGZaszDjgvfN0D+Mg1y4GIiEhUYtad7u7bzOwK4H0gBXje3eeY2R3ADHcfBzwHvGxmPwErCRJ9cSryLvoioJiio5iil4hxKaboKKboJWJcMY8p6ZYiFRERkYDmThcREUlSSuIiIiJJSklcEp6ZvRz+fVW8Y5FdY4FaBdcUkcLY4+6Jm1lZ4DLgOMCBKcBT7r4proFJnsxsLnAS8B7QFsgyq5+7r4xDWFJIZjbb3RvEOw6RWCruHLMnJvHRwDrglbDobKCiu/eMY0xn5lK8Bpjt7n8VcyyV89sfj4RpZlcClwIHE8wtEJnE3d0PLu6YIplZKyCdiKc93H143AIKhb9Xmf+RuPtbcY7nJeA/7j49nnFkF67zUJ2sP79f4xdRYjGza919iJk9TvC7lIW7XxmHmB5x96vN7J08YupS3DFlKO4csycm8bnuXq+gsmKO6V3gWODjsKgtMBOoA9zh7i8XYyy/ENxmqQksIoESppk95e6Xxuv6uQm7+g8BZgHbw2KPx39skczsSeBQYGRY1Av42d0vj2NM34cxLQL+JvjdcndvGMeYBgG3AkuBHWFxvGM6k2AxqGoEn1HG51QhTvGc7u7vmNl5ue1395dyK49xTE3dfaaZtckjpv8Vd0wZijvH7IlJ/BWC1sDn4XYL4HJ3PzeOMb0PnOvuS8Pt6sBwoA8w2d3rF3M8RtALUKzXTUZmNg+ol2iTFIUJ88iMuMysFDDH3Y+MY0y1cyt390XFHUuGcI6KFu6eMDNFhjGd7u7z4h1LsjOzN9y9ezFfs1hzTFLMnV7EmgJTzSyju+wg4Aczm038voHXykjgob/CspVmtrW4g3F3N7OZZtY80bo+E9B3wP7AH/EOJJufCH63MxJkrbAsbuKZrPOxmODWVSJZmkgJPJG7rqNQbD2HGTkESGVnjnGgNvB9rK67JybxjvEOIBefmNl4YEy43T0s2xtYHaeYWgB9zSxhuj4TVBVgrpl9CWzOKEyA/9jKA/PCuJxgaeAZZjYOEiK+RLGA4N/au2T9+f1f/EJihpmNAt4ma0xvximejNt5D8bp+rujOHvITivGa2Xa47rTE1HYfd0daB0WfQa8Ec8u2kTs+kxEiXhPDvKOK0O840sUZnZrbuXufntxx5LBzF7Ipdjd/YJiD6YQ4tF1XRAz+8rdm8Q7jlhSEhcRkd1mZl+7+9HxjiNSIsZU1PbE7vSEYWbryL27J66jUSV6CTiSOK/fKQD0O5WVmR0G/Iucjwi2i2NMVYGLc4kpoVviFG/XdbSui3cAsaYkHkfuXj7eMchuG0ICjSTO+J0yszsJBtu9TPDFoi9wQBxDS1RjgKeBZ9n5iGC8jQU+BSaRODElJDNrDdxGMHisNDu/RB9M8OK/8YuueKg7XWQ3mNln7t664JrFy8y+cfdGBZXt6cxsprs3jXcckcxslrs3jncchRWPruvwUcprCObVyPzCk0iPDMaaWuIiuyfRRhJn+NvM+gKvEXRz9iF4ykCyesfMLgPeIuvPL55T+Y43s87uPiGOMeyKeHRdr3H39+Jw3YShlrjIbkjUkcRmlg48SvDEgxM88XC1uy+MX1SJJ5yhMLu4zUwYPqmS0aLcDGwlQcbIFNR1HaeY7gNSgDfJ+iXsq3jFVNyUxEV2Qzgf+FXuvjrcrgQ8FO8kLtExs7LZF6bIrayYY/ouEWdLTMSuazPLmKo6SyKL58DE4qbudJHd0zAjgQO4+yozi/sjLWZWBxhEzhHOmuQlq6lA9ueIcysrTok6W2Iidl13IphjI52dv+d7VMtUSVxk95Qys0ruvgoyV4FLhH9XbwPPAe+wc2EPCZnZ/kANIM3MIhN2BaBcfKLKlKizJX5sZg+QWF3XbxPMavkVkNF7oiQuIlF7CJhmZhlT5vYE7o5jPBk2uftj8Q4igZ0C9CdYrS9yOtF1wPXxCCjCKXG+fl5ahH9nH80fz67rmu6eiFNpFxvdExfZTWZWj53/kX3k7nPjGQ+AmZ0N1AX+S+K0mhKGmf0zYtPZueSuQ9znTk9IZlaWXLqu3f2OOMY0DHjc3WfHK4Z4U0tcZDeFSTvuiTubBkA/gi8XmetkE99WUyLZJ/z7cKA5wQQrBpwOfBmvoBJcInZdHwf0D58y2Ezi3HooNmqJi5RA4ZrU9dx9S7xjSWRmNhk41d3XhdvlgXfd/YT4RpZ4EnHUvBZqUktcpKT6DqhIsDa95K06EPlFZ0tYJjlNNbMGidR1vScl67woiYuUTBWB781sOom1znmiGQ58aWZvhdvdgBfjF05C2+O7rhORutNFSqBEXec8EYWPmB0fbk5296/jGU+iUtd1YlISF9kDmdk0dz823nGIyO4pFe8ARCQuysY7ABHZfUriInsmdcGJlABK4iIiIklKSVxkz2QFVxGRRKdHzERKMDOrQNZVzFaGL/vFJyIRKUoanS5SApnZQOB2gukxM/6Ru7sfHL+oRKSoKYmLlEBmNh841t2XxzsWEYkd3RMXKZl+BjbEOwgRiS21xEVKIDM7GngB+IKs065eGbegRKTIaWCbSMk0FPgImM3OpUhFpIRRS1ykBDKzr9396HjHISKxpSQuUgKZ2T3AQuAdsnanr8zrGBFJPkriIiVQuFxkhsx/5HrETKRk0eh0kZLpOqCRu9chGOD2DdAjviGJSFFTEhcpmW5y97VmdhzQDngWeCrOMYlIEVMSFymZtod/nwo84+7vAmXiGI+IxICSuEjJ9JuZDQV6ARPMbC/0712kxNHANpESyMzKAR2B2e4+38wOABq4+3/jHJqIFCElcRERkSSl7jUREZEkpSQuIiKSpJTERfZAZrafmc0K//xpZr9FbBdqFLuZvWBmh8cqVhHJm+6Ji+zhzOw2YL27PxjvWESkcNQSF5EszOxaM/su/DMoLDvUzOaY2WtmNs/MRptZWrhvipk1Dl+famZfmdk3ZqaR8CIxpiQuIpnMrAXQF2gOHAtcZmYNwt31gEfc/UhgEzAw27H7E8wKd4a7NwJ6F1vgInsoJXERiXQc8Ia7b3T3dcDbwPHhvl/c/fPw9Sth3UjHAh+7+yLQimkixUFJXESilX0AjQbUiMSZkriIRPoUOMPM0sxsH6BrWAZQx8yah6/PBqZkO3YqcKKZ1QYws8rFEbDInqx0vAMQkcTh7l+a2Uhgelj0lLvPNrNDgXnAP8JBbLOBYdmOXWpmlwJjzcyA34FOxRi+yB5Hj5iJSIHCJP66uzeOdywispO600VERJKUWuIiIiJJSi1xERGRJKUkLiIikqSUxEVERJKUkriIiEiSUhIXERFJUv8PT9JyajE0eQIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_keys_val = sorted(tuple(topic_to_wrong_val_percent_correct),reverse=True,key=lambda x: topic_to_wrong_val_percent_correct[x])\n",
    "# sorted_keys_eqn = sorted(tuple(topic_to_wrong_eqn_percent_correct),reverse=True,key=lambda x: topic_to_wrong_eqn_percent_correct[x])\n",
    "plot = pd.DataFrame({\"Value Accuracy\": [topic_to_wrong_val_percent_correct[key] for key in sorted_keys_val],\"Equation Accuracy\": [topic_to_wrong_eqn_percent_correct[key] for key in sorted_keys_val]}, index=sorted_keys_val).plot(kind=\"bar\",title=\"Test Accuracy by Topic\",figsize=(8, 4))\n",
    "plot.axhline(0.9, linestyle=\"dashed\", label=\"90% Accuracy\")\n",
    "plot.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Percent Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
